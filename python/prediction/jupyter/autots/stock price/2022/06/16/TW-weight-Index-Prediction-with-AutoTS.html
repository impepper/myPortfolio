<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>台灣加權股價指數預測 - 使用 AutoTS | ChiHong Lin</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="台灣加權股價指數預測 - 使用 AutoTS" />
<meta name="author" content="ChiHong Lin" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="利用 Python 強大的時間序列分析的 AutoTS 函式庫進行台灣加權股價指數預測" />
<meta property="og:description" content="利用 Python 強大的時間序列分析的 AutoTS 函式庫進行台灣加權股價指數預測" />
<link rel="canonical" href="https://impepper.github.io/myPortfolio/python/prediction/jupyter/autots/stock%20price/2022/06/16/TW-weight-Index-Prediction-with-AutoTS.html" />
<meta property="og:url" content="https://impepper.github.io/myPortfolio/python/prediction/jupyter/autots/stock%20price/2022/06/16/TW-weight-Index-Prediction-with-AutoTS.html" />
<meta property="og:site_name" content="ChiHong Lin" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-16T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="台灣加權股價指數預測 - 使用 AutoTS" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"ChiHong Lin"},"dateModified":"2022-06-16T00:00:00-05:00","datePublished":"2022-06-16T00:00:00-05:00","description":"利用 Python 強大的時間序列分析的 AutoTS 函式庫進行台灣加權股價指數預測","headline":"台灣加權股價指數預測 - 使用 AutoTS","mainEntityOfPage":{"@type":"WebPage","@id":"https://impepper.github.io/myPortfolio/python/prediction/jupyter/autots/stock%20price/2022/06/16/TW-weight-Index-Prediction-with-AutoTS.html"},"url":"https://impepper.github.io/myPortfolio/python/prediction/jupyter/autots/stock%20price/2022/06/16/TW-weight-Index-Prediction-with-AutoTS.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/myPortfolio/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://impepper.github.io/myPortfolio/feed.xml" title="ChiHong Lin" /><link rel="shortcut icon" type="image/x-icon" href="/myPortfolio/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/myPortfolio/">ChiHong Lin</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/myPortfolio/about/">CV</a><a class="page-link" href="/myPortfolio/projects/">Projects</a><a class="page-link" href="/myPortfolio/search/">Search</a><a class="page-link" href="/myPortfolio/skill/">Skills</a><a class="page-link" href="/myPortfolio/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">台灣加權股價指數預測 - 使用 AutoTS</h1><p class="page-description">利用 Python 強大的時間序列分析的 AutoTS 函式庫進行台灣加權股價指數預測</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-06-16T00:00:00-05:00" itemprop="datePublished">
        Jun 16, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">ChiHong Lin</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      311 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/myPortfolio/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myPortfolio/categories/#prediction">prediction</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myPortfolio/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myPortfolio/categories/#AutoTS">AutoTS</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myPortfolio/categories/#Stock Price">Stock Price</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-06-16-TW weight Index Prediction with AutoTS.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="&#32929;&#20729;&#38928;&#28204;&#26159;&#27231;&#22120;&#23416;&#32722;&#22312;&#37329;&#34701;&#38936;&#22495;&#26368;&#37325;&#35201;&#30340;&#25033;&#29992;&#20043;&#19968;&#12290;&#22312;&#36889;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#23559;&#22039;&#35430;&#36879;&#36942;&#20351;&#29992;-Python-&#30340;&#32218;&#24615;&#22238;&#27512;&#27169;&#22411;&#20358;&#36914;&#34892;&#32929;&#31080;&#20729;&#26684;&#30340;&#38928;&#28204;&#12290;">&#32929;&#20729;&#38928;&#28204;&#26159;&#27231;&#22120;&#23416;&#32722;&#22312;&#37329;&#34701;&#38936;&#22495;&#26368;&#37325;&#35201;&#30340;&#25033;&#29992;&#20043;&#19968;&#12290;&#22312;&#36889;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#23559;&#22039;&#35430;&#36879;&#36942;&#20351;&#29992; Python &#30340;&#32218;&#24615;&#22238;&#27512;&#27169;&#22411;&#20358;&#36914;&#34892;&#32929;&#31080;&#20729;&#26684;&#30340;&#38928;&#28204;&#12290;<a class="anchor-link" href="#&#32929;&#20729;&#38928;&#28204;&#26159;&#27231;&#22120;&#23416;&#32722;&#22312;&#37329;&#34701;&#38936;&#22495;&#26368;&#37325;&#35201;&#30340;&#25033;&#29992;&#20043;&#19968;&#12290;&#22312;&#36889;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#23559;&#22039;&#35430;&#36879;&#36942;&#20351;&#29992;-Python-&#30340;&#32218;&#24615;&#22238;&#27512;&#27169;&#22411;&#20358;&#36914;&#34892;&#32929;&#31080;&#20729;&#26684;&#30340;&#38928;&#28204;&#12290;"> </a></h4><p>預測股市的價格，一直是投資者的終極目標。 在每天數以億計的交易之中，每筆交易，都代表者投資者對於該股票的價格預期，並且期望透過交易獲利。</p>
<p>也因此，股票漲跌，便取決於投資者在交易市場中的投資行為。 如果投資者能夠準確預測市場動向，便有機會創造誘人的財富。</p>
<p>如果您具有股票市場的投資經驗以及機器學習的量化數據分析技能，對於您預測價格趨勢將會有明顯的助益。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Python-&#20989;&#24335;&#24235;-AutoTS">Python &#20989;&#24335;&#24235; AutoTS<a class="anchor-link" href="#Python-&#20989;&#24335;&#24235;-AutoTS"> </a></h2><p>AutoTS 是一個用於自動時間序列分析的 Python 函式庫。它是 autoML 的一部分，其目標是為初學者提供自動化的時間序列模型工具。</p>
<p>時間序列問題無論是在銷量預測，天氣預測還是在股票預測等問題中都至關重要，而如今隨著機器學習等快速發展，已經出現了非常多時間序列建模相關的函式庫，AutoTS 融合了自動化機器學習技術，會先對數據進行預處理，從數據中刪除異常值，再通過學習尋找最佳值。Auto 只需使用一行代碼，就可以訓練多個時間序列模型，包括ARIMA、SARIMAX、FB Prophet、VAR，並得出效果最佳的模型。它具有以下幾個特性：</p>
<ol>
<li>它可用於查找最佳時間序列預測模型，具體取決於您使用的數據類型。</li>
<li>它可以處理單變量和多變量時間序列。</li>
<li>它還可以通過刪除和填充 NaN 值來處理混亂的數據，它還可以處理異常值。</li>
</ol>
<p>您可以將此庫用於時間序列預測的任何任務，例如預測未來 n 天的股票價格。</p>
<p>AutoTS是一個非常不錯的時間序列函式庫，在碰到時間序列問題時，可以考慮使用AutoTS來進行訓練和預測，作為一個非常不錯的Baseline。</p>
<h3 id="&#21443;&#32771;&#36899;&#32080;">&#21443;&#32771;&#36899;&#32080;<a class="anchor-link" href="#&#21443;&#32771;&#36899;&#32080;"> </a></h3><ul>
<li><a href="https://pypi.org/project/AutoTS/">https://pypi.org/project/AutoTS/</a></li>
<li><a href="https://github.com/winedarksea/AutoTS">https://github.com/winedarksea/AutoTS</a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#21488;&#28771;&#21152;&#27402;&#32929;&#20729;&#25351;&#25976;&#38928;&#28204;">&#21488;&#28771;&#21152;&#27402;&#32929;&#20729;&#25351;&#25976;&#38928;&#28204;<a class="anchor-link" href="#&#21488;&#28771;&#21152;&#27402;&#32929;&#20729;&#25351;&#25976;&#38928;&#28204;"> </a></h2><p>我將透過 <a href="https://pypi.org/project/yfinance/">yfinance API</a> 從 <a href="https://pypi.org/project/yfinance/">yfinance API</a> 取得台灣加權指數（代碼 <strong>^TWII</strong>）近3年的歷史價格數據，並藉由這些數據來進行分析及預測。</p>
<p>我們首先先將需要的函式庫載入：</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="nn">yf</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">date</span><span class="p">,</span> <span class="n">timedelta</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>透過 <a href="https://pypi.org/project/yfinance/">yfinance API</a> 從 <a href="https://pypi.org/project/yfinance/">yfinance API</a> 取得台灣加權指數（代碼 <strong>^TWII</strong>）近3年的歷史價格數據</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">today</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>

<span class="n">d1</span> <span class="o">=</span> <span class="n">today</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">end_date</span> <span class="o">=</span> <span class="n">d1</span>
<span class="n">d2</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1095</span><span class="p">)</span>
<span class="n">d2</span> <span class="o">=</span> <span class="n">d2</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">start_date</span> <span class="o">=</span> <span class="n">d2</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;^TWII&#39;</span><span class="p">,</span>
                   <span class="n">start</span><span class="o">=</span><span class="n">start_date</span><span class="p">,</span>
                   <span class="n">end</span><span class="o">=</span><span class="n">end_date</span><span class="p">,</span>
                   <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;Date&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s2">&quot;Date&quot;</span><span class="p">,</span> <span class="s2">&quot;Open&quot;</span><span class="p">,</span> <span class="s2">&quot;High&quot;</span><span class="p">,</span> <span class="s2">&quot;Low&quot;</span><span class="p">,</span> <span class="s2">&quot;Close&quot;</span><span class="p">,</span> <span class="s2">&quot;Adj Close&quot;</span><span class="p">,</span> <span class="s2">&quot;Volume&quot;</span><span class="p">]]</span>
<span class="n">data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>初步了解取得的數據內容</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(730, 7)
        Date          Open          High           Low         Close  \
0 2019-06-17  10488.700195  10562.969727  10474.190430  10530.540039   
1 2019-06-18  10547.150391  10573.769531  10521.700195  10566.740234   
2 2019-06-19  10650.480469  10778.639648  10650.480469  10775.339844   
3 2019-06-20  10749.410156  10799.139648  10745.250000  10785.009766   
4 2019-06-21  10817.709961  10840.290039  10773.469727  10803.769531   

      Adj Close   Volume  
0  10530.540039  1444800  
1  10566.740234  1524200  
2  10775.339844  2370300  
3  10785.009766  2079800  
4  10803.769531  2780700  
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>我們繪製一下指數的走勢（以K線圖表示）：</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">plotly.graph_objects</span> <span class="k">as</span> <span class="nn">go</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="n">go</span><span class="o">.</span><span class="n">Candlestick</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;Date&quot;</span><span class="p">],</span>
                                        <span class="nb">open</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;Open&quot;</span><span class="p">],</span>
                                        <span class="n">high</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;High&quot;</span><span class="p">],</span>
                                        <span class="n">low</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;Low&quot;</span><span class="p">],</span>
                                        <span class="n">close</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">])])</span>
<span class="n">figure</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;台灣加權指數走勢&quot;</span><span class="p">,</span> 
                     <span class="n">xaxis_rangeslider_visible</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">figure</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>                            <div id="1c55714d-cc2a-43c4-a332-0d6afcdcc557" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("1c55714d-cc2a-43c4-a332-0d6afcdcc557")) {                    Plotly.newPlot(                        "1c55714d-cc2a-43c4-a332-0d6afcdcc557",                        [{"close":[10530.5400390625,10566.740234375,10775.33984375,10785.009765625,10803.76953125,10779.4501953125,10706.7197265625,10652.5498046875,10773.900390625,10730.830078125,10895.4599609375,10865.1201171875,10743.76953125,10775.900390625,10785.73046875,10751.2197265625,10702.7802734375,10798.48046875,10843.419921875,10824.349609375,10876.4296875,10886.0498046875,10828.48046875,10799.2802734375,10873.1904296875,10944.5302734375,10947.259765625,10935.759765625,10941.41015625,10891.98046875,10885.73046875,10830.900390625,10823.8095703125,10731.75,10549.0400390625,10423.41015625,10394.75,10386.1796875,10494.490234375,10472.3603515625,10362.66015625,10427.73046875,10327.1298828125,10420.8896484375,10488.75,10522.5,10525.7998046875,10529.7802734375,10538.1103515625,10354.5703125,10387.23046875,10434.2900390625,10462.4296875,10618.0498046875,10634.849609375,10558.2099609375,10657.3095703125,10756.9296875,10780.6396484375,10753.580078125,10790.349609375,10827.5498046875,10898.1298828125,10874.5,10929.4501953125,10894.7001953125,10929.6904296875,10919.01953125,10918.009765625,10873.6904296875,10871.990234375,10829.6796875,10967.650390625,10947.8798828125,10875.91015625,10894.48046875,10935.0595703125,11017.3095703125,10889.9599609375,11066.9501953125,11111.7998046875,11162.830078125,11186.8798828125,11180.2197265625,11184.150390625,11271.25,11239.669921875,11320.1396484375,11296.1201171875,11315.01953125,11333.8701171875,11380.2802734375,11358.7099609375,11399.5302734375,11556.849609375,11644.0302734375,11653.0703125,11606.5595703125,11579.5400390625,11427.2802734375,11520.3701171875,11467.830078125,11450.419921875,11525.599609375,11599.7802734375,11656.400390625,11631.2001953125,11558.26953125,11566.7998046875,11561.580078125,11576.8203125,11647.4599609375,11617.080078125,11489.5703125,11502.830078125,11531.580078125,11510.4697265625,11594.650390625,11609.6396484375,11660.76953125,11627.83984375,11700.76953125,11836.419921875,11927.73046875,11939.76953125,12097.009765625,12122.4501953125,12018.900390625,11959.080078125,12022.23046875,11976.3798828125,12008.1298828125,12001.009765625,12091.58984375,12053.3701171875,11997.1396484375,12100.48046875,12110.4296875,11953.3603515625,11880.3203125,11817.099609375,11970.6298828125,12024.650390625,12113.419921875,12179.8095703125,12091.8798828125,12066.9296875,12090.2900390625,12118.7099609375,11421.740234375,11495.099609375,11354.919921875,11555.919921875,11573.6201171875,11749.6796875,11612.8095703125,11574.0703125,11664.0400390625,11774.1904296875,11791.7802734375,11815.7001953125,11763.509765625,11648.98046875,11758.83984375,11725.08984375,11686.349609375,11534.8701171875,11540.23046875,11433.6201171875,11292.169921875,11170.4599609375,11327.7197265625,11392.349609375,11514.8203125,11321.8095703125,10977.6396484375,11003.5400390625,10893.75,10422.3203125,10128.8701171875,9717.76953125,9439.6298828125,9218.669921875,8681.33984375,9234.08984375,8890.0302734375,9285.6201171875,9644.75,9736.3603515625,9698.919921875,9629.4296875,9708.0595703125,9663.6298828125,9818.740234375,9996.3896484375,10137.4697265625,10119.4296875,10157.6103515625,10099.2197265625,10332.9404296875,10447.2099609375,10375.48046875,10597.0400390625,10586.7099609375,10288.419921875,10307.740234375,10366.509765625,10347.3603515625,10567.26953125,10616.0595703125,10772.2197265625,10992.1396484375,10720.48046875,10774.6103515625,10774.98046875,10842.919921875,10901.419921875,11013.259765625,10879.4697265625,10938.26953125,10780.8798828125,10814.919921875,10740.5498046875,10860.4404296875,10907.7998046875,11008.3095703125,10811.150390625,10871.1796875,10997.2099609375,11014.66015625,10944.1904296875,10942.16015625,11079.01953125,11127.9296875,11320.16015625,11393.23046875,11479.400390625,11610.3203125,11637.1103515625,11720.16015625,11535.76953125,11429.9404296875,11306.259765625,11511.6396484375,11534.58984375,11548.330078125,11549.8603515625,11572.9296875,11612.3603515625,11660.669921875,11542.6201171875,11621.240234375,11703.419921875,11805.1396484375,11909.16015625,12116.7001953125,12092.9697265625,12170.1904296875,12192.6904296875,12073.6796875,12211.5595703125,12209.009765625,12202.849609375,12157.740234375,12181.5595703125,12174.5400390625,12397.5498046875,12473.26953125,12413.0400390625,12304.0400390625,12588.2998046875,12586.73046875,12540.9697265625,12722.919921875,12664.7998046875,12513.0302734375,12709.919921875,12802.2998046875,12913.5,12828.8701171875,12894.0,12780.1904296875,12670.349609375,12763.1298828125,12795.4599609375,12956.1103515625,12872.1396484375,12778.6396484375,12362.6396484375,12607.83984375,12647.1298828125,12758.25,12833.2900390625,12797.3095703125,12728.849609375,12591.4501953125,12703.2802734375,12699.5,12757.9697265625,12637.9501953125,12601.400390625,12663.5595703125,12608.580078125,12691.75,12675.9501953125,12787.8203125,12845.650390625,12976.759765625,12872.740234375,12875.6201171875,12795.1201171875,12645.509765625,12583.8798828125,12264.3798828125,12232.91015625,12462.759765625,12467.73046875,12515.6103515625,12548.2802734375,12704.23046875,12746.3701171875,12887.1904296875,12955.91015625,12947.1298828125,12919.3095703125,12827.8203125,12750.3701171875,12908.33984375,12862.3701171875,12877.25,12917.0302734375,12898.8203125,12909.0302734375,12875.009765625,12793.75,12662.91015625,12546.33984375,12591.3095703125,12736.009765625,12867.900390625,12918.7998046875,12973.5302734375,13127.4697265625,13081.7197265625,13262.1904296875,13221.7802734375,13273.330078125,13551.830078125,13593.009765625,13773.2900390625,13722.4296875,13716.4404296875,13878.009765625,13807.1298828125,13738.830078125,13845.66015625,13867.08984375,13722.8896484375,13885.669921875,13989.1396484375,13977.08984375,14132.4404296875,14256.599609375,14360.400390625,14390.1396484375,14249.490234375,14261.6904296875,14211.0498046875,14068.51953125,14304.4599609375,14258.9296875,14249.9599609375,14384.9599609375,14177.4599609375,14223.08984375,14280.2802734375,14331.419921875,14483.0703125,14472.0498046875,14687.7001953125,14732.5302734375,14902.0302734375,15000.0302734375,14983.1298828125,15214.0,15463.9501953125,15557.2998046875,15500.7001953125,15769.98046875,15707.1904296875,15616.3896484375,15612.0,15877.3701171875,15806.1796875,16153.76953125,16019.0302734375,15946.5400390625,15658.849609375,15701.4501953125,15415.8798828125,15138.3095703125,15410.08984375,15760.0498046875,15771.3203125,15706.2197265625,15802.400390625,16362.2900390625,16424.509765625,16341.3798828125,16410.16015625,16443.400390625,16212.5302734375,16452.1796875,15953.7998046875,15946.8798828125,16211.73046875,15906.41015625,15855.23046875,15820.1103515625,15853.08984375,15911.669921875,16179.5595703125,16255.1796875,16249.330078125,16313.16015625,16215.8203125,16287.83984375,16070.240234375,16189.2197265625,16177.58984375,16032.1201171875,16060.1396484375,16305.8798828125,16475.970703125,16554.900390625,16431.130859375,16571.279296875,16815.359375,16926.439453125,16854.099609375,16859.69921875,16824.91015625,16865.970703125,17076.73046875,17158.810546875,17263.279296875,17323.869140625,17202.109375,17096.970703125,17300.26953125,17572.2890625,17595.900390625,17567.529296875,17566.66015625,17222.349609375,16933.779296875,16843.439453125,16994.359375,17285.0,17235.609375,16583.130859375,15902.3701171875,15670.099609375,15827.08984375,15353.8896484375,16145.98046875,16132.66015625,16042.3603515625,16302.0595703125,16338.2900390625,16595.669921875,16643.689453125,16601.609375,16870.859375,17068.4296875,17162.380859375,17165.0390625,17246.16015625,17147.41015625,17083.91015625,17076.2109375,16966.220703125,17159.220703125,17213.51953125,17371.2890625,17307.859375,17390.609375,17318.5390625,17062.98046875,17075.55078125,17336.7109375,17407.9609375,17502.990234375,17590.970703125,17598.189453125,17755.4609375,17713.939453125,17710.150390625,17919.330078125,17913.0703125,17850.689453125,17866.08984375,17661.48046875,17814.330078125,17847.51953125,17845.75,18034.189453125,17895.25,17789.25,17528.740234375,17458.7890625,17572.330078125,17572.919921875,17403.560546875,17269.869140625,17135.220703125,17402.810546875,17247.41015625,17503.279296875,17553.759765625,17623.890625,17603.119140625,17526.279296875,17485.150390625,17323.640625,17227.1796875,17219.939453125,16982.109375,16858.76953125,16661.359375,16826.26953125,16375.400390625,16341.9404296875,16741.83984375,16818.73046875,17045.859375,17066.9609375,17209.9296875,17396.51953125,17490.2890625,17473.990234375,17319.759765625,17516.919921875,17495.30078125,17428.869140625,17270.490234375,17304.330078125,17474.5703125,17446.310546875,17434.900390625,17354.0,17278.69921875,17276.7890625,16925.8203125,17078.220703125,17260.189453125,17313.76953125,17181.439453125,16855.4609375,16934.76953125,16570.890625,16408.349609375,16460.75,16393.16015625,16713.859375,16640.4296875,16462.83984375,16347.990234375,16387.279296875,16781.189453125,16705.4609375,16900.669921875,16887.8203125,16889.509765625,16888.740234375,16894.240234375,17034.33984375,17074.55078125,17041.630859375,16987.41015625,17068.240234375,17065.970703125,17122.16015625,17078.859375,17296.900390625,17415.30078125,17541.359375,17559.650390625,17452.51953125,17518.130859375,17634.470703125,17693.130859375,17764.0390625,17841.369140625,17818.310546875,17803.5390625,17666.119140625,17642.51953125,17654.189453125,17369.390625,17328.08984375,17427.759765625,17585.990234375,17724.880859375,17697.140625,17688.2109375,17796.919921875,17832.419921875,17914.119140625,17826.259765625,17767.599609375,17599.369140625,17660.099609375,17785.740234375,17812.58984375,17669.109375,17789.26953125,17826.830078125,17946.66015625,17961.640625,18048.939453125,18196.810546875,18248.279296875,18218.83984375,18270.509765625,18526.349609375,18499.9609375,18367.919921875,18169.759765625,18239.380859375,18288.2109375,18375.400390625,18436.9296875,18403.330078125,18525.439453125,18378.640625,18227.4609375,18218.279296875,17899.30078125,17989.0390625,17701.119140625,17674.400390625,17900.30078125,17966.560546875,18151.759765625,18338.05078125,18310.939453125,17997.669921875,17951.810546875,18231.470703125,18268.5703125,18232.349609375,18221.490234375,17969.2890625,18055.73046875,17594.55078125,17652.1796875,17898.25,17867.599609375,17934.400390625,17736.51953125,17178.689453125,16825.25,17015.359375,17433.19921875,17264.740234375,17263.0390625,16926.060546875,16940.830078125,17448.220703125,17456.51953125,17560.359375,17559.7109375,17731.369140625,17699.060546875,17676.94921875,17520.009765625,17548.66015625,17740.560546875,17693.470703125,17625.58984375,17522.5,17178.630859375,17284.5390625,17048.369140625,16990.91015625,17301.650390625,17245.650390625,17004.1796875,16898.869140625,16993.400390625,17148.880859375,17127.94921875,17025.08984375,16620.900390625,16644.7890625,16303.349609375,16419.380859375,16592.1796875,16498.900390625,16565.830078125,16696.119140625,16408.19921875,16048.919921875,16061.7001953125,16006.25,15616.6796875,15832.5400390625,15901.0400390625,16056.08984375,16296.8603515625,16020.3203125,16144.849609375,16156.41015625,15963.6298828125,16104.0302734375,15968.830078125,16266.2197265625,16610.619140625,16807.76953125,16675.08984375,16552.5703125,16605.9609375,16512.880859375,16670.509765625,16621.33984375,16460.119140625,16070.98046875,16047.3701171875,15999.25],"high":[10562.9697265625,10573.76953125,10778.6396484375,10799.1396484375,10840.2900390625,10786.330078125,10787.6201171875,10690.98046875,10800.2900390625,10788.080078125,10914.849609375,10888.2099609375,10812.650390625,10791.2802734375,10812.3798828125,10781.1103515625,10733.5703125,10810.16015625,10856.509765625,10867.58984375,10880.5595703125,10899.83984375,10861.1103515625,10835.4296875,10919.9599609375,10949.759765625,10994.4404296875,10976.4599609375,10945.919921875,10907.4404296875,10905.740234375,10927.16015625,10835.7998046875,10773.25,10641.2802734375,10542.490234375,10425.599609375,10461.3701171875,10500.76953125,10514.0498046875,10436.6201171875,10518.01953125,10374.75,10456.3203125,10516.0498046875,10538.1201171875,10545.25,10596.41015625,10541.73046875,10453.400390625,10431.7802734375,10456.2998046875,10466.990234375,10618.0498046875,10634.849609375,10650.150390625,10670.4296875,10766.599609375,10803.0703125,10810.0302734375,10815.58984375,10862.6796875,10898.1298828125,10912.23046875,10971.5400390625,10954.1796875,10931.759765625,10948.1904296875,10947.5302734375,10885.669921875,10934.91015625,10921.169921875,10967.650390625,10965.2001953125,10888.400390625,10941.490234375,10954.4501953125,11020.509765625,10989.3896484375,11085.490234375,11126.4501953125,11180.1103515625,11186.8798828125,11237.3798828125,11188.1298828125,11271.25,11281.1201171875,11320.1396484375,11347.1796875,11341.0302734375,11373.9501953125,11380.2802734375,11428.419921875,11399.5302734375,11559.0703125,11644.0302734375,11668.2001953125,11647.4697265625,11642.41015625,11570.330078125,11520.3701171875,11509.3701171875,11498.25,11552.25,11599.7802734375,11656.400390625,11649.0703125,11573.83984375,11577.01953125,11604.75,11642.9599609375,11651.73046875,11654.0595703125,11623.58984375,11524.849609375,11531.580078125,11513.830078125,11604.3896484375,11657.650390625,11678.3603515625,11649.73046875,11700.76953125,11875.98046875,11990.7802734375,11975.73046875,12097.009765625,12125.900390625,12111.76953125,12028.2197265625,12022.23046875,12027.599609375,12032.3701171875,12030.66015625,12093.01953125,12114.8896484375,12047.75,12110.740234375,12197.6396484375,12040.080078125,11986.0302734375,11899.669921875,11992.5498046875,12038.2099609375,12113.419921875,12186.6201171875,12169.919921875,12075.5400390625,12117.5498046875,12151.419921875,11933.23046875,11594.2099609375,11365.900390625,11581.3603515625,11620.419921875,11749.6796875,11712.7099609375,11598.0302734375,11678.580078125,11801.51953125,11854.98046875,11840.7900390625,11775.5595703125,11717.099609375,11783.4296875,11827.830078125,11755.169921875,11615.2802734375,11567.08984375,11494.2197265625,11470.23046875,11282.0498046875,11390.240234375,11392.349609375,11525.3203125,11471.3603515625,11221.759765625,11032.4697265625,11088.23046875,10845.3896484375,10171.2001953125,10130.7998046875,9677.0703125,9509.6103515625,9085.2802734375,9264.419921875,9029.51953125,9415.6396484375,9722.3701171875,9739.73046875,9954.8603515625,9655.7001953125,9789.8095703125,9736.0,9818.740234375,10039.150390625,10149.759765625,10246.83984375,10165.1201171875,10179.400390625,10344.1298828125,10461.83984375,10425.2900390625,10710.150390625,10637.6396484375,10544.7998046875,10310.849609375,10462.7001953125,10386.9296875,10578.9599609375,10620.51953125,10794.830078125,11012.7802734375,10781.509765625,10833.5302734375,10828.73046875,10890.8701171875,10970.7001953125,11039.1103515625,10974.509765625,10938.26953125,10894.169921875,10904.009765625,10812.8701171875,10924.7900390625,10933.98046875,11021.66015625,10977.5498046875,10874.5400390625,11046.2197265625,11069.7197265625,11087.5302734375,10965.0302734375,11109.2900390625,11170.490234375,11330.51953125,11425.419921875,11482.3603515625,11631.8896484375,11640.4501953125,11740.900390625,11771.1201171875,11442.2998046875,11469.83984375,11542.25,11550.3203125,11567.419921875,11584.8798828125,11632.8798828125,11679.400390625,11701.23046875,11608.7998046875,11638.0,11736.3896484375,11805.2099609375,11933.58984375,12116.7001953125,12249.9501953125,12190.26953125,12273.4296875,12253.580078125,12216.240234375,12228.3095703125,12320.48046875,12220.9296875,12266.9296875,12221.330078125,12450.16015625,12486.9501953125,12429.759765625,12502.83984375,12686.3603515625,13031.7001953125,12660.8701171875,12769.4697265625,12733.48046875,12673.01953125,12709.919921875,12816.3896484375,12971.8701171875,12912.6298828125,12933.16015625,12906.009765625,12730.9599609375,12812.7998046875,12801.3095703125,12956.1103515625,12981.580078125,12950.1103515625,12764.75,12638.650390625,12702.9404296875,12814.5595703125,12833.2900390625,12960.6796875,12799.16015625,12831.3798828125,12703.2802734375,12802.6103515625,12857.7900390625,12655.669921875,12725.0498046875,12702.5498046875,12616.5703125,12708.6396484375,12701.7900390625,12793.0703125,12857.73046875,13021.6796875,12972.51953125,12927.8095703125,12952.3095703125,12786.91015625,12700.8896484375,12487.48046875,12385.8095703125,12462.759765625,12571.33984375,12568.6796875,12637.6201171875,12706.3896484375,12774.3603515625,12887.1904296875,12997.7900390625,12994.66015625,12960.0,12909.1103515625,12896.2998046875,12911.41015625,12917.75,12942.1201171875,12917.0302734375,12963.259765625,12971.580078125,12884.3203125,12879.98046875,12699.8203125,12656.2900390625,12594.33984375,12760.1396484375,12885.2802734375,12918.7998046875,12999.16015625,13149.900390625,13142.2197265625,13262.1904296875,13324.8603515625,13273.330078125,13551.830078125,13780.1201171875,13773.2900390625,13785.919921875,13726.2197265625,13921.16015625,13951.169921875,13893.2001953125,13856.759765625,13885.009765625,13969.3896484375,13885.669921875,13995.7001953125,14049.580078125,14149.5595703125,14306.8701171875,14367.0,14427.41015625,14319.3798828125,14353.169921875,14270.33984375,14256.5498046875,14339.5,14338.400390625,14329.1201171875,14384.9599609375,14411.9296875,14247.7900390625,14324.419921875,14400.830078125,14483.0703125,14547.0703125,14695.4404296875,14760.0595703125,14937.1298828125,15000.0302734375,15197.6796875,15270.400390625,15463.9501953125,15557.2998046875,15642.0302734375,15778.51953125,15760.150390625,16041.58984375,15676.4501953125,15928.1396484375,16004.3203125,16238.4599609375,16138.0400390625,16014.9599609375,16023.8701171875,15837.4697265625,15557.01953125,15603.41015625,15429.98046875,15838.150390625,15896.400390625,15801.3701171875,15938.08984375,16406.779296875,16517.73046875,16382.7001953125,16579.169921875,16467.75,16456.939453125,16474.05078125,16190.0400390625,16262.91015625,16211.73046875,16091.75,15934.4296875,16074.9697265625,15864.259765625,15986.0703125,16216.2197265625,16298.0302734375,16281.91015625,16340.66015625,16349.2099609375,16410.01953125,16186.4599609375,16235.6298828125,16351.3798828125,16125.5400390625,16146.580078125,16325.6201171875,16520.890625,16556.189453125,16550.19921875,16602.470703125,16816.33984375,16926.720703125,17016.130859375,16979.349609375,17041.369140625,16935.390625,17076.73046875,17158.810546875,17294.150390625,17323.869140625,17282.759765625,17428.150390625,17300.26953125,17572.2890625,17630.189453125,17628.810546875,17709.23046875,17546.939453125,17328.55078125,17052.19921875,17088.73046875,17285.0,17304.470703125,17137.189453125,16552.630859375,16031.9296875,16075.48046875,15719.740234375,16153.76953125,16273.98046875,16154.080078125,16431.140625,16397.58984375,16657.599609375,16706.2890625,16601.609375,16889.009765625,17113.330078125,17184.30078125,17274.66015625,17311.279296875,17225.060546875,17189.23046875,17181.51953125,17082.51953125,17159.220703125,17278.55078125,17371.2890625,17398.220703125,17390.609375,17417.5,17305.490234375,17270.470703125,17375.7890625,17439.630859375,17597.330078125,17595.509765625,17713.240234375,17797.26953125,17863.900390625,17795.880859375,17945.51953125,18008.369140625,17933.619140625,17935.109375,17778.119140625,17947.900390625,18018.0390625,17940.859375,18034.189453125,17926.380859375,17854.349609375,17724.919921875,17707.560546875,17667.380859375,17672.599609375,17637.359375,17459.349609375,17252.869140625,17402.810546875,17429.009765625,17503.279296875,17553.759765625,17636.109375,17643.970703125,17593.849609375,17510.08984375,17524.91015625,17327.19921875,17233.109375,17216.33984375,16983.58984375,16870.55078125,16826.26953125,16777.779296875,16507.109375,16785.2890625,16904.30078125,17045.859375,17201.419921875,17229.890625,17396.51953125,17490.2890625,17503.9296875,17523.16015625,17540.779296875,17633.669921875,17559.2109375,17447.580078125,17319.08984375,17474.5703125,17482.5703125,17529.470703125,17439.75,17411.369140625,17408.7109375,17196.7890625,17145.25,17273.58984375,17335.990234375,17286.890625,17127.859375,16994.2109375,16883.0,16680.2890625,16460.75,16568.2109375,16731.580078125,16771.7109375,16589.720703125,16543.330078125,16519.9609375,16781.189453125,16862.029296875,16916.720703125,16973.859375,17026.890625,16932.890625,16930.98046875,17067.150390625,17079.599609375,17104.859375,17073.970703125,17119.4296875,17237.08984375,17153.759765625,17219.650390625,17296.900390625,17415.30078125,17581.51953125,17575.439453125,17527.1796875,17602.05078125,17683.189453125,17708.099609375,17764.0390625,17841.369140625,17986.1796875,17857.73046875,17797.900390625,17722.890625,17724.5,17641.7890625,17415.630859375,17535.23046875,17626.2109375,17741.55078125,17781.140625,17763.419921875,17796.919921875,17988.880859375,17925.119140625,17893.2890625,17919.349609375,17754.380859375,17678.779296875,17814.3203125,17822.740234375,17812.810546875,17825.890625,17870.16015625,17960.990234375,18039.849609375,18099.779296875,18197.359375,18283.25,18291.25,18379.689453125,18526.349609375,18619.609375,18427.150390625,18444.119140625,18243.259765625,18293.529296875,18394.69921875,18459.73046875,18509.0,18535.419921875,18575.41015625,18359.140625,18292.140625,18113.939453125,18004.44921875,17890.7109375,17776.419921875,17900.30078125,18063.55078125,18168.599609375,18338.05078125,18310.939453125,18182.73046875,18085.91015625,18233.7890625,18330.630859375,18262.9609375,18253.099609375,18159.509765625,18109.279296875,17939.529296875,17737.3203125,17944.5,17918.98046875,18026.029296875,17845.009765625,17581.5703125,17113.669921875,17072.740234375,17478.4296875,17373.900390625,17363.0390625,17177.26953125,17085.76953125,17472.94921875,17472.380859375,17603.990234375,17573.2890625,17738.689453125,17711.169921875,17747.130859375,17527.150390625,17585.91015625,17770.0703125,17767.810546875,17657.759765625,17528.990234375,17438.599609375,17316.689453125,17316.349609375,17100.849609375,17333.2109375,17374.140625,17141.330078125,16999.359375,17106.259765625,17148.880859375,17213.66015625,17088.759765625,16912.30078125,16729.470703125,16427.3203125,16455.5703125,16663.66015625,16604.869140625,16617.060546875,16783.779296875,16491.109375,16345.83984375,16071.5,16081.150390625,15943.6201171875,15860.6904296875,16032.849609375,16085.849609375,16316.580078125,16111.490234375,16181.66015625,16249.4501953125,16219.7998046875,16169.1796875,16179.009765625,16266.2197265625,16610.619140625,16807.76953125,16811.0390625,16617.259765625,16654.119140625,16593.75,16702.990234375,16643.94921875,16581.810546875,16295.0703125,16067.7998046875,16106.75],"low":[10474.1904296875,10521.7001953125,10650.48046875,10745.25,10773.4697265625,10695.490234375,10693.0400390625,10645.3701171875,10674.2001953125,10719.080078125,10821.2998046875,10843.6396484375,10720.66015625,10750.900390625,10756.669921875,10708.919921875,10680.849609375,10723.23046875,10799.650390625,10823.8896484375,10769.5703125,10865.0,10804.33984375,10792.26953125,10861.990234375,10909.150390625,10932.5302734375,10912.919921875,10879.400390625,10879.240234375,10863.330078125,10827.740234375,10754.0703125,10714.73046875,10524.6796875,10418.25,10180.0400390625,10366.5400390625,10383.6201171875,10440.76953125,10361.8896484375,10427.73046875,10287.759765625,10318.3701171875,10449.3896484375,10497.1298828125,10504.490234375,10515.7197265625,10503.0703125,10340.150390625,10368.9599609375,10397.599609375,10406.490234375,10504.2802734375,10589.419921875,10557.0302734375,10566.3203125,10714.26953125,10753.4501953125,10732.7802734375,10746.8701171875,10804.01953125,10822.6904296875,10866.4296875,10878.33984375,10874.66015625,10903.4501953125,10905.919921875,10886.6201171875,10825.849609375,10856.9599609375,10827.6103515625,10855.599609375,10927.3896484375,10809.2802734375,10854.1201171875,10919.4296875,10986.009765625,10889.9599609375,11004.740234375,11091.2900390625,11113.1796875,11131.4501953125,11154.8603515625,11147.8603515625,11218.25,11209.099609375,11254.58984375,11281.3701171875,11295.4404296875,11292.830078125,11306.9501953125,11358.7099609375,11335.509765625,11451.7197265625,11576.1796875,11601.7001953125,11552.080078125,11561.3095703125,11409.830078125,11459.6796875,11439.08984375,11424.76953125,11485.4599609375,11532.9697265625,11576.7900390625,11591.73046875,11478.4296875,11534.150390625,11559.330078125,11576.8203125,11590.8095703125,11604.6796875,11485.16015625,11454.3798828125,11460.0595703125,11457.4296875,11546.75,11577.830078125,11631.0302734375,11607.259765625,11622.580078125,11766.98046875,11913.01953125,11915.6103515625,11939.6201171875,12059.919921875,12008.16015625,11937.4501953125,11960.2099609375,11976.3798828125,11973.9501953125,11982.6396484375,12032.7197265625,12046.2197265625,11997.1396484375,12026.23046875,12023.599609375,11953.3603515625,11822.400390625,11777.4501953125,11889.4599609375,11959.0595703125,12037.240234375,12140.26953125,12048.009765625,12006.080078125,12055.91015625,12101.5498046875,11418.2197265625,11436.9501953125,11138.0302734375,11393.0302734375,11512.7099609375,11605.1103515625,11592.08984375,11423.33984375,11614.25,11693.400390625,11784.9404296875,11788.8701171875,11724.8203125,11642.9501953125,11654.16015625,11714.150390625,11661.6298828125,11512.080078125,11415.4697265625,11408.0595703125,11274.51953125,11049.849609375,11279.8603515625,11297.8095703125,11454.650390625,11310.3203125,10977.6396484375,10830.2197265625,10885.91015625,10359.669921875,9636.150390625,9717.76953125,9371.349609375,9218.669921875,8523.6298828125,8816.8603515625,8750.1396484375,9083.7802734375,9426.4296875,9565.01953125,9691.1396484375,9415.51953125,9630.2998046875,9663.6298828125,9651.51953125,9928.16015625,9984.66015625,10092.3603515625,10103.76953125,10080.650390625,10130.650390625,10366.76953125,10317.1298828125,10552.580078125,10542.9599609375,10278.9501953125,10140.08984375,10294.8798828125,10324.2001953125,10407.490234375,10537.7099609375,10656.400390625,10826.259765625,10658.5,10735.009765625,10708.099609375,10775.16015625,10883.2197265625,10942.1796875,10854.509765625,10828.9296875,10777.4599609375,10730.5498046875,10730.7001953125,10812.7900390625,10860.150390625,10933.2099609375,10804.5595703125,10719.25,10903.3203125,10972.25,10915.2998046875,10861.900390625,10971.400390625,11102.9697265625,11182.51953125,11341.580078125,11411.9404296875,11528.4404296875,11537.3798828125,11621.01953125,11516.58984375,11244.6396484375,11299.4501953125,11380.669921875,11482.3203125,11485.3896484375,11542.3701171875,11553.91015625,11530.849609375,11637.7900390625,11500.650390625,11563.599609375,11622.6396484375,11690.9501953125,11857.900390625,11941.83984375,12028.5703125,12083.83984375,12181.33984375,12030.2001953125,12109.6103515625,12143.91015625,12162.51953125,12107.0400390625,12144.6201171875,12065.7998046875,12242.3203125,12389.400390625,12347.8603515625,12266.5498046875,12586.91015625,12533.1904296875,12488.009765625,12616.830078125,12635.7099609375,12506.58984375,12577.8798828125,12739.990234375,12851.2001953125,12791.1796875,12786.7998046875,12780.1904296875,12625.5400390625,12717.1298828125,12679.1904296875,12800.6904296875,12840.25,12778.6396484375,12144.759765625,12462.51953125,12567.9501953125,12698.849609375,12734.6904296875,12786.4501953125,12674.5703125,12591.4501953125,12565.830078125,12646.4697265625,12732.3203125,12559.7802734375,12575.3603515625,12614.7197265625,12480.5,12650.400390625,12616.6796875,12680.41015625,12773.23046875,12948.7197265625,12851.51953125,12841.08984375,12795.08984375,12632.740234375,12548.0703125,12264.3798828125,12149.8095703125,12282.3603515625,12429.7197265625,12466.580078125,12519.1201171875,12644.08984375,12619.8095703125,12818.009765625,12898.8896484375,12857.099609375,12895.7900390625,12786.259765625,12750.3701171875,12803.3203125,12862.3701171875,12846.419921875,12827.400390625,12875.23046875,12894.1796875,12821.0703125,12761.330078125,12583.3701171875,12546.33984375,12480.66015625,12641.2802734375,12736.01953125,12840.400390625,12927.2998046875,13048.669921875,13022.919921875,13067.0400390625,13193.740234375,13170.1201171875,13356.740234375,13593.009765625,13608.7197265625,13700.0400390625,13666.0703125,13793.5498046875,13798.3203125,13731.8095703125,13763.7900390625,13811.8095703125,13722.8896484375,13749.7099609375,13894.7001953125,13940.0703125,14010.169921875,14142.01953125,14184.580078125,14336.6904296875,14191.849609375,14081.419921875,14182.25,14053.349609375,14145.240234375,14213.490234375,14245.599609375,14166.8896484375,14175.6904296875,14134.8701171875,14256.2900390625,14296.9697265625,14363.4501953125,14435.0302734375,14476.6904296875,14646.330078125,14720.25,14861.990234375,14837.0,15049.8603515625,15275.3798828125,15395.73046875,15421.23046875,15550.16015625,15620.9599609375,15615.1103515625,15320.9697265625,15716.6396484375,15745.48046875,15775.73046875,15973.01953125,15772.6298828125,15589.2099609375,15642.1201171875,15367.4501953125,15138.3095703125,15089.9599609375,15546.6904296875,15741.16015625,15606.740234375,15774.33984375,16197.4501953125,16323.2197265625,16211.25,16410.16015625,16211.75,16212.5302734375,16322.26953125,15953.7998046875,15946.8798828125,15884.5498046875,15840.990234375,15636.4296875,15816.5,15657.919921875,15857.3203125,15947.2099609375,16166.349609375,16194.91015625,16244.990234375,16166.349609375,16264.6103515625,16022.169921875,15983.76953125,16166.2900390625,15967.9501953125,15944.9599609375,16140.3701171875,16411.669921875,16438.400390625,16427.19921875,16496.16015625,16715.3203125,16735.779296875,16815.58984375,16793.5390625,16802.220703125,16559.5703125,16851.060546875,16998.91015625,17135.51953125,17175.01953125,17167.390625,17066.169921875,17055.48046875,17378.359375,17489.7109375,17497.740234375,17548.30078125,17222.349609375,16647.609375,16843.439453125,16764.7109375,17032.23046875,17188.150390625,16460.869140625,15165.26953125,15368.5400390625,15702.099609375,15159.8603515625,15564.9599609375,16009.759765625,15943.4501953125,16136.8603515625,16136.9697265625,16444.75,16523.23046875,16419.419921875,16690.0390625,16939.91015625,17060.44921875,17056.419921875,17198.890625,17084.490234375,16775.849609375,17056.529296875,16907.4296875,16978.009765625,17193.609375,17279.69921875,17275.01953125,17150.51953125,17318.5390625,17023.310546875,17075.55078125,17127.58984375,17319.890625,17471.0703125,17481.23046875,17541.140625,17648.25,17644.359375,17676.98046875,17783.80078125,17895.779296875,17756.8203125,17742.080078125,17597.4609375,17759.900390625,17786.759765625,17716.439453125,17878.779296875,17779.609375,17708.150390625,17500.689453125,17352.240234375,17482.810546875,17511.859375,17403.560546875,17264.5,16893.69921875,17190.48046875,17237.669921875,17231.220703125,17456.19921875,17557.1796875,17566.720703125,17469.6796875,17350.150390625,17305.060546875,17090.25,17139.2109375,16978.109375,16773.5703125,16657.630859375,16418.5390625,16375.400390625,16248.080078125,16459.130859375,16779.900390625,16821.080078125,16984.689453125,17000.259765625,17244.619140625,17207.5703125,17415.51953125,17319.759765625,17380.51953125,17461.0703125,17388.369140625,17167.080078125,17122.94921875,17270.279296875,17387.5703125,17424.5390625,17316.51953125,17254.099609375,17235.44921875,16838.580078125,16998.0703125,17130.740234375,17235.6796875,17113.470703125,16801.779296875,16767.19921875,16503.740234375,16380.0595703125,16162.169921875,16303.6298828125,16465.5703125,16605.490234375,16349.490234375,16328.4697265625,16347.8798828125,16426.759765625,16695.890625,16772.150390625,16855.810546875,16873.990234375,16800.490234375,16784.109375,16909.3203125,16973.16015625,16994.369140625,16920.6796875,17021.76953125,17026.630859375,17080.509765625,17061.4609375,17097.16015625,17279.4609375,17433.099609375,17489.869140625,17403.48046875,17479.55078125,17560.51953125,17629.80078125,17669.580078125,17748.2109375,17786.05078125,17790.640625,17650.0703125,17588.779296875,17609.509765625,17330.439453125,17167.240234375,17369.7890625,17374.58984375,17559.439453125,17670.3203125,17585.94921875,17642.3203125,17832.419921875,17807.119140625,17767.80078125,17767.599609375,17566.990234375,17556.869140625,17719.060546875,17718.26953125,17646.390625,17652.3203125,17799.720703125,17855.779296875,17953.5703125,17975.41015625,18099.7109375,18192.859375,18216.44921875,18238.470703125,18395.140625,18446.51953125,18253.8203125,18134.41015625,18043.970703125,18135.4296875,18255.380859375,18346.810546875,18213.439453125,18435.01953125,18378.640625,18199.349609375,18125.19921875,17851.390625,17682.330078125,17645.66015625,17633.029296875,17712.349609375,17955.94921875,18039.23046875,18145.0390625,18191.75,17965.220703125,17942.6796875,18109.169921875,18190.240234375,18098.51953125,18129.650390625,17840.380859375,17954.75,17561.0703125,17554.970703125,17657.5,17784.640625,17906.240234375,17710.5390625,17135.6796875,16764.779296875,16944.080078125,17224.73046875,17239.900390625,17217.580078125,16911.94921875,16808.4296875,17172.810546875,17359.5,17503.94921875,17468.55078125,17581.619140625,17603.220703125,17633.859375,17368.66015625,17493.009765625,17572.900390625,17682.529296875,17465.609375,17381.0703125,17178.630859375,17210.400390625,17046.669921875,16905.130859375,17080.400390625,17245.650390625,17004.1796875,16845.509765625,16926.33984375,16983.55078125,17106.369140625,16923.869140625,16579.890625,16582.109375,16219.41015625,16256.8798828125,16521.939453125,16465.990234375,16514.30078125,16650.810546875,16312.169921875,16048.919921875,15734.4404296875,15953.26953125,15616.6796875,15687.150390625,15847.4599609375,15915.9296875,16172.7998046875,15892.73046875,16058.2001953125,16125.4501953125,15963.6298828125,15980.900390625,15949.6103515625,16075.91015625,16368.9296875,16493.0703125,16649.91015625,16540.55078125,16509.009765625,16465.869140625,16538.669921875,16557.5390625,16403.330078125,16055.8896484375,15869.0595703125,15981.5595703125],"open":[10488.7001953125,10547.150390625,10650.48046875,10749.41015625,10817.7099609375,10734.25,10777.1796875,10661.3896484375,10674.2001953125,10786.66015625,10821.2998046875,10878.009765625,10793.099609375,10755.8701171875,10785.849609375,10742.8095703125,10729.830078125,10723.23046875,10817.599609375,10855.16015625,10819.919921875,10865.0,10861.1103515625,10821.919921875,10861.990234375,10910.5,10963.8603515625,10969.740234375,10892.25,10898.25,10872.6298828125,10909.98046875,10824.150390625,10773.0595703125,10641.2802734375,10528.8701171875,10304.8798828125,10422.8896484375,10383.6201171875,10491.7900390625,10436.6201171875,10444.5,10374.75,10345.419921875,10449.3896484375,10508.419921875,10526.8701171875,10560.009765625,10526.150390625,10453.400390625,10386.2099609375,10397.599609375,10440.150390625,10504.2802734375,10613.1904296875,10629.2197265625,10566.3203125,10718.400390625,10783.4599609375,10791.9501953125,10787.650390625,10830.25,10822.6904296875,10908.849609375,10887.419921875,10947.6201171875,10908.099609375,10924.8095703125,10917.4404296875,10885.669921875,10909.5703125,10904.0,10855.599609375,10945.919921875,10866.5,10907.6904296875,10932.240234375,10986.009765625,10976.9296875,11004.740234375,11103.5,11166.169921875,11156.1396484375,11190.2099609375,11166.240234375,11221.1904296875,11266.1796875,11266.83984375,11336.6396484375,11321.990234375,11347.3896484375,11336.9697265625,11393.6796875,11373.7001953125,11451.7197265625,11576.1796875,11645.080078125,11642.91015625,11620.8896484375,11570.330078125,11463.330078125,11483.240234375,11488.740234375,11485.4599609375,11543.7998046875,11608.48046875,11645.73046875,11573.83984375,11556.75,11590.8095703125,11608.3701171875,11590.8095703125,11641.7001953125,11616.8798828125,11509.9404296875,11473.3203125,11511.8203125,11546.75,11639.7998046875,11635.4697265625,11647.7802734375,11635.0703125,11766.98046875,11937.900390625,11915.6103515625,11939.6201171875,12061.099609375,12082.98046875,12001.5595703125,11969.1396484375,12023.7900390625,11978.9404296875,12018.3798828125,12032.7197265625,12094.8095703125,12019.1904296875,12026.5,12167.4404296875,12035.7099609375,11961.9697265625,11818.759765625,11889.4599609375,12009.26953125,12069.6103515625,12161.73046875,12169.919921875,12006.080078125,12080.7197265625,12107.5595703125,11933.23046875,11494.0302734375,11365.900390625,11399.4599609375,11601.5498046875,11605.1103515625,11712.7099609375,11514.7197265625,11614.25,11693.400390625,11813.5,11806.51953125,11770.2998046875,11700.91015625,11655.3701171875,11785.7802734375,11721.16015625,11615.2802734375,11506.740234375,11468.599609375,11436.9599609375,11184.66015625,11279.8603515625,11368.25,11454.650390625,11471.3603515625,11221.759765625,10907.6201171875,11022.8203125,10845.3896484375,10091.0302734375,10069.419921875,9538.6396484375,9453.98046875,9085.2802734375,8816.8603515625,9025.5498046875,9083.7802734375,9426.4296875,9667.1396484375,9807.900390625,9571.2197265625,9689.6201171875,9726.2001953125,9707.75,9928.16015625,10010.6396484375,10173.259765625,10105.4296875,10147.5595703125,10130.650390625,10366.76953125,10385.7802734375,10554.5498046875,10612.4501953125,10544.7998046875,10256.1103515625,10370.1298828125,10367.9697265625,10407.490234375,10580.25,10656.400390625,10826.259765625,10781.509765625,10756.9501953125,10771.08984375,10778.5302734375,10883.2197265625,10942.1796875,10974.509765625,10861.009765625,10894.169921875,10833.16015625,10753.2099609375,10812.7900390625,10892.759765625,10933.2099609375,10977.5498046875,10812.9404296875,10903.3203125,11023.9296875,11040.6201171875,10921.16015625,10971.400390625,11109.26953125,11182.51953125,11373.9404296875,11418.009765625,11539.0,11600.6103515625,11635.990234375,11738.490234375,11406.5400390625,11436.2802734375,11380.669921875,11525.5,11534.2001953125,11557.26953125,11553.91015625,11618.419921875,11647.8603515625,11608.7998046875,11563.599609375,11622.6396484375,11694.099609375,11857.900390625,11941.83984375,12176.7900390625,12086.1298828125,12222.900390625,12250.4404296875,12109.6103515625,12202.8896484375,12233.990234375,12173.0400390625,12195.7197265625,12205.25,12242.3203125,12389.759765625,12423.01953125,12467.4296875,12618.6904296875,12951.7197265625,12530.740234375,12691.8603515625,12653.4599609375,12642.73046875,12577.8798828125,12762.33984375,12894.240234375,12901.4296875,12786.7998046875,12856.4599609375,12713.6298828125,12758.8701171875,12709.9697265625,12813.9404296875,12974.9599609375,12904.83984375,12764.75,12462.51953125,12629.7802734375,12706.400390625,12768.9599609375,12888.650390625,12759.2998046875,12763.4404296875,12617.3896484375,12772.4296875,12774.9697265625,12645.919921875,12645.9296875,12637.419921875,12592.1796875,12665.740234375,12697.4599609375,12680.41015625,12787.419921875,12989.8095703125,12920.150390625,12858.599609375,12874.6103515625,12786.91015625,12656.2998046875,12487.48046875,12312.9404296875,12282.3603515625,12488.099609375,12483.650390625,12567.8798828125,12644.08984375,12667.509765625,12832.5400390625,12959.150390625,12988.4404296875,12927.08984375,12892.2900390625,12814.16015625,12803.3203125,12889.990234375,12889.8798828125,12854.9697265625,12945.1201171875,12923.5498046875,12867.76953125,12853.759765625,12687.6396484375,12651.349609375,12565.3203125,12641.2802734375,12766.8603515625,12878.009765625,12952.490234375,13053.98046875,13090.650390625,13067.0400390625,13324.8603515625,13221.7998046875,13356.740234375,13723.76953125,13628.419921875,13775.259765625,13702.58984375,13793.5498046875,13918.83984375,13860.9501953125,13763.7900390625,13833.2099609375,13917.650390625,13810.5498046875,13970.509765625,13988.490234375,14010.169921875,14230.0,14251.9404296875,14336.6904296875,14295.150390625,14298.58984375,14238.919921875,14206.330078125,14145.240234375,14326.16015625,14268.1298828125,14273.7900390625,14348.1103515625,14180.7001953125,14256.2900390625,14306.98046875,14363.4501953125,14500.91015625,14485.9697265625,14704.5302734375,14720.25,14913.6396484375,15145.849609375,15059.51953125,15365.1298828125,15425.580078125,15549.5302734375,15550.16015625,15651.2001953125,15987.16015625,15676.4501953125,15716.6396484375,15934.849609375,15775.73046875,15984.8896484375,16006.2099609375,15955.16015625,15711.759765625,15519.849609375,15544.3603515625,15176.5595703125,15546.6904296875,15828.6396484375,15697.75,15805.759765625,16197.4501953125,16366.23046875,16376.91015625,16445.869140625,16320.8798828125,16329.5400390625,16376.7998046875,16190.0400390625,16127.8701171875,15992.3203125,16091.75,15759.580078125,15943.3701171875,15715.0703125,15921.4501953125,15947.2099609375,16241.5498046875,16256.580078125,16253.9296875,16312.98046875,16264.6103515625,16186.4599609375,16065.5,16250.2001953125,15994.9599609375,16010.5400390625,16140.3701171875,16411.669921875,16490.310546875,16529.23046875,16538.279296875,16771.349609375,16786.560546875,16974.279296875,16908.55078125,16872.400390625,16869.779296875,16851.060546875,17028.349609375,17141.25,17231.580078125,17282.759765625,17302.73046875,17117.490234375,17378.359375,17586.01953125,17610.720703125,17646.9296875,17505.51953125,17249.560546875,16968.75,16925.51953125,17032.23046875,17274.23046875,17137.189453125,16515.880859375,15668.330078125,15819.240234375,15554.990234375,15564.9599609375,16112.2099609375,16122.51953125,16136.8603515625,16246.51953125,16444.75,16645.169921875,16591.69921875,16690.0390625,16948.470703125,17098.490234375,17192.91015625,17201.30078125,17225.060546875,17176.08984375,17094.33984375,17082.51953125,17024.5390625,17200.44921875,17279.69921875,17357.369140625,17254.83984375,17384.740234375,17305.490234375,17162.7109375,17127.58984375,17358.5703125,17471.0703125,17531.8203125,17621.150390625,17648.25,17801.189453125,17745.689453125,17783.80078125,17929.220703125,17901.25,17880.900390625,17778.119140625,17843.30078125,17931.470703125,17892.509765625,17878.779296875,17839.580078125,17854.349609375,17724.919921875,17593.599609375,17482.810546875,17603.94921875,17554.9296875,17394.76953125,17252.869140625,17216.580078125,17414.76953125,17256.609375,17489.119140625,17588.640625,17624.8203125,17593.849609375,17505.009765625,17492.44921875,17308.619140625,17221.349609375,17216.33984375,16941.330078125,16841.619140625,16630.990234375,16777.779296875,16426.98046875,16459.130859375,16830.630859375,16821.080078125,17177.390625,17061.099609375,17244.619140625,17384.609375,17463.80078125,17455.919921875,17380.51953125,17534.05078125,17534.380859375,17411.529296875,17175.0390625,17270.279296875,17452.16015625,17463.779296875,17434.01953125,17332.33984375,17279.2890625,17196.7890625,16998.0703125,17130.740234375,17278.109375,17286.890625,17127.859375,16886.5703125,16883.0,16600.51953125,16362.26953125,16488.2109375,16465.5703125,16742.349609375,16589.720703125,16480.98046875,16392.509765625,16426.759765625,16816.939453125,16791.119140625,16936.19921875,16904.4609375,16900.3203125,16879.33984375,16909.3203125,17037.369140625,17081.169921875,17058.0390625,17021.76953125,17094.419921875,17087.890625,17158.279296875,17097.16015625,17323.390625,17433.099609375,17549.08984375,17527.1796875,17479.55078125,17560.51953125,17639.9609375,17705.2890625,17767.060546875,17864.189453125,17828.529296875,17797.900390625,17680.16015625,17686.119140625,17641.7890625,17320.009765625,17369.7890625,17428.609375,17575.91015625,17720.9296875,17650.669921875,17734.189453125,17845.060546875,17880.41015625,17893.2890625,17841.029296875,17754.380859375,17592.869140625,17719.060546875,17744.5390625,17812.810546875,17686.83984375,17805.740234375,17855.779296875,17966.349609375,17975.41015625,18099.7109375,18209.140625,18270.0,18260.23046875,18395.140625,18598.130859375,18395.720703125,18388.16015625,18095.390625,18266.5390625,18348.390625,18356.2109375,18509.0,18512.150390625,18492.810546875,18275.1796875,18212.259765625,18113.939453125,17843.330078125,17890.7109375,17657.970703125,17750.69921875,17955.94921875,18060.330078125,18217.2890625,18258.810546875,18182.73046875,17978.439453125,18109.169921875,18213.30078125,18250.369140625,18196.400390625,18159.509765625,17954.75,17939.529296875,17617.359375,17657.5,17864.109375,17932.150390625,17845.009765625,17581.5703125,17000.0,16944.080078125,17224.73046875,17373.8203125,17287.900390625,17177.26953125,17007.580078125,17172.810546875,17439.91015625,17503.94921875,17512.41015625,17581.619140625,17711.169921875,17695.80078125,17510.150390625,17568.3203125,17572.900390625,17754.099609375,17657.759765625,17484.189453125,17430.130859375,17210.400390625,17273.05078125,17005.83984375,17080.400390625,17353.25,17139.33984375,16958.66015625,16926.33984375,17057.130859375,17159.880859375,17088.759765625,16912.30078125,16677.83984375,16427.3203125,16350.7197265625,16599.83984375,16593.2109375,16531.369140625,16689.98046875,16491.109375,16345.83984375,15891.400390625,16053.75,15943.6201171875,15687.150390625,15943.6904296875,15915.9296875,16174.7802734375,16111.490234375,16061.919921875,16193.919921875,16166.5703125,15987.740234375,16128.2099609375,16075.91015625,16368.9296875,16561.6796875,16718.91015625,16605.4609375,16570.890625,16593.75,16538.669921875,16643.94921875,16581.810546875,16295.0703125,15975.169921875,16025.83984375],"x":["2019-06-17T00:00:00","2019-06-18T00:00:00","2019-06-19T00:00:00","2019-06-20T00:00:00","2019-06-21T00:00:00","2019-06-24T00:00:00","2019-06-25T00:00:00","2019-06-26T00:00:00","2019-06-27T00:00:00","2019-06-28T00:00:00","2019-07-01T00:00:00","2019-07-02T00:00:00","2019-07-03T00:00:00","2019-07-04T00:00:00","2019-07-05T00:00:00","2019-07-08T00:00:00","2019-07-09T00:00:00","2019-07-10T00:00:00","2019-07-11T00:00:00","2019-07-12T00:00:00","2019-07-15T00:00:00","2019-07-16T00:00:00","2019-07-17T00:00:00","2019-07-18T00:00:00","2019-07-19T00:00:00","2019-07-22T00:00:00","2019-07-23T00:00:00","2019-07-24T00:00:00","2019-07-25T00:00:00","2019-07-26T00:00:00","2019-07-29T00:00:00","2019-07-30T00:00:00","2019-07-31T00:00:00","2019-08-01T00:00:00","2019-08-02T00:00:00","2019-08-05T00:00:00","2019-08-06T00:00:00","2019-08-07T00:00:00","2019-08-08T00:00:00","2019-08-12T00:00:00","2019-08-13T00:00:00","2019-08-14T00:00:00","2019-08-15T00:00:00","2019-08-16T00:00:00","2019-08-19T00:00:00","2019-08-20T00:00:00","2019-08-21T00:00:00","2019-08-22T00:00:00","2019-08-23T00:00:00","2019-08-26T00:00:00","2019-08-27T00:00:00","2019-08-28T00:00:00","2019-08-29T00:00:00","2019-08-30T00:00:00","2019-09-02T00:00:00","2019-09-03T00:00:00","2019-09-04T00:00:00","2019-09-05T00:00:00","2019-09-06T00:00:00","2019-09-10T00:00:00","2019-09-11T00:00:00","2019-09-12T00:00:00","2019-09-16T00:00:00","2019-09-17T00:00:00","2019-09-18T00:00:00","2019-09-19T00:00:00","2019-09-20T00:00:00","2019-09-23T00:00:00","2019-09-24T00:00:00","2019-09-25T00:00:00","2019-09-26T00:00:00","2019-09-27T00:00:00","2019-10-01T00:00:00","2019-10-02T00:00:00","2019-10-03T00:00:00","2019-10-04T00:00:00","2019-10-07T00:00:00","2019-10-08T00:00:00","2019-10-09T00:00:00","2019-10-14T00:00:00","2019-10-15T00:00:00","2019-10-16T00:00:00","2019-10-17T00:00:00","2019-10-18T00:00:00","2019-10-21T00:00:00","2019-10-22T00:00:00","2019-10-23T00:00:00","2019-10-24T00:00:00","2019-10-25T00:00:00","2019-10-28T00:00:00","2019-10-29T00:00:00","2019-10-30T00:00:00","2019-10-31T00:00:00","2019-11-01T00:00:00","2019-11-04T00:00:00","2019-11-05T00:00:00","2019-11-06T00:00:00","2019-11-07T00:00:00","2019-11-08T00:00:00","2019-11-11T00:00:00","2019-11-12T00:00:00","2019-11-13T00:00:00","2019-11-14T00:00:00","2019-11-15T00:00:00","2019-11-18T00:00:00","2019-11-19T00:00:00","2019-11-20T00:00:00","2019-11-21T00:00:00","2019-11-22T00:00:00","2019-11-25T00:00:00","2019-11-26T00:00:00","2019-11-27T00:00:00","2019-11-28T00:00:00","2019-11-29T00:00:00","2019-12-02T00:00:00","2019-12-03T00:00:00","2019-12-04T00:00:00","2019-12-05T00:00:00","2019-12-06T00:00:00","2019-12-09T00:00:00","2019-12-10T00:00:00","2019-12-11T00:00:00","2019-12-12T00:00:00","2019-12-13T00:00:00","2019-12-16T00:00:00","2019-12-17T00:00:00","2019-12-18T00:00:00","2019-12-19T00:00:00","2019-12-20T00:00:00","2019-12-23T00:00:00","2019-12-24T00:00:00","2019-12-25T00:00:00","2019-12-26T00:00:00","2019-12-27T00:00:00","2019-12-30T00:00:00","2019-12-31T00:00:00","2020-01-02T00:00:00","2020-01-03T00:00:00","2020-01-06T00:00:00","2020-01-07T00:00:00","2020-01-08T00:00:00","2020-01-09T00:00:00","2020-01-10T00:00:00","2020-01-13T00:00:00","2020-01-14T00:00:00","2020-01-15T00:00:00","2020-01-16T00:00:00","2020-01-17T00:00:00","2020-01-20T00:00:00","2020-01-30T00:00:00","2020-01-31T00:00:00","2020-02-03T00:00:00","2020-02-04T00:00:00","2020-02-05T00:00:00","2020-02-06T00:00:00","2020-02-07T00:00:00","2020-02-10T00:00:00","2020-02-11T00:00:00","2020-02-12T00:00:00","2020-02-13T00:00:00","2020-02-14T00:00:00","2020-02-17T00:00:00","2020-02-18T00:00:00","2020-02-19T00:00:00","2020-02-20T00:00:00","2020-02-21T00:00:00","2020-02-24T00:00:00","2020-02-25T00:00:00","2020-02-26T00:00:00","2020-02-27T00:00:00","2020-03-02T00:00:00","2020-03-03T00:00:00","2020-03-04T00:00:00","2020-03-05T00:00:00","2020-03-06T00:00:00","2020-03-09T00:00:00","2020-03-10T00:00:00","2020-03-11T00:00:00","2020-03-12T00:00:00","2020-03-13T00:00:00","2020-03-16T00:00:00","2020-03-17T00:00:00","2020-03-18T00:00:00","2020-03-19T00:00:00","2020-03-20T00:00:00","2020-03-23T00:00:00","2020-03-24T00:00:00","2020-03-25T00:00:00","2020-03-26T00:00:00","2020-03-27T00:00:00","2020-03-30T00:00:00","2020-03-31T00:00:00","2020-04-01T00:00:00","2020-04-06T00:00:00","2020-04-07T00:00:00","2020-04-08T00:00:00","2020-04-09T00:00:00","2020-04-10T00:00:00","2020-04-13T00:00:00","2020-04-14T00:00:00","2020-04-15T00:00:00","2020-04-16T00:00:00","2020-04-17T00:00:00","2020-04-20T00:00:00","2020-04-21T00:00:00","2020-04-22T00:00:00","2020-04-23T00:00:00","2020-04-24T00:00:00","2020-04-27T00:00:00","2020-04-28T00:00:00","2020-04-29T00:00:00","2020-04-30T00:00:00","2020-05-04T00:00:00","2020-05-05T00:00:00","2020-05-06T00:00:00","2020-05-07T00:00:00","2020-05-08T00:00:00","2020-05-11T00:00:00","2020-05-12T00:00:00","2020-05-13T00:00:00","2020-05-14T00:00:00","2020-05-15T00:00:00","2020-05-18T00:00:00","2020-05-19T00:00:00","2020-05-20T00:00:00","2020-05-21T00:00:00","2020-05-22T00:00:00","2020-05-25T00:00:00","2020-05-26T00:00:00","2020-05-27T00:00:00","2020-05-28T00:00:00","2020-05-29T00:00:00","2020-06-01T00:00:00","2020-06-02T00:00:00","2020-06-03T00:00:00","2020-06-04T00:00:00","2020-06-05T00:00:00","2020-06-08T00:00:00","2020-06-09T00:00:00","2020-06-10T00:00:00","2020-06-11T00:00:00","2020-06-12T00:00:00","2020-06-15T00:00:00","2020-06-16T00:00:00","2020-06-17T00:00:00","2020-06-18T00:00:00","2020-06-19T00:00:00","2020-06-22T00:00:00","2020-06-23T00:00:00","2020-06-24T00:00:00","2020-06-29T00:00:00","2020-06-30T00:00:00","2020-07-01T00:00:00","2020-07-02T00:00:00","2020-07-03T00:00:00","2020-07-06T00:00:00","2020-07-07T00:00:00","2020-07-08T00:00:00","2020-07-09T00:00:00","2020-07-10T00:00:00","2020-07-13T00:00:00","2020-07-14T00:00:00","2020-07-15T00:00:00","2020-07-16T00:00:00","2020-07-17T00:00:00","2020-07-20T00:00:00","2020-07-21T00:00:00","2020-07-22T00:00:00","2020-07-23T00:00:00","2020-07-24T00:00:00","2020-07-27T00:00:00","2020-07-28T00:00:00","2020-07-29T00:00:00","2020-07-30T00:00:00","2020-07-31T00:00:00","2020-08-03T00:00:00","2020-08-04T00:00:00","2020-08-05T00:00:00","2020-08-06T00:00:00","2020-08-07T00:00:00","2020-08-10T00:00:00","2020-08-11T00:00:00","2020-08-12T00:00:00","2020-08-13T00:00:00","2020-08-14T00:00:00","2020-08-17T00:00:00","2020-08-18T00:00:00","2020-08-19T00:00:00","2020-08-20T00:00:00","2020-08-21T00:00:00","2020-08-24T00:00:00","2020-08-25T00:00:00","2020-08-26T00:00:00","2020-08-27T00:00:00","2020-08-28T00:00:00","2020-08-31T00:00:00","2020-09-01T00:00:00","2020-09-02T00:00:00","2020-09-03T00:00:00","2020-09-04T00:00:00","2020-09-07T00:00:00","2020-09-08T00:00:00","2020-09-09T00:00:00","2020-09-10T00:00:00","2020-09-11T00:00:00","2020-09-14T00:00:00","2020-09-15T00:00:00","2020-09-16T00:00:00","2020-09-17T00:00:00","2020-09-18T00:00:00","2020-09-21T00:00:00","2020-09-22T00:00:00","2020-09-23T00:00:00","2020-09-24T00:00:00","2020-09-25T00:00:00","2020-09-28T00:00:00","2020-09-29T00:00:00","2020-09-30T00:00:00","2020-10-05T00:00:00","2020-10-06T00:00:00","2020-10-07T00:00:00","2020-10-08T00:00:00","2020-10-12T00:00:00","2020-10-13T00:00:00","2020-10-14T00:00:00","2020-10-15T00:00:00","2020-10-16T00:00:00","2020-10-19T00:00:00","2020-10-20T00:00:00","2020-10-21T00:00:00","2020-10-22T00:00:00","2020-10-23T00:00:00","2020-10-26T00:00:00","2020-10-27T00:00:00","2020-10-28T00:00:00","2020-10-29T00:00:00","2020-10-30T00:00:00","2020-11-02T00:00:00","2020-11-03T00:00:00","2020-11-04T00:00:00","2020-11-05T00:00:00","2020-11-06T00:00:00","2020-11-09T00:00:00","2020-11-10T00:00:00","2020-11-11T00:00:00","2020-11-12T00:00:00","2020-11-13T00:00:00","2020-11-16T00:00:00","2020-11-17T00:00:00","2020-11-18T00:00:00","2020-11-19T00:00:00","2020-11-20T00:00:00","2020-11-23T00:00:00","2020-11-24T00:00:00","2020-11-25T00:00:00","2020-11-26T00:00:00","2020-11-27T00:00:00","2020-11-30T00:00:00","2020-12-01T00:00:00","2020-12-02T00:00:00","2020-12-03T00:00:00","2020-12-04T00:00:00","2020-12-07T00:00:00","2020-12-08T00:00:00","2020-12-09T00:00:00","2020-12-10T00:00:00","2020-12-11T00:00:00","2020-12-14T00:00:00","2020-12-15T00:00:00","2020-12-16T00:00:00","2020-12-17T00:00:00","2020-12-18T00:00:00","2020-12-21T00:00:00","2020-12-22T00:00:00","2020-12-23T00:00:00","2020-12-24T00:00:00","2020-12-25T00:00:00","2020-12-28T00:00:00","2020-12-29T00:00:00","2020-12-30T00:00:00","2020-12-31T00:00:00","2021-01-04T00:00:00","2021-01-05T00:00:00","2021-01-06T00:00:00","2021-01-07T00:00:00","2021-01-08T00:00:00","2021-01-11T00:00:00","2021-01-12T00:00:00","2021-01-13T00:00:00","2021-01-14T00:00:00","2021-01-15T00:00:00","2021-01-18T00:00:00","2021-01-19T00:00:00","2021-01-20T00:00:00","2021-01-21T00:00:00","2021-01-22T00:00:00","2021-01-25T00:00:00","2021-01-26T00:00:00","2021-01-27T00:00:00","2021-01-28T00:00:00","2021-01-29T00:00:00","2021-02-01T00:00:00","2021-02-02T00:00:00","2021-02-03T00:00:00","2021-02-04T00:00:00","2021-02-05T00:00:00","2021-02-17T00:00:00","2021-02-18T00:00:00","2021-02-19T00:00:00","2021-02-22T00:00:00","2021-02-23T00:00:00","2021-02-24T00:00:00","2021-02-25T00:00:00","2021-02-26T00:00:00","2021-03-02T00:00:00","2021-03-03T00:00:00","2021-03-04T00:00:00","2021-03-05T00:00:00","2021-03-08T00:00:00","2021-03-09T00:00:00","2021-03-10T00:00:00","2021-03-11T00:00:00","2021-03-12T00:00:00","2021-03-15T00:00:00","2021-03-16T00:00:00","2021-03-17T00:00:00","2021-03-18T00:00:00","2021-03-19T00:00:00","2021-03-22T00:00:00","2021-03-23T00:00:00","2021-03-24T00:00:00","2021-03-25T00:00:00","2021-03-26T00:00:00","2021-03-29T00:00:00","2021-03-30T00:00:00","2021-03-31T00:00:00","2021-04-01T00:00:00","2021-04-07T00:00:00","2021-04-08T00:00:00","2021-04-09T00:00:00","2021-04-12T00:00:00","2021-04-13T00:00:00","2021-04-14T00:00:00","2021-04-15T00:00:00","2021-04-16T00:00:00","2021-04-19T00:00:00","2021-04-20T00:00:00","2021-04-21T00:00:00","2021-04-22T00:00:00","2021-04-23T00:00:00","2021-04-26T00:00:00","2021-04-27T00:00:00","2021-04-28T00:00:00","2021-04-29T00:00:00","2021-05-03T00:00:00","2021-05-04T00:00:00","2021-05-05T00:00:00","2021-05-06T00:00:00","2021-05-07T00:00:00","2021-05-10T00:00:00","2021-05-11T00:00:00","2021-05-12T00:00:00","2021-05-13T00:00:00","2021-05-14T00:00:00","2021-05-17T00:00:00","2021-05-18T00:00:00","2021-05-19T00:00:00","2021-05-20T00:00:00","2021-05-21T00:00:00","2021-05-24T00:00:00","2021-05-25T00:00:00","2021-05-26T00:00:00","2021-05-27T00:00:00","2021-05-28T00:00:00","2021-05-31T00:00:00","2021-06-01T00:00:00","2021-06-02T00:00:00","2021-06-03T00:00:00","2021-06-04T00:00:00","2021-06-07T00:00:00","2021-06-08T00:00:00","2021-06-09T00:00:00","2021-06-10T00:00:00","2021-06-11T00:00:00","2021-06-15T00:00:00","2021-06-16T00:00:00","2021-06-17T00:00:00","2021-06-18T00:00:00","2021-06-21T00:00:00","2021-06-22T00:00:00","2021-06-23T00:00:00","2021-06-24T00:00:00","2021-06-25T00:00:00","2021-06-28T00:00:00","2021-06-29T00:00:00","2021-06-30T00:00:00","2021-07-01T00:00:00","2021-07-02T00:00:00","2021-07-05T00:00:00","2021-07-06T00:00:00","2021-07-07T00:00:00","2021-07-08T00:00:00","2021-07-09T00:00:00","2021-07-12T00:00:00","2021-07-13T00:00:00","2021-07-14T00:00:00","2021-07-15T00:00:00","2021-07-16T00:00:00","2021-07-19T00:00:00","2021-07-20T00:00:00","2021-07-21T00:00:00","2021-07-22T00:00:00","2021-07-23T00:00:00","2021-07-26T00:00:00","2021-07-27T00:00:00","2021-07-28T00:00:00","2021-07-29T00:00:00","2021-07-30T00:00:00","2021-08-02T00:00:00","2021-08-03T00:00:00","2021-08-04T00:00:00","2021-08-05T00:00:00","2021-08-06T00:00:00","2021-08-09T00:00:00","2021-08-10T00:00:00","2021-08-11T00:00:00","2021-08-12T00:00:00","2021-08-13T00:00:00","2021-08-16T00:00:00","2021-08-17T00:00:00","2021-08-18T00:00:00","2021-08-19T00:00:00","2021-08-20T00:00:00","2021-08-23T00:00:00","2021-08-24T00:00:00","2021-08-25T00:00:00","2021-08-26T00:00:00","2021-08-27T00:00:00","2021-08-30T00:00:00","2021-08-31T00:00:00","2021-09-01T00:00:00","2021-09-02T00:00:00","2021-09-03T00:00:00","2021-09-06T00:00:00","2021-09-07T00:00:00","2021-09-08T00:00:00","2021-09-09T00:00:00","2021-09-10T00:00:00","2021-09-13T00:00:00","2021-09-14T00:00:00","2021-09-15T00:00:00","2021-09-16T00:00:00","2021-09-17T00:00:00","2021-09-22T00:00:00","2021-09-23T00:00:00","2021-09-24T00:00:00","2021-09-27T00:00:00","2021-09-28T00:00:00","2021-09-29T00:00:00","2021-09-30T00:00:00","2021-10-01T00:00:00","2021-10-04T00:00:00","2021-10-05T00:00:00","2021-10-06T00:00:00","2021-10-07T00:00:00","2021-10-08T00:00:00","2021-10-12T00:00:00","2021-10-13T00:00:00","2021-10-14T00:00:00","2021-10-15T00:00:00","2021-10-18T00:00:00","2021-10-19T00:00:00","2021-10-20T00:00:00","2021-10-21T00:00:00","2021-10-22T00:00:00","2021-10-25T00:00:00","2021-10-26T00:00:00","2021-10-27T00:00:00","2021-10-28T00:00:00","2021-10-29T00:00:00","2021-11-01T00:00:00","2021-11-02T00:00:00","2021-11-03T00:00:00","2021-11-04T00:00:00","2021-11-05T00:00:00","2021-11-08T00:00:00","2021-11-09T00:00:00","2021-11-10T00:00:00","2021-11-11T00:00:00","2021-11-12T00:00:00","2021-11-15T00:00:00","2021-11-16T00:00:00","2021-11-17T00:00:00","2021-11-18T00:00:00","2021-11-19T00:00:00","2021-11-22T00:00:00","2021-11-23T00:00:00","2021-11-24T00:00:00","2021-11-25T00:00:00","2021-11-26T00:00:00","2021-11-29T00:00:00","2021-11-30T00:00:00","2021-12-01T00:00:00","2021-12-02T00:00:00","2021-12-03T00:00:00","2021-12-06T00:00:00","2021-12-07T00:00:00","2021-12-08T00:00:00","2021-12-09T00:00:00","2021-12-10T00:00:00","2021-12-13T00:00:00","2021-12-14T00:00:00","2021-12-15T00:00:00","2021-12-16T00:00:00","2021-12-17T00:00:00","2021-12-20T00:00:00","2021-12-21T00:00:00","2021-12-22T00:00:00","2021-12-23T00:00:00","2021-12-24T00:00:00","2021-12-27T00:00:00","2021-12-28T00:00:00","2021-12-29T00:00:00","2021-12-30T00:00:00","2022-01-03T00:00:00","2022-01-04T00:00:00","2022-01-05T00:00:00","2022-01-06T00:00:00","2022-01-07T00:00:00","2022-01-10T00:00:00","2022-01-11T00:00:00","2022-01-12T00:00:00","2022-01-13T00:00:00","2022-01-14T00:00:00","2022-01-17T00:00:00","2022-01-18T00:00:00","2022-01-19T00:00:00","2022-01-20T00:00:00","2022-01-21T00:00:00","2022-01-24T00:00:00","2022-01-25T00:00:00","2022-01-26T00:00:00","2022-02-07T00:00:00","2022-02-08T00:00:00","2022-02-09T00:00:00","2022-02-10T00:00:00","2022-02-11T00:00:00","2022-02-14T00:00:00","2022-02-15T00:00:00","2022-02-16T00:00:00","2022-02-17T00:00:00","2022-02-18T00:00:00","2022-02-21T00:00:00","2022-02-22T00:00:00","2022-02-23T00:00:00","2022-02-24T00:00:00","2022-02-25T00:00:00","2022-03-01T00:00:00","2022-03-02T00:00:00","2022-03-03T00:00:00","2022-03-04T00:00:00","2022-03-07T00:00:00","2022-03-08T00:00:00","2022-03-09T00:00:00","2022-03-10T00:00:00","2022-03-11T00:00:00","2022-03-14T00:00:00","2022-03-15T00:00:00","2022-03-16T00:00:00","2022-03-17T00:00:00","2022-03-18T00:00:00","2022-03-21T00:00:00","2022-03-22T00:00:00","2022-03-23T00:00:00","2022-03-24T00:00:00","2022-03-25T00:00:00","2022-03-28T00:00:00","2022-03-29T00:00:00","2022-03-30T00:00:00","2022-03-31T00:00:00","2022-04-01T00:00:00","2022-04-06T00:00:00","2022-04-07T00:00:00","2022-04-08T00:00:00","2022-04-11T00:00:00","2022-04-12T00:00:00","2022-04-13T00:00:00","2022-04-14T00:00:00","2022-04-15T00:00:00","2022-04-18T00:00:00","2022-04-19T00:00:00","2022-04-20T00:00:00","2022-04-21T00:00:00","2022-04-22T00:00:00","2022-04-25T00:00:00","2022-04-26T00:00:00","2022-04-27T00:00:00","2022-04-28T00:00:00","2022-04-29T00:00:00","2022-05-03T00:00:00","2022-05-04T00:00:00","2022-05-05T00:00:00","2022-05-06T00:00:00","2022-05-09T00:00:00","2022-05-10T00:00:00","2022-05-11T00:00:00","2022-05-12T00:00:00","2022-05-13T00:00:00","2022-05-16T00:00:00","2022-05-17T00:00:00","2022-05-18T00:00:00","2022-05-19T00:00:00","2022-05-20T00:00:00","2022-05-23T00:00:00","2022-05-24T00:00:00","2022-05-25T00:00:00","2022-05-26T00:00:00","2022-05-27T00:00:00","2022-05-30T00:00:00","2022-05-31T00:00:00","2022-06-01T00:00:00","2022-06-02T00:00:00","2022-06-06T00:00:00","2022-06-07T00:00:00","2022-06-08T00:00:00","2022-06-09T00:00:00","2022-06-10T00:00:00","2022-06-13T00:00:00","2022-06-14T00:00:00","2022-06-15T00:00:00"],"type":"candlestick"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"rangeslider":{"visible":false}},"title":{"text":"\u53f0\u7063\u52a0\u6b0a\u6307\u6578\u8d70\u52e2"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('1c55714d-cc2a-43c4-a332-0d6afcdcc557');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>分析時間序列數據的最佳方法之一是創建互動式圖表，您可以在其中手動選擇輸出圖表本身的時間間隔。
一種方法是在圖表下方添加一個滑動區塊，並在圖表上方添加按鈕來控制時間的間隔。 以下是創建互動式K線圖表的方法，您可以在其中選擇輸出本身的時間間隔：</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">figure</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">go</span><span class="o">.</span><span class="n">Candlestick</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                                          <span class="nb">open</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;Open&quot;</span><span class="p">],</span>
                                          <span class="n">high</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;High&quot;</span><span class="p">],</span>
                                          <span class="n">low</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;Low&quot;</span><span class="p">],</span>
                                          <span class="n">close</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">])])</span>
<span class="n">figure</span><span class="o">.</span><span class="n">update_layout</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;台灣加權指數走勢 (互動式圖表)&quot;</span><span class="p">)</span>

<span class="n">figure</span><span class="o">.</span><span class="n">update_xaxes</span><span class="p">(</span>
    <span class="n">rangeslider_visible</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">rangeselector</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">buttons</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;1m&quot;</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="s2">&quot;month&quot;</span><span class="p">,</span> <span class="n">stepmode</span> <span class="o">=</span> <span class="s2">&quot;backward&quot;</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;6m&quot;</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="s2">&quot;month&quot;</span><span class="p">,</span> <span class="n">stepmode</span> <span class="o">=</span> <span class="s2">&quot;backward&quot;</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;YTD&quot;</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="n">stepmode</span> <span class="o">=</span> <span class="s2">&quot;todate&quot;</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">count</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;1y&quot;</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="n">stepmode</span> <span class="o">=</span> <span class="s2">&quot;backward&quot;</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">step</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span><span class="p">)</span>
        <span class="p">])</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">figure</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>                            <div id="9f4ab9e9-0ce6-4d49-a558-ab173beb8646" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("9f4ab9e9-0ce6-4d49-a558-ab173beb8646")) {                    Plotly.newPlot(                        "9f4ab9e9-0ce6-4d49-a558-ab173beb8646",                        [{"close":[10530.5400390625,10566.740234375,10775.33984375,10785.009765625,10803.76953125,10779.4501953125,10706.7197265625,10652.5498046875,10773.900390625,10730.830078125,10895.4599609375,10865.1201171875,10743.76953125,10775.900390625,10785.73046875,10751.2197265625,10702.7802734375,10798.48046875,10843.419921875,10824.349609375,10876.4296875,10886.0498046875,10828.48046875,10799.2802734375,10873.1904296875,10944.5302734375,10947.259765625,10935.759765625,10941.41015625,10891.98046875,10885.73046875,10830.900390625,10823.8095703125,10731.75,10549.0400390625,10423.41015625,10394.75,10386.1796875,10494.490234375,10472.3603515625,10362.66015625,10427.73046875,10327.1298828125,10420.8896484375,10488.75,10522.5,10525.7998046875,10529.7802734375,10538.1103515625,10354.5703125,10387.23046875,10434.2900390625,10462.4296875,10618.0498046875,10634.849609375,10558.2099609375,10657.3095703125,10756.9296875,10780.6396484375,10753.580078125,10790.349609375,10827.5498046875,10898.1298828125,10874.5,10929.4501953125,10894.7001953125,10929.6904296875,10919.01953125,10918.009765625,10873.6904296875,10871.990234375,10829.6796875,10967.650390625,10947.8798828125,10875.91015625,10894.48046875,10935.0595703125,11017.3095703125,10889.9599609375,11066.9501953125,11111.7998046875,11162.830078125,11186.8798828125,11180.2197265625,11184.150390625,11271.25,11239.669921875,11320.1396484375,11296.1201171875,11315.01953125,11333.8701171875,11380.2802734375,11358.7099609375,11399.5302734375,11556.849609375,11644.0302734375,11653.0703125,11606.5595703125,11579.5400390625,11427.2802734375,11520.3701171875,11467.830078125,11450.419921875,11525.599609375,11599.7802734375,11656.400390625,11631.2001953125,11558.26953125,11566.7998046875,11561.580078125,11576.8203125,11647.4599609375,11617.080078125,11489.5703125,11502.830078125,11531.580078125,11510.4697265625,11594.650390625,11609.6396484375,11660.76953125,11627.83984375,11700.76953125,11836.419921875,11927.73046875,11939.76953125,12097.009765625,12122.4501953125,12018.900390625,11959.080078125,12022.23046875,11976.3798828125,12008.1298828125,12001.009765625,12091.58984375,12053.3701171875,11997.1396484375,12100.48046875,12110.4296875,11953.3603515625,11880.3203125,11817.099609375,11970.6298828125,12024.650390625,12113.419921875,12179.8095703125,12091.8798828125,12066.9296875,12090.2900390625,12118.7099609375,11421.740234375,11495.099609375,11354.919921875,11555.919921875,11573.6201171875,11749.6796875,11612.8095703125,11574.0703125,11664.0400390625,11774.1904296875,11791.7802734375,11815.7001953125,11763.509765625,11648.98046875,11758.83984375,11725.08984375,11686.349609375,11534.8701171875,11540.23046875,11433.6201171875,11292.169921875,11170.4599609375,11327.7197265625,11392.349609375,11514.8203125,11321.8095703125,10977.6396484375,11003.5400390625,10893.75,10422.3203125,10128.8701171875,9717.76953125,9439.6298828125,9218.669921875,8681.33984375,9234.08984375,8890.0302734375,9285.6201171875,9644.75,9736.3603515625,9698.919921875,9629.4296875,9708.0595703125,9663.6298828125,9818.740234375,9996.3896484375,10137.4697265625,10119.4296875,10157.6103515625,10099.2197265625,10332.9404296875,10447.2099609375,10375.48046875,10597.0400390625,10586.7099609375,10288.419921875,10307.740234375,10366.509765625,10347.3603515625,10567.26953125,10616.0595703125,10772.2197265625,10992.1396484375,10720.48046875,10774.6103515625,10774.98046875,10842.919921875,10901.419921875,11013.259765625,10879.4697265625,10938.26953125,10780.8798828125,10814.919921875,10740.5498046875,10860.4404296875,10907.7998046875,11008.3095703125,10811.150390625,10871.1796875,10997.2099609375,11014.66015625,10944.1904296875,10942.16015625,11079.01953125,11127.9296875,11320.16015625,11393.23046875,11479.400390625,11610.3203125,11637.1103515625,11720.16015625,11535.76953125,11429.9404296875,11306.259765625,11511.6396484375,11534.58984375,11548.330078125,11549.8603515625,11572.9296875,11612.3603515625,11660.669921875,11542.6201171875,11621.240234375,11703.419921875,11805.1396484375,11909.16015625,12116.7001953125,12092.9697265625,12170.1904296875,12192.6904296875,12073.6796875,12211.5595703125,12209.009765625,12202.849609375,12157.740234375,12181.5595703125,12174.5400390625,12397.5498046875,12473.26953125,12413.0400390625,12304.0400390625,12588.2998046875,12586.73046875,12540.9697265625,12722.919921875,12664.7998046875,12513.0302734375,12709.919921875,12802.2998046875,12913.5,12828.8701171875,12894.0,12780.1904296875,12670.349609375,12763.1298828125,12795.4599609375,12956.1103515625,12872.1396484375,12778.6396484375,12362.6396484375,12607.83984375,12647.1298828125,12758.25,12833.2900390625,12797.3095703125,12728.849609375,12591.4501953125,12703.2802734375,12699.5,12757.9697265625,12637.9501953125,12601.400390625,12663.5595703125,12608.580078125,12691.75,12675.9501953125,12787.8203125,12845.650390625,12976.759765625,12872.740234375,12875.6201171875,12795.1201171875,12645.509765625,12583.8798828125,12264.3798828125,12232.91015625,12462.759765625,12467.73046875,12515.6103515625,12548.2802734375,12704.23046875,12746.3701171875,12887.1904296875,12955.91015625,12947.1298828125,12919.3095703125,12827.8203125,12750.3701171875,12908.33984375,12862.3701171875,12877.25,12917.0302734375,12898.8203125,12909.0302734375,12875.009765625,12793.75,12662.91015625,12546.33984375,12591.3095703125,12736.009765625,12867.900390625,12918.7998046875,12973.5302734375,13127.4697265625,13081.7197265625,13262.1904296875,13221.7802734375,13273.330078125,13551.830078125,13593.009765625,13773.2900390625,13722.4296875,13716.4404296875,13878.009765625,13807.1298828125,13738.830078125,13845.66015625,13867.08984375,13722.8896484375,13885.669921875,13989.1396484375,13977.08984375,14132.4404296875,14256.599609375,14360.400390625,14390.1396484375,14249.490234375,14261.6904296875,14211.0498046875,14068.51953125,14304.4599609375,14258.9296875,14249.9599609375,14384.9599609375,14177.4599609375,14223.08984375,14280.2802734375,14331.419921875,14483.0703125,14472.0498046875,14687.7001953125,14732.5302734375,14902.0302734375,15000.0302734375,14983.1298828125,15214.0,15463.9501953125,15557.2998046875,15500.7001953125,15769.98046875,15707.1904296875,15616.3896484375,15612.0,15877.3701171875,15806.1796875,16153.76953125,16019.0302734375,15946.5400390625,15658.849609375,15701.4501953125,15415.8798828125,15138.3095703125,15410.08984375,15760.0498046875,15771.3203125,15706.2197265625,15802.400390625,16362.2900390625,16424.509765625,16341.3798828125,16410.16015625,16443.400390625,16212.5302734375,16452.1796875,15953.7998046875,15946.8798828125,16211.73046875,15906.41015625,15855.23046875,15820.1103515625,15853.08984375,15911.669921875,16179.5595703125,16255.1796875,16249.330078125,16313.16015625,16215.8203125,16287.83984375,16070.240234375,16189.2197265625,16177.58984375,16032.1201171875,16060.1396484375,16305.8798828125,16475.970703125,16554.900390625,16431.130859375,16571.279296875,16815.359375,16926.439453125,16854.099609375,16859.69921875,16824.91015625,16865.970703125,17076.73046875,17158.810546875,17263.279296875,17323.869140625,17202.109375,17096.970703125,17300.26953125,17572.2890625,17595.900390625,17567.529296875,17566.66015625,17222.349609375,16933.779296875,16843.439453125,16994.359375,17285.0,17235.609375,16583.130859375,15902.3701171875,15670.099609375,15827.08984375,15353.8896484375,16145.98046875,16132.66015625,16042.3603515625,16302.0595703125,16338.2900390625,16595.669921875,16643.689453125,16601.609375,16870.859375,17068.4296875,17162.380859375,17165.0390625,17246.16015625,17147.41015625,17083.91015625,17076.2109375,16966.220703125,17159.220703125,17213.51953125,17371.2890625,17307.859375,17390.609375,17318.5390625,17062.98046875,17075.55078125,17336.7109375,17407.9609375,17502.990234375,17590.970703125,17598.189453125,17755.4609375,17713.939453125,17710.150390625,17919.330078125,17913.0703125,17850.689453125,17866.08984375,17661.48046875,17814.330078125,17847.51953125,17845.75,18034.189453125,17895.25,17789.25,17528.740234375,17458.7890625,17572.330078125,17572.919921875,17403.560546875,17269.869140625,17135.220703125,17402.810546875,17247.41015625,17503.279296875,17553.759765625,17623.890625,17603.119140625,17526.279296875,17485.150390625,17323.640625,17227.1796875,17219.939453125,16982.109375,16858.76953125,16661.359375,16826.26953125,16375.400390625,16341.9404296875,16741.83984375,16818.73046875,17045.859375,17066.9609375,17209.9296875,17396.51953125,17490.2890625,17473.990234375,17319.759765625,17516.919921875,17495.30078125,17428.869140625,17270.490234375,17304.330078125,17474.5703125,17446.310546875,17434.900390625,17354.0,17278.69921875,17276.7890625,16925.8203125,17078.220703125,17260.189453125,17313.76953125,17181.439453125,16855.4609375,16934.76953125,16570.890625,16408.349609375,16460.75,16393.16015625,16713.859375,16640.4296875,16462.83984375,16347.990234375,16387.279296875,16781.189453125,16705.4609375,16900.669921875,16887.8203125,16889.509765625,16888.740234375,16894.240234375,17034.33984375,17074.55078125,17041.630859375,16987.41015625,17068.240234375,17065.970703125,17122.16015625,17078.859375,17296.900390625,17415.30078125,17541.359375,17559.650390625,17452.51953125,17518.130859375,17634.470703125,17693.130859375,17764.0390625,17841.369140625,17818.310546875,17803.5390625,17666.119140625,17642.51953125,17654.189453125,17369.390625,17328.08984375,17427.759765625,17585.990234375,17724.880859375,17697.140625,17688.2109375,17796.919921875,17832.419921875,17914.119140625,17826.259765625,17767.599609375,17599.369140625,17660.099609375,17785.740234375,17812.58984375,17669.109375,17789.26953125,17826.830078125,17946.66015625,17961.640625,18048.939453125,18196.810546875,18248.279296875,18218.83984375,18270.509765625,18526.349609375,18499.9609375,18367.919921875,18169.759765625,18239.380859375,18288.2109375,18375.400390625,18436.9296875,18403.330078125,18525.439453125,18378.640625,18227.4609375,18218.279296875,17899.30078125,17989.0390625,17701.119140625,17674.400390625,17900.30078125,17966.560546875,18151.759765625,18338.05078125,18310.939453125,17997.669921875,17951.810546875,18231.470703125,18268.5703125,18232.349609375,18221.490234375,17969.2890625,18055.73046875,17594.55078125,17652.1796875,17898.25,17867.599609375,17934.400390625,17736.51953125,17178.689453125,16825.25,17015.359375,17433.19921875,17264.740234375,17263.0390625,16926.060546875,16940.830078125,17448.220703125,17456.51953125,17560.359375,17559.7109375,17731.369140625,17699.060546875,17676.94921875,17520.009765625,17548.66015625,17740.560546875,17693.470703125,17625.58984375,17522.5,17178.630859375,17284.5390625,17048.369140625,16990.91015625,17301.650390625,17245.650390625,17004.1796875,16898.869140625,16993.400390625,17148.880859375,17127.94921875,17025.08984375,16620.900390625,16644.7890625,16303.349609375,16419.380859375,16592.1796875,16498.900390625,16565.830078125,16696.119140625,16408.19921875,16048.919921875,16061.7001953125,16006.25,15616.6796875,15832.5400390625,15901.0400390625,16056.08984375,16296.8603515625,16020.3203125,16144.849609375,16156.41015625,15963.6298828125,16104.0302734375,15968.830078125,16266.2197265625,16610.619140625,16807.76953125,16675.08984375,16552.5703125,16605.9609375,16512.880859375,16670.509765625,16621.33984375,16460.119140625,16070.98046875,16047.3701171875,15999.25],"high":[10562.9697265625,10573.76953125,10778.6396484375,10799.1396484375,10840.2900390625,10786.330078125,10787.6201171875,10690.98046875,10800.2900390625,10788.080078125,10914.849609375,10888.2099609375,10812.650390625,10791.2802734375,10812.3798828125,10781.1103515625,10733.5703125,10810.16015625,10856.509765625,10867.58984375,10880.5595703125,10899.83984375,10861.1103515625,10835.4296875,10919.9599609375,10949.759765625,10994.4404296875,10976.4599609375,10945.919921875,10907.4404296875,10905.740234375,10927.16015625,10835.7998046875,10773.25,10641.2802734375,10542.490234375,10425.599609375,10461.3701171875,10500.76953125,10514.0498046875,10436.6201171875,10518.01953125,10374.75,10456.3203125,10516.0498046875,10538.1201171875,10545.25,10596.41015625,10541.73046875,10453.400390625,10431.7802734375,10456.2998046875,10466.990234375,10618.0498046875,10634.849609375,10650.150390625,10670.4296875,10766.599609375,10803.0703125,10810.0302734375,10815.58984375,10862.6796875,10898.1298828125,10912.23046875,10971.5400390625,10954.1796875,10931.759765625,10948.1904296875,10947.5302734375,10885.669921875,10934.91015625,10921.169921875,10967.650390625,10965.2001953125,10888.400390625,10941.490234375,10954.4501953125,11020.509765625,10989.3896484375,11085.490234375,11126.4501953125,11180.1103515625,11186.8798828125,11237.3798828125,11188.1298828125,11271.25,11281.1201171875,11320.1396484375,11347.1796875,11341.0302734375,11373.9501953125,11380.2802734375,11428.419921875,11399.5302734375,11559.0703125,11644.0302734375,11668.2001953125,11647.4697265625,11642.41015625,11570.330078125,11520.3701171875,11509.3701171875,11498.25,11552.25,11599.7802734375,11656.400390625,11649.0703125,11573.83984375,11577.01953125,11604.75,11642.9599609375,11651.73046875,11654.0595703125,11623.58984375,11524.849609375,11531.580078125,11513.830078125,11604.3896484375,11657.650390625,11678.3603515625,11649.73046875,11700.76953125,11875.98046875,11990.7802734375,11975.73046875,12097.009765625,12125.900390625,12111.76953125,12028.2197265625,12022.23046875,12027.599609375,12032.3701171875,12030.66015625,12093.01953125,12114.8896484375,12047.75,12110.740234375,12197.6396484375,12040.080078125,11986.0302734375,11899.669921875,11992.5498046875,12038.2099609375,12113.419921875,12186.6201171875,12169.919921875,12075.5400390625,12117.5498046875,12151.419921875,11933.23046875,11594.2099609375,11365.900390625,11581.3603515625,11620.419921875,11749.6796875,11712.7099609375,11598.0302734375,11678.580078125,11801.51953125,11854.98046875,11840.7900390625,11775.5595703125,11717.099609375,11783.4296875,11827.830078125,11755.169921875,11615.2802734375,11567.08984375,11494.2197265625,11470.23046875,11282.0498046875,11390.240234375,11392.349609375,11525.3203125,11471.3603515625,11221.759765625,11032.4697265625,11088.23046875,10845.3896484375,10171.2001953125,10130.7998046875,9677.0703125,9509.6103515625,9085.2802734375,9264.419921875,9029.51953125,9415.6396484375,9722.3701171875,9739.73046875,9954.8603515625,9655.7001953125,9789.8095703125,9736.0,9818.740234375,10039.150390625,10149.759765625,10246.83984375,10165.1201171875,10179.400390625,10344.1298828125,10461.83984375,10425.2900390625,10710.150390625,10637.6396484375,10544.7998046875,10310.849609375,10462.7001953125,10386.9296875,10578.9599609375,10620.51953125,10794.830078125,11012.7802734375,10781.509765625,10833.5302734375,10828.73046875,10890.8701171875,10970.7001953125,11039.1103515625,10974.509765625,10938.26953125,10894.169921875,10904.009765625,10812.8701171875,10924.7900390625,10933.98046875,11021.66015625,10977.5498046875,10874.5400390625,11046.2197265625,11069.7197265625,11087.5302734375,10965.0302734375,11109.2900390625,11170.490234375,11330.51953125,11425.419921875,11482.3603515625,11631.8896484375,11640.4501953125,11740.900390625,11771.1201171875,11442.2998046875,11469.83984375,11542.25,11550.3203125,11567.419921875,11584.8798828125,11632.8798828125,11679.400390625,11701.23046875,11608.7998046875,11638.0,11736.3896484375,11805.2099609375,11933.58984375,12116.7001953125,12249.9501953125,12190.26953125,12273.4296875,12253.580078125,12216.240234375,12228.3095703125,12320.48046875,12220.9296875,12266.9296875,12221.330078125,12450.16015625,12486.9501953125,12429.759765625,12502.83984375,12686.3603515625,13031.7001953125,12660.8701171875,12769.4697265625,12733.48046875,12673.01953125,12709.919921875,12816.3896484375,12971.8701171875,12912.6298828125,12933.16015625,12906.009765625,12730.9599609375,12812.7998046875,12801.3095703125,12956.1103515625,12981.580078125,12950.1103515625,12764.75,12638.650390625,12702.9404296875,12814.5595703125,12833.2900390625,12960.6796875,12799.16015625,12831.3798828125,12703.2802734375,12802.6103515625,12857.7900390625,12655.669921875,12725.0498046875,12702.5498046875,12616.5703125,12708.6396484375,12701.7900390625,12793.0703125,12857.73046875,13021.6796875,12972.51953125,12927.8095703125,12952.3095703125,12786.91015625,12700.8896484375,12487.48046875,12385.8095703125,12462.759765625,12571.33984375,12568.6796875,12637.6201171875,12706.3896484375,12774.3603515625,12887.1904296875,12997.7900390625,12994.66015625,12960.0,12909.1103515625,12896.2998046875,12911.41015625,12917.75,12942.1201171875,12917.0302734375,12963.259765625,12971.580078125,12884.3203125,12879.98046875,12699.8203125,12656.2900390625,12594.33984375,12760.1396484375,12885.2802734375,12918.7998046875,12999.16015625,13149.900390625,13142.2197265625,13262.1904296875,13324.8603515625,13273.330078125,13551.830078125,13780.1201171875,13773.2900390625,13785.919921875,13726.2197265625,13921.16015625,13951.169921875,13893.2001953125,13856.759765625,13885.009765625,13969.3896484375,13885.669921875,13995.7001953125,14049.580078125,14149.5595703125,14306.8701171875,14367.0,14427.41015625,14319.3798828125,14353.169921875,14270.33984375,14256.5498046875,14339.5,14338.400390625,14329.1201171875,14384.9599609375,14411.9296875,14247.7900390625,14324.419921875,14400.830078125,14483.0703125,14547.0703125,14695.4404296875,14760.0595703125,14937.1298828125,15000.0302734375,15197.6796875,15270.400390625,15463.9501953125,15557.2998046875,15642.0302734375,15778.51953125,15760.150390625,16041.58984375,15676.4501953125,15928.1396484375,16004.3203125,16238.4599609375,16138.0400390625,16014.9599609375,16023.8701171875,15837.4697265625,15557.01953125,15603.41015625,15429.98046875,15838.150390625,15896.400390625,15801.3701171875,15938.08984375,16406.779296875,16517.73046875,16382.7001953125,16579.169921875,16467.75,16456.939453125,16474.05078125,16190.0400390625,16262.91015625,16211.73046875,16091.75,15934.4296875,16074.9697265625,15864.259765625,15986.0703125,16216.2197265625,16298.0302734375,16281.91015625,16340.66015625,16349.2099609375,16410.01953125,16186.4599609375,16235.6298828125,16351.3798828125,16125.5400390625,16146.580078125,16325.6201171875,16520.890625,16556.189453125,16550.19921875,16602.470703125,16816.33984375,16926.720703125,17016.130859375,16979.349609375,17041.369140625,16935.390625,17076.73046875,17158.810546875,17294.150390625,17323.869140625,17282.759765625,17428.150390625,17300.26953125,17572.2890625,17630.189453125,17628.810546875,17709.23046875,17546.939453125,17328.55078125,17052.19921875,17088.73046875,17285.0,17304.470703125,17137.189453125,16552.630859375,16031.9296875,16075.48046875,15719.740234375,16153.76953125,16273.98046875,16154.080078125,16431.140625,16397.58984375,16657.599609375,16706.2890625,16601.609375,16889.009765625,17113.330078125,17184.30078125,17274.66015625,17311.279296875,17225.060546875,17189.23046875,17181.51953125,17082.51953125,17159.220703125,17278.55078125,17371.2890625,17398.220703125,17390.609375,17417.5,17305.490234375,17270.470703125,17375.7890625,17439.630859375,17597.330078125,17595.509765625,17713.240234375,17797.26953125,17863.900390625,17795.880859375,17945.51953125,18008.369140625,17933.619140625,17935.109375,17778.119140625,17947.900390625,18018.0390625,17940.859375,18034.189453125,17926.380859375,17854.349609375,17724.919921875,17707.560546875,17667.380859375,17672.599609375,17637.359375,17459.349609375,17252.869140625,17402.810546875,17429.009765625,17503.279296875,17553.759765625,17636.109375,17643.970703125,17593.849609375,17510.08984375,17524.91015625,17327.19921875,17233.109375,17216.33984375,16983.58984375,16870.55078125,16826.26953125,16777.779296875,16507.109375,16785.2890625,16904.30078125,17045.859375,17201.419921875,17229.890625,17396.51953125,17490.2890625,17503.9296875,17523.16015625,17540.779296875,17633.669921875,17559.2109375,17447.580078125,17319.08984375,17474.5703125,17482.5703125,17529.470703125,17439.75,17411.369140625,17408.7109375,17196.7890625,17145.25,17273.58984375,17335.990234375,17286.890625,17127.859375,16994.2109375,16883.0,16680.2890625,16460.75,16568.2109375,16731.580078125,16771.7109375,16589.720703125,16543.330078125,16519.9609375,16781.189453125,16862.029296875,16916.720703125,16973.859375,17026.890625,16932.890625,16930.98046875,17067.150390625,17079.599609375,17104.859375,17073.970703125,17119.4296875,17237.08984375,17153.759765625,17219.650390625,17296.900390625,17415.30078125,17581.51953125,17575.439453125,17527.1796875,17602.05078125,17683.189453125,17708.099609375,17764.0390625,17841.369140625,17986.1796875,17857.73046875,17797.900390625,17722.890625,17724.5,17641.7890625,17415.630859375,17535.23046875,17626.2109375,17741.55078125,17781.140625,17763.419921875,17796.919921875,17988.880859375,17925.119140625,17893.2890625,17919.349609375,17754.380859375,17678.779296875,17814.3203125,17822.740234375,17812.810546875,17825.890625,17870.16015625,17960.990234375,18039.849609375,18099.779296875,18197.359375,18283.25,18291.25,18379.689453125,18526.349609375,18619.609375,18427.150390625,18444.119140625,18243.259765625,18293.529296875,18394.69921875,18459.73046875,18509.0,18535.419921875,18575.41015625,18359.140625,18292.140625,18113.939453125,18004.44921875,17890.7109375,17776.419921875,17900.30078125,18063.55078125,18168.599609375,18338.05078125,18310.939453125,18182.73046875,18085.91015625,18233.7890625,18330.630859375,18262.9609375,18253.099609375,18159.509765625,18109.279296875,17939.529296875,17737.3203125,17944.5,17918.98046875,18026.029296875,17845.009765625,17581.5703125,17113.669921875,17072.740234375,17478.4296875,17373.900390625,17363.0390625,17177.26953125,17085.76953125,17472.94921875,17472.380859375,17603.990234375,17573.2890625,17738.689453125,17711.169921875,17747.130859375,17527.150390625,17585.91015625,17770.0703125,17767.810546875,17657.759765625,17528.990234375,17438.599609375,17316.689453125,17316.349609375,17100.849609375,17333.2109375,17374.140625,17141.330078125,16999.359375,17106.259765625,17148.880859375,17213.66015625,17088.759765625,16912.30078125,16729.470703125,16427.3203125,16455.5703125,16663.66015625,16604.869140625,16617.060546875,16783.779296875,16491.109375,16345.83984375,16071.5,16081.150390625,15943.6201171875,15860.6904296875,16032.849609375,16085.849609375,16316.580078125,16111.490234375,16181.66015625,16249.4501953125,16219.7998046875,16169.1796875,16179.009765625,16266.2197265625,16610.619140625,16807.76953125,16811.0390625,16617.259765625,16654.119140625,16593.75,16702.990234375,16643.94921875,16581.810546875,16295.0703125,16067.7998046875,16106.75],"low":[10474.1904296875,10521.7001953125,10650.48046875,10745.25,10773.4697265625,10695.490234375,10693.0400390625,10645.3701171875,10674.2001953125,10719.080078125,10821.2998046875,10843.6396484375,10720.66015625,10750.900390625,10756.669921875,10708.919921875,10680.849609375,10723.23046875,10799.650390625,10823.8896484375,10769.5703125,10865.0,10804.33984375,10792.26953125,10861.990234375,10909.150390625,10932.5302734375,10912.919921875,10879.400390625,10879.240234375,10863.330078125,10827.740234375,10754.0703125,10714.73046875,10524.6796875,10418.25,10180.0400390625,10366.5400390625,10383.6201171875,10440.76953125,10361.8896484375,10427.73046875,10287.759765625,10318.3701171875,10449.3896484375,10497.1298828125,10504.490234375,10515.7197265625,10503.0703125,10340.150390625,10368.9599609375,10397.599609375,10406.490234375,10504.2802734375,10589.419921875,10557.0302734375,10566.3203125,10714.26953125,10753.4501953125,10732.7802734375,10746.8701171875,10804.01953125,10822.6904296875,10866.4296875,10878.33984375,10874.66015625,10903.4501953125,10905.919921875,10886.6201171875,10825.849609375,10856.9599609375,10827.6103515625,10855.599609375,10927.3896484375,10809.2802734375,10854.1201171875,10919.4296875,10986.009765625,10889.9599609375,11004.740234375,11091.2900390625,11113.1796875,11131.4501953125,11154.8603515625,11147.8603515625,11218.25,11209.099609375,11254.58984375,11281.3701171875,11295.4404296875,11292.830078125,11306.9501953125,11358.7099609375,11335.509765625,11451.7197265625,11576.1796875,11601.7001953125,11552.080078125,11561.3095703125,11409.830078125,11459.6796875,11439.08984375,11424.76953125,11485.4599609375,11532.9697265625,11576.7900390625,11591.73046875,11478.4296875,11534.150390625,11559.330078125,11576.8203125,11590.8095703125,11604.6796875,11485.16015625,11454.3798828125,11460.0595703125,11457.4296875,11546.75,11577.830078125,11631.0302734375,11607.259765625,11622.580078125,11766.98046875,11913.01953125,11915.6103515625,11939.6201171875,12059.919921875,12008.16015625,11937.4501953125,11960.2099609375,11976.3798828125,11973.9501953125,11982.6396484375,12032.7197265625,12046.2197265625,11997.1396484375,12026.23046875,12023.599609375,11953.3603515625,11822.400390625,11777.4501953125,11889.4599609375,11959.0595703125,12037.240234375,12140.26953125,12048.009765625,12006.080078125,12055.91015625,12101.5498046875,11418.2197265625,11436.9501953125,11138.0302734375,11393.0302734375,11512.7099609375,11605.1103515625,11592.08984375,11423.33984375,11614.25,11693.400390625,11784.9404296875,11788.8701171875,11724.8203125,11642.9501953125,11654.16015625,11714.150390625,11661.6298828125,11512.080078125,11415.4697265625,11408.0595703125,11274.51953125,11049.849609375,11279.8603515625,11297.8095703125,11454.650390625,11310.3203125,10977.6396484375,10830.2197265625,10885.91015625,10359.669921875,9636.150390625,9717.76953125,9371.349609375,9218.669921875,8523.6298828125,8816.8603515625,8750.1396484375,9083.7802734375,9426.4296875,9565.01953125,9691.1396484375,9415.51953125,9630.2998046875,9663.6298828125,9651.51953125,9928.16015625,9984.66015625,10092.3603515625,10103.76953125,10080.650390625,10130.650390625,10366.76953125,10317.1298828125,10552.580078125,10542.9599609375,10278.9501953125,10140.08984375,10294.8798828125,10324.2001953125,10407.490234375,10537.7099609375,10656.400390625,10826.259765625,10658.5,10735.009765625,10708.099609375,10775.16015625,10883.2197265625,10942.1796875,10854.509765625,10828.9296875,10777.4599609375,10730.5498046875,10730.7001953125,10812.7900390625,10860.150390625,10933.2099609375,10804.5595703125,10719.25,10903.3203125,10972.25,10915.2998046875,10861.900390625,10971.400390625,11102.9697265625,11182.51953125,11341.580078125,11411.9404296875,11528.4404296875,11537.3798828125,11621.01953125,11516.58984375,11244.6396484375,11299.4501953125,11380.669921875,11482.3203125,11485.3896484375,11542.3701171875,11553.91015625,11530.849609375,11637.7900390625,11500.650390625,11563.599609375,11622.6396484375,11690.9501953125,11857.900390625,11941.83984375,12028.5703125,12083.83984375,12181.33984375,12030.2001953125,12109.6103515625,12143.91015625,12162.51953125,12107.0400390625,12144.6201171875,12065.7998046875,12242.3203125,12389.400390625,12347.8603515625,12266.5498046875,12586.91015625,12533.1904296875,12488.009765625,12616.830078125,12635.7099609375,12506.58984375,12577.8798828125,12739.990234375,12851.2001953125,12791.1796875,12786.7998046875,12780.1904296875,12625.5400390625,12717.1298828125,12679.1904296875,12800.6904296875,12840.25,12778.6396484375,12144.759765625,12462.51953125,12567.9501953125,12698.849609375,12734.6904296875,12786.4501953125,12674.5703125,12591.4501953125,12565.830078125,12646.4697265625,12732.3203125,12559.7802734375,12575.3603515625,12614.7197265625,12480.5,12650.400390625,12616.6796875,12680.41015625,12773.23046875,12948.7197265625,12851.51953125,12841.08984375,12795.08984375,12632.740234375,12548.0703125,12264.3798828125,12149.8095703125,12282.3603515625,12429.7197265625,12466.580078125,12519.1201171875,12644.08984375,12619.8095703125,12818.009765625,12898.8896484375,12857.099609375,12895.7900390625,12786.259765625,12750.3701171875,12803.3203125,12862.3701171875,12846.419921875,12827.400390625,12875.23046875,12894.1796875,12821.0703125,12761.330078125,12583.3701171875,12546.33984375,12480.66015625,12641.2802734375,12736.01953125,12840.400390625,12927.2998046875,13048.669921875,13022.919921875,13067.0400390625,13193.740234375,13170.1201171875,13356.740234375,13593.009765625,13608.7197265625,13700.0400390625,13666.0703125,13793.5498046875,13798.3203125,13731.8095703125,13763.7900390625,13811.8095703125,13722.8896484375,13749.7099609375,13894.7001953125,13940.0703125,14010.169921875,14142.01953125,14184.580078125,14336.6904296875,14191.849609375,14081.419921875,14182.25,14053.349609375,14145.240234375,14213.490234375,14245.599609375,14166.8896484375,14175.6904296875,14134.8701171875,14256.2900390625,14296.9697265625,14363.4501953125,14435.0302734375,14476.6904296875,14646.330078125,14720.25,14861.990234375,14837.0,15049.8603515625,15275.3798828125,15395.73046875,15421.23046875,15550.16015625,15620.9599609375,15615.1103515625,15320.9697265625,15716.6396484375,15745.48046875,15775.73046875,15973.01953125,15772.6298828125,15589.2099609375,15642.1201171875,15367.4501953125,15138.3095703125,15089.9599609375,15546.6904296875,15741.16015625,15606.740234375,15774.33984375,16197.4501953125,16323.2197265625,16211.25,16410.16015625,16211.75,16212.5302734375,16322.26953125,15953.7998046875,15946.8798828125,15884.5498046875,15840.990234375,15636.4296875,15816.5,15657.919921875,15857.3203125,15947.2099609375,16166.349609375,16194.91015625,16244.990234375,16166.349609375,16264.6103515625,16022.169921875,15983.76953125,16166.2900390625,15967.9501953125,15944.9599609375,16140.3701171875,16411.669921875,16438.400390625,16427.19921875,16496.16015625,16715.3203125,16735.779296875,16815.58984375,16793.5390625,16802.220703125,16559.5703125,16851.060546875,16998.91015625,17135.51953125,17175.01953125,17167.390625,17066.169921875,17055.48046875,17378.359375,17489.7109375,17497.740234375,17548.30078125,17222.349609375,16647.609375,16843.439453125,16764.7109375,17032.23046875,17188.150390625,16460.869140625,15165.26953125,15368.5400390625,15702.099609375,15159.8603515625,15564.9599609375,16009.759765625,15943.4501953125,16136.8603515625,16136.9697265625,16444.75,16523.23046875,16419.419921875,16690.0390625,16939.91015625,17060.44921875,17056.419921875,17198.890625,17084.490234375,16775.849609375,17056.529296875,16907.4296875,16978.009765625,17193.609375,17279.69921875,17275.01953125,17150.51953125,17318.5390625,17023.310546875,17075.55078125,17127.58984375,17319.890625,17471.0703125,17481.23046875,17541.140625,17648.25,17644.359375,17676.98046875,17783.80078125,17895.779296875,17756.8203125,17742.080078125,17597.4609375,17759.900390625,17786.759765625,17716.439453125,17878.779296875,17779.609375,17708.150390625,17500.689453125,17352.240234375,17482.810546875,17511.859375,17403.560546875,17264.5,16893.69921875,17190.48046875,17237.669921875,17231.220703125,17456.19921875,17557.1796875,17566.720703125,17469.6796875,17350.150390625,17305.060546875,17090.25,17139.2109375,16978.109375,16773.5703125,16657.630859375,16418.5390625,16375.400390625,16248.080078125,16459.130859375,16779.900390625,16821.080078125,16984.689453125,17000.259765625,17244.619140625,17207.5703125,17415.51953125,17319.759765625,17380.51953125,17461.0703125,17388.369140625,17167.080078125,17122.94921875,17270.279296875,17387.5703125,17424.5390625,17316.51953125,17254.099609375,17235.44921875,16838.580078125,16998.0703125,17130.740234375,17235.6796875,17113.470703125,16801.779296875,16767.19921875,16503.740234375,16380.0595703125,16162.169921875,16303.6298828125,16465.5703125,16605.490234375,16349.490234375,16328.4697265625,16347.8798828125,16426.759765625,16695.890625,16772.150390625,16855.810546875,16873.990234375,16800.490234375,16784.109375,16909.3203125,16973.16015625,16994.369140625,16920.6796875,17021.76953125,17026.630859375,17080.509765625,17061.4609375,17097.16015625,17279.4609375,17433.099609375,17489.869140625,17403.48046875,17479.55078125,17560.51953125,17629.80078125,17669.580078125,17748.2109375,17786.05078125,17790.640625,17650.0703125,17588.779296875,17609.509765625,17330.439453125,17167.240234375,17369.7890625,17374.58984375,17559.439453125,17670.3203125,17585.94921875,17642.3203125,17832.419921875,17807.119140625,17767.80078125,17767.599609375,17566.990234375,17556.869140625,17719.060546875,17718.26953125,17646.390625,17652.3203125,17799.720703125,17855.779296875,17953.5703125,17975.41015625,18099.7109375,18192.859375,18216.44921875,18238.470703125,18395.140625,18446.51953125,18253.8203125,18134.41015625,18043.970703125,18135.4296875,18255.380859375,18346.810546875,18213.439453125,18435.01953125,18378.640625,18199.349609375,18125.19921875,17851.390625,17682.330078125,17645.66015625,17633.029296875,17712.349609375,17955.94921875,18039.23046875,18145.0390625,18191.75,17965.220703125,17942.6796875,18109.169921875,18190.240234375,18098.51953125,18129.650390625,17840.380859375,17954.75,17561.0703125,17554.970703125,17657.5,17784.640625,17906.240234375,17710.5390625,17135.6796875,16764.779296875,16944.080078125,17224.73046875,17239.900390625,17217.580078125,16911.94921875,16808.4296875,17172.810546875,17359.5,17503.94921875,17468.55078125,17581.619140625,17603.220703125,17633.859375,17368.66015625,17493.009765625,17572.900390625,17682.529296875,17465.609375,17381.0703125,17178.630859375,17210.400390625,17046.669921875,16905.130859375,17080.400390625,17245.650390625,17004.1796875,16845.509765625,16926.33984375,16983.55078125,17106.369140625,16923.869140625,16579.890625,16582.109375,16219.41015625,16256.8798828125,16521.939453125,16465.990234375,16514.30078125,16650.810546875,16312.169921875,16048.919921875,15734.4404296875,15953.26953125,15616.6796875,15687.150390625,15847.4599609375,15915.9296875,16172.7998046875,15892.73046875,16058.2001953125,16125.4501953125,15963.6298828125,15980.900390625,15949.6103515625,16075.91015625,16368.9296875,16493.0703125,16649.91015625,16540.55078125,16509.009765625,16465.869140625,16538.669921875,16557.5390625,16403.330078125,16055.8896484375,15869.0595703125,15981.5595703125],"open":[10488.7001953125,10547.150390625,10650.48046875,10749.41015625,10817.7099609375,10734.25,10777.1796875,10661.3896484375,10674.2001953125,10786.66015625,10821.2998046875,10878.009765625,10793.099609375,10755.8701171875,10785.849609375,10742.8095703125,10729.830078125,10723.23046875,10817.599609375,10855.16015625,10819.919921875,10865.0,10861.1103515625,10821.919921875,10861.990234375,10910.5,10963.8603515625,10969.740234375,10892.25,10898.25,10872.6298828125,10909.98046875,10824.150390625,10773.0595703125,10641.2802734375,10528.8701171875,10304.8798828125,10422.8896484375,10383.6201171875,10491.7900390625,10436.6201171875,10444.5,10374.75,10345.419921875,10449.3896484375,10508.419921875,10526.8701171875,10560.009765625,10526.150390625,10453.400390625,10386.2099609375,10397.599609375,10440.150390625,10504.2802734375,10613.1904296875,10629.2197265625,10566.3203125,10718.400390625,10783.4599609375,10791.9501953125,10787.650390625,10830.25,10822.6904296875,10908.849609375,10887.419921875,10947.6201171875,10908.099609375,10924.8095703125,10917.4404296875,10885.669921875,10909.5703125,10904.0,10855.599609375,10945.919921875,10866.5,10907.6904296875,10932.240234375,10986.009765625,10976.9296875,11004.740234375,11103.5,11166.169921875,11156.1396484375,11190.2099609375,11166.240234375,11221.1904296875,11266.1796875,11266.83984375,11336.6396484375,11321.990234375,11347.3896484375,11336.9697265625,11393.6796875,11373.7001953125,11451.7197265625,11576.1796875,11645.080078125,11642.91015625,11620.8896484375,11570.330078125,11463.330078125,11483.240234375,11488.740234375,11485.4599609375,11543.7998046875,11608.48046875,11645.73046875,11573.83984375,11556.75,11590.8095703125,11608.3701171875,11590.8095703125,11641.7001953125,11616.8798828125,11509.9404296875,11473.3203125,11511.8203125,11546.75,11639.7998046875,11635.4697265625,11647.7802734375,11635.0703125,11766.98046875,11937.900390625,11915.6103515625,11939.6201171875,12061.099609375,12082.98046875,12001.5595703125,11969.1396484375,12023.7900390625,11978.9404296875,12018.3798828125,12032.7197265625,12094.8095703125,12019.1904296875,12026.5,12167.4404296875,12035.7099609375,11961.9697265625,11818.759765625,11889.4599609375,12009.26953125,12069.6103515625,12161.73046875,12169.919921875,12006.080078125,12080.7197265625,12107.5595703125,11933.23046875,11494.0302734375,11365.900390625,11399.4599609375,11601.5498046875,11605.1103515625,11712.7099609375,11514.7197265625,11614.25,11693.400390625,11813.5,11806.51953125,11770.2998046875,11700.91015625,11655.3701171875,11785.7802734375,11721.16015625,11615.2802734375,11506.740234375,11468.599609375,11436.9599609375,11184.66015625,11279.8603515625,11368.25,11454.650390625,11471.3603515625,11221.759765625,10907.6201171875,11022.8203125,10845.3896484375,10091.0302734375,10069.419921875,9538.6396484375,9453.98046875,9085.2802734375,8816.8603515625,9025.5498046875,9083.7802734375,9426.4296875,9667.1396484375,9807.900390625,9571.2197265625,9689.6201171875,9726.2001953125,9707.75,9928.16015625,10010.6396484375,10173.259765625,10105.4296875,10147.5595703125,10130.650390625,10366.76953125,10385.7802734375,10554.5498046875,10612.4501953125,10544.7998046875,10256.1103515625,10370.1298828125,10367.9697265625,10407.490234375,10580.25,10656.400390625,10826.259765625,10781.509765625,10756.9501953125,10771.08984375,10778.5302734375,10883.2197265625,10942.1796875,10974.509765625,10861.009765625,10894.169921875,10833.16015625,10753.2099609375,10812.7900390625,10892.759765625,10933.2099609375,10977.5498046875,10812.9404296875,10903.3203125,11023.9296875,11040.6201171875,10921.16015625,10971.400390625,11109.26953125,11182.51953125,11373.9404296875,11418.009765625,11539.0,11600.6103515625,11635.990234375,11738.490234375,11406.5400390625,11436.2802734375,11380.669921875,11525.5,11534.2001953125,11557.26953125,11553.91015625,11618.419921875,11647.8603515625,11608.7998046875,11563.599609375,11622.6396484375,11694.099609375,11857.900390625,11941.83984375,12176.7900390625,12086.1298828125,12222.900390625,12250.4404296875,12109.6103515625,12202.8896484375,12233.990234375,12173.0400390625,12195.7197265625,12205.25,12242.3203125,12389.759765625,12423.01953125,12467.4296875,12618.6904296875,12951.7197265625,12530.740234375,12691.8603515625,12653.4599609375,12642.73046875,12577.8798828125,12762.33984375,12894.240234375,12901.4296875,12786.7998046875,12856.4599609375,12713.6298828125,12758.8701171875,12709.9697265625,12813.9404296875,12974.9599609375,12904.83984375,12764.75,12462.51953125,12629.7802734375,12706.400390625,12768.9599609375,12888.650390625,12759.2998046875,12763.4404296875,12617.3896484375,12772.4296875,12774.9697265625,12645.919921875,12645.9296875,12637.419921875,12592.1796875,12665.740234375,12697.4599609375,12680.41015625,12787.419921875,12989.8095703125,12920.150390625,12858.599609375,12874.6103515625,12786.91015625,12656.2998046875,12487.48046875,12312.9404296875,12282.3603515625,12488.099609375,12483.650390625,12567.8798828125,12644.08984375,12667.509765625,12832.5400390625,12959.150390625,12988.4404296875,12927.08984375,12892.2900390625,12814.16015625,12803.3203125,12889.990234375,12889.8798828125,12854.9697265625,12945.1201171875,12923.5498046875,12867.76953125,12853.759765625,12687.6396484375,12651.349609375,12565.3203125,12641.2802734375,12766.8603515625,12878.009765625,12952.490234375,13053.98046875,13090.650390625,13067.0400390625,13324.8603515625,13221.7998046875,13356.740234375,13723.76953125,13628.419921875,13775.259765625,13702.58984375,13793.5498046875,13918.83984375,13860.9501953125,13763.7900390625,13833.2099609375,13917.650390625,13810.5498046875,13970.509765625,13988.490234375,14010.169921875,14230.0,14251.9404296875,14336.6904296875,14295.150390625,14298.58984375,14238.919921875,14206.330078125,14145.240234375,14326.16015625,14268.1298828125,14273.7900390625,14348.1103515625,14180.7001953125,14256.2900390625,14306.98046875,14363.4501953125,14500.91015625,14485.9697265625,14704.5302734375,14720.25,14913.6396484375,15145.849609375,15059.51953125,15365.1298828125,15425.580078125,15549.5302734375,15550.16015625,15651.2001953125,15987.16015625,15676.4501953125,15716.6396484375,15934.849609375,15775.73046875,15984.8896484375,16006.2099609375,15955.16015625,15711.759765625,15519.849609375,15544.3603515625,15176.5595703125,15546.6904296875,15828.6396484375,15697.75,15805.759765625,16197.4501953125,16366.23046875,16376.91015625,16445.869140625,16320.8798828125,16329.5400390625,16376.7998046875,16190.0400390625,16127.8701171875,15992.3203125,16091.75,15759.580078125,15943.3701171875,15715.0703125,15921.4501953125,15947.2099609375,16241.5498046875,16256.580078125,16253.9296875,16312.98046875,16264.6103515625,16186.4599609375,16065.5,16250.2001953125,15994.9599609375,16010.5400390625,16140.3701171875,16411.669921875,16490.310546875,16529.23046875,16538.279296875,16771.349609375,16786.560546875,16974.279296875,16908.55078125,16872.400390625,16869.779296875,16851.060546875,17028.349609375,17141.25,17231.580078125,17282.759765625,17302.73046875,17117.490234375,17378.359375,17586.01953125,17610.720703125,17646.9296875,17505.51953125,17249.560546875,16968.75,16925.51953125,17032.23046875,17274.23046875,17137.189453125,16515.880859375,15668.330078125,15819.240234375,15554.990234375,15564.9599609375,16112.2099609375,16122.51953125,16136.8603515625,16246.51953125,16444.75,16645.169921875,16591.69921875,16690.0390625,16948.470703125,17098.490234375,17192.91015625,17201.30078125,17225.060546875,17176.08984375,17094.33984375,17082.51953125,17024.5390625,17200.44921875,17279.69921875,17357.369140625,17254.83984375,17384.740234375,17305.490234375,17162.7109375,17127.58984375,17358.5703125,17471.0703125,17531.8203125,17621.150390625,17648.25,17801.189453125,17745.689453125,17783.80078125,17929.220703125,17901.25,17880.900390625,17778.119140625,17843.30078125,17931.470703125,17892.509765625,17878.779296875,17839.580078125,17854.349609375,17724.919921875,17593.599609375,17482.810546875,17603.94921875,17554.9296875,17394.76953125,17252.869140625,17216.580078125,17414.76953125,17256.609375,17489.119140625,17588.640625,17624.8203125,17593.849609375,17505.009765625,17492.44921875,17308.619140625,17221.349609375,17216.33984375,16941.330078125,16841.619140625,16630.990234375,16777.779296875,16426.98046875,16459.130859375,16830.630859375,16821.080078125,17177.390625,17061.099609375,17244.619140625,17384.609375,17463.80078125,17455.919921875,17380.51953125,17534.05078125,17534.380859375,17411.529296875,17175.0390625,17270.279296875,17452.16015625,17463.779296875,17434.01953125,17332.33984375,17279.2890625,17196.7890625,16998.0703125,17130.740234375,17278.109375,17286.890625,17127.859375,16886.5703125,16883.0,16600.51953125,16362.26953125,16488.2109375,16465.5703125,16742.349609375,16589.720703125,16480.98046875,16392.509765625,16426.759765625,16816.939453125,16791.119140625,16936.19921875,16904.4609375,16900.3203125,16879.33984375,16909.3203125,17037.369140625,17081.169921875,17058.0390625,17021.76953125,17094.419921875,17087.890625,17158.279296875,17097.16015625,17323.390625,17433.099609375,17549.08984375,17527.1796875,17479.55078125,17560.51953125,17639.9609375,17705.2890625,17767.060546875,17864.189453125,17828.529296875,17797.900390625,17680.16015625,17686.119140625,17641.7890625,17320.009765625,17369.7890625,17428.609375,17575.91015625,17720.9296875,17650.669921875,17734.189453125,17845.060546875,17880.41015625,17893.2890625,17841.029296875,17754.380859375,17592.869140625,17719.060546875,17744.5390625,17812.810546875,17686.83984375,17805.740234375,17855.779296875,17966.349609375,17975.41015625,18099.7109375,18209.140625,18270.0,18260.23046875,18395.140625,18598.130859375,18395.720703125,18388.16015625,18095.390625,18266.5390625,18348.390625,18356.2109375,18509.0,18512.150390625,18492.810546875,18275.1796875,18212.259765625,18113.939453125,17843.330078125,17890.7109375,17657.970703125,17750.69921875,17955.94921875,18060.330078125,18217.2890625,18258.810546875,18182.73046875,17978.439453125,18109.169921875,18213.30078125,18250.369140625,18196.400390625,18159.509765625,17954.75,17939.529296875,17617.359375,17657.5,17864.109375,17932.150390625,17845.009765625,17581.5703125,17000.0,16944.080078125,17224.73046875,17373.8203125,17287.900390625,17177.26953125,17007.580078125,17172.810546875,17439.91015625,17503.94921875,17512.41015625,17581.619140625,17711.169921875,17695.80078125,17510.150390625,17568.3203125,17572.900390625,17754.099609375,17657.759765625,17484.189453125,17430.130859375,17210.400390625,17273.05078125,17005.83984375,17080.400390625,17353.25,17139.33984375,16958.66015625,16926.33984375,17057.130859375,17159.880859375,17088.759765625,16912.30078125,16677.83984375,16427.3203125,16350.7197265625,16599.83984375,16593.2109375,16531.369140625,16689.98046875,16491.109375,16345.83984375,15891.400390625,16053.75,15943.6201171875,15687.150390625,15943.6904296875,15915.9296875,16174.7802734375,16111.490234375,16061.919921875,16193.919921875,16166.5703125,15987.740234375,16128.2099609375,16075.91015625,16368.9296875,16561.6796875,16718.91015625,16605.4609375,16570.890625,16593.75,16538.669921875,16643.94921875,16581.810546875,16295.0703125,15975.169921875,16025.83984375],"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729],"type":"candlestick"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"title":{"text":"\u53f0\u7063\u52a0\u6b0a\u6307\u6578\u8d70\u52e2 (\u4e92\u52d5\u5f0f\u5716\u8868)"},"xaxis":{"rangeslider":{"visible":true},"rangeselector":{"buttons":[{"count":1,"label":"1m","step":"month","stepmode":"backward"},{"count":6,"label":"6m","step":"month","stepmode":"backward"},{"count":1,"label":"YTD","step":"year","stepmode":"todate"},{"count":1,"label":"1y","step":"year","stepmode":"backward"},{"step":"all"}]}}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('9f4ab9e9-0ce6-4d49-a558-ab173beb8646');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="AutoTS-&#26178;&#38291;&#24207;&#21015;&#19979;&#30340;&#20729;&#26684;&#38928;&#28204;">AutoTS &#26178;&#38291;&#24207;&#21015;&#19979;&#30340;&#20729;&#26684;&#38928;&#28204;<a class="anchor-link" href="#AutoTS-&#26178;&#38291;&#24207;&#21015;&#19979;&#30340;&#20729;&#26684;&#38928;&#28204;"> </a></h2><p>接下來，我們透過AutoTS函式庫，來預測接下來30天的台灣加權股價指數（收盤價格）：</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">autots</span> <span class="kn">import</span> <span class="n">AutoTS</span>  <span class="c1"># 載入 AutoTS 函式庫</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoTS</span><span class="p">(</span><span class="n">forecast_length</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="s1">&#39;infer&#39;</span><span class="p">,</span> <span class="n">ensemble</span><span class="o">=</span><span class="s1">&#39;simple&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">date_col</span><span class="o">=</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="n">value_col</span><span class="o">=</span><span class="s1">&#39;Close&#39;</span><span class="p">,</span> <span class="n">id_col</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span>
<span class="n">forecast</span> <span class="o">=</span> <span class="n">prediction</span><span class="o">.</span><span class="n">forecast</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Inferred frequency is: B
Model Number: 1 with model AverageValueNaive in generation 0 of 10
Model Number: 2 with model AverageValueNaive in generation 0 of 10
Model Number: 3 with model AverageValueNaive in generation 0 of 10
Model Number: 4 with model DatepartRegression in generation 0 of 10
Model Number: 5 with model DatepartRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\svm\_base.py:1208: ConvergenceWarning:

Liblinear failed to converge, increase the number of iterations.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 6 with model DatepartRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:549: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 7 with model DatepartRegression in generation 0 of 10
Epoch 1/50
24/24 [==============================] - 9s 8ms/step - loss: 0.4147
Epoch 2/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4123
Epoch 3/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4116
Epoch 4/50
24/24 [==============================] - 0s 7ms/step - loss: 0.4103
Epoch 5/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4097
Epoch 6/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4109
Epoch 7/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4109
Epoch 8/50
24/24 [==============================] - 0s 7ms/step - loss: 0.4082
Epoch 9/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4064
Epoch 10/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4070
Epoch 11/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4073
Epoch 12/50
24/24 [==============================] - 0s 7ms/step - loss: 0.4084
Epoch 13/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4095
Epoch 14/50
24/24 [==============================] - 0s 7ms/step - loss: 0.4060
Epoch 15/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4064
Epoch 16/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4070
Epoch 17/50
24/24 [==============================] - 0s 7ms/step - loss: 0.4044
Epoch 18/50
24/24 [==============================] - 0s 11ms/step - loss: 0.4086
Epoch 19/50
24/24 [==============================] - 0s 7ms/step - loss: 0.4056
Epoch 20/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4052
Epoch 21/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4043
Epoch 22/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4070
Epoch 23/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4051
Epoch 24/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4038
Epoch 25/50
24/24 [==============================] - 0s 10ms/step - loss: 0.4033
Epoch 26/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4054
Epoch 27/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4050
Epoch 28/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4059
Epoch 29/50
24/24 [==============================] - 0s 10ms/step - loss: 0.4025
Epoch 30/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4032
Epoch 31/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4049
Epoch 32/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4048
Epoch 33/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4054
Epoch 34/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4037
Epoch 35/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4058
Epoch 36/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4049
Epoch 37/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4032
Epoch 38/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4011
Epoch 39/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4022
Epoch 40/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4034
Epoch 41/50
24/24 [==============================] - 0s 15ms/step - loss: 0.4010
Epoch 42/50
24/24 [==============================] - 0s 13ms/step - loss: 0.4032
Epoch 43/50
24/24 [==============================] - 0s 9ms/step - loss: 0.4015
Epoch 44/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4010
Epoch 45/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4028
Epoch 46/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4020
Epoch 47/50
24/24 [==============================] - 0s 10ms/step - loss: 0.3999
Epoch 48/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4000
Epoch 49/50
24/24 [==============================] - 0s 8ms/step - loss: 0.4012
Epoch 50/50
24/24 [==============================] - 0s 8ms/step - loss: 0.3992
Template Eval Error: ValueError(&#39;Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True&#39;) in model 7: DatepartRegression
Model Number: 8 with model ETS in generation 0 of 10
Model Number: 9 with model ETS in generation 0 of 10
Model Number: 10 with model GLM in generation 0 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 10: GLM
Model Number: 11 with model GLM in generation 0 of 10
Model Number: 12 with model GLS in generation 0 of 10
Model Number: 13 with model GLS in generation 0 of 10
Model Number: 14 with model LastValueNaive in generation 0 of 10
Model Number: 15 with model LastValueNaive in generation 0 of 10
Model Number: 16 with model LastValueNaive in generation 0 of 10
Model Number: 17 with model LastValueNaive in generation 0 of 10
Model Number: 18 with model SeasonalNaive in generation 0 of 10
Model Number: 19 with model SeasonalNaive in generation 0 of 10
Model Number: 20 with model SeasonalNaive in generation 0 of 10
Model Number: 21 with model UnobservedComponents in generation 0 of 10
Model Number: 22 with model UnobservedComponents in generation 0 of 10
Model Number: 23 with model UnobservedComponents in generation 0 of 10
Model Number: 24 with model VAR in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 24: VAR
Model Number: 25 with model VAR in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 25: VAR
Model Number: 26 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 26: VECM
Model Number: 27 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 27: VECM
Model Number: 28 with model WindowRegression in generation 0 of 10
Model Number: 29 with model ConstantNaive in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:549: ConvergenceWarning:

lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 30 with model FBProphet in generation 0 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 30: FBProphet
Model Number: 31 with model MultivariateRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.5s
[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.6s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 32 with model MultivariateRegression in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 32: MultivariateRegression
Model Number: 33 with model DatepartRegression in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 33: DatepartRegression
Model Number: 34 with model SeasonalNaive in generation 0 of 10
Model Number: 35 with model DatepartRegression in generation 0 of 10
Model Number: 36 with model UnobservedComponents in generation 0 of 10
Model Number: 37 with model UnobservedComponents in generation 0 of 10
Model Number: 38 with model ETS in generation 0 of 10
Model Number: 39 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 39: VECM
Model Number: 40 with model ARDL in generation 0 of 10
Model Number: 41 with model MultivariateMotif in generation 0 of 10
Model Number: 42 with model MultivariateMotif in generation 0 of 10
Model Number: 43 with model UnivariateMotif in generation 0 of 10
Model Number: 44 with model UnivariateMotif in generation 0 of 10
Model Number: 45 with model SectionalMotif in generation 0 of 10
Model Number: 46 with model SectionalMotif in generation 0 of 10
Model Number: 47 with model MultivariateRegression in generation 0 of 10
Model Number: 48 with model FBProphet in generation 0 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 48: FBProphet
Model Number: 49 with model SeasonalNaive in generation 0 of 10
Model Number: 50 with model DatepartRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 51 with model NVAR in generation 0 of 10
Model Number: 52 with model Theta in generation 0 of 10
Model Number: 53 with model ConstantNaive in generation 0 of 10
Model Number: 54 with model LastValueNaive in generation 0 of 10
Model Number: 55 with model AverageValueNaive in generation 0 of 10
Model Number: 56 with model GLS in generation 0 of 10
Model Number: 57 with model SeasonalNaive in generation 0 of 10
Model Number: 58 with model GLM in generation 0 of 10
Template Eval Error: ValueError(&#39;regression_type=user and no future_regressor passed&#39;) in model 58: GLM
Model Number: 59 with model ETS in generation 0 of 10
Model Number: 60 with model FBProphet in generation 0 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 60: FBProphet
Model Number: 61 with model UnobservedComponents in generation 0 of 10
Model Number: 62 with model VAR in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 62: VAR
Model Number: 63 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 63: VECM
Model Number: 64 with model WindowRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.1s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 65 with model DatepartRegression in generation 0 of 10
Model Number: 66 with model MultivariateRegression in generation 0 of 10
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] Accuracy may be bad since you didn&#39;t explicitly set num_leaves OR 2^max_depth &gt; num_leaves. (num_leaves=31).
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Model Number: 67 with model UnivariateMotif in generation 0 of 10
Model Number: 68 with model MultivariateMotif in generation 0 of 10
Model Number: 69 with model SectionalMotif in generation 0 of 10
Model Number: 70 with model NVAR in generation 0 of 10
Model Number: 71 with model Theta in generation 0 of 10
Model Number: 72 with model ARDL in generation 0 of 10
Model Number: 73 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 73: VECM
Model Number: 74 with model MultivariateRegression in generation 0 of 10
Model Number: 75 with model WindowRegression in generation 0 of 10
Model Number: 76 with model SectionalMotif in generation 0 of 10
Model Number: 77 with model Theta in generation 0 of 10
Model Number: 78 with model GLS in generation 0 of 10
Model Number: 79 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 79: VECM
Model Number: 80 with model WindowRegression in generation 0 of 10
Model Number: 81 with model SectionalMotif in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type==&#39;User&#39; but no future_regressor supplied&#34;) in model 81: SectionalMotif
Model Number: 82 with model MultivariateMotif in generation 0 of 10
Model Number: 83 with model ConstantNaive in generation 0 of 10
Template Eval Error: ValueError(&#34;Model returned NaN due to a preprocessing transformer {&#39;fillna&#39;: &#39;rolling_mean&#39;, &#39;transformations&#39;: {&#39;0&#39;: &#39;StandardScaler&#39;, &#39;1&#39;: &#39;StandardScaler&#39;, &#39;2&#39;: &#39;bkfilter&#39;, &#39;3&#39;: &#39;CumSumTransformer&#39;, &#39;4&#39;: &#39;cffilter&#39;}, &#39;transformation_params&#39;: {&#39;0&#39;: {}, &#39;1&#39;: {}, &#39;2&#39;: {}, &#39;3&#39;: {}, &#39;4&#39;: {}}}. fail_on_forecast_nan=True&#34;) in model 83: ConstantNaive
Model Number: 84 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 84: VECM
Model Number: 85 with model SectionalMotif in generation 0 of 10
Model Number: 86 with model LastValueNaive in generation 0 of 10
Model Number: 87 with model LastValueNaive in generation 0 of 10
Model Number: 88 with model UnivariateMotif in generation 0 of 10
Model Number: 89 with model ETS in generation 0 of 10
Model Number: 90 with model ConstantNaive in generation 0 of 10
Model Number: 91 with model MultivariateRegression in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 91: MultivariateRegression
Model Number: 92 with model ARDL in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but future_regressor not supplied&#34;) in model 92: ARDL
Model Number: 93 with model NVAR in generation 0 of 10
Model Number: 94 with model SectionalMotif in generation 0 of 10
Model Number: 95 with model UnivariateMotif in generation 0 of 10
Template Eval Error: ValueError(&#39;Model UnivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True&#39;) in model 95: UnivariateMotif
Model Number: 96 with model UnobservedComponents in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\numpy\core\_methods.py:48: RuntimeWarning:

invalid value encountered in reduce

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\numpy\lib\function_base.py:412: RuntimeWarning:

invalid value encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 97 with model DatepartRegression in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 97: DatepartRegression
Model Number: 98 with model Theta in generation 0 of 10
Model Number: 99 with model ConstantNaive in generation 0 of 10
Model Number: 100 with model NVAR in generation 0 of 10
Template Eval Error: ValueError(&#39;Model NVAR returned NaN for one or more series. fail_on_forecast_nan=True&#39;) in model 100: NVAR
Model Number: 101 with model ConstantNaive in generation 0 of 10
Model Number: 102 with model FBProphet in generation 0 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 102: FBProphet
Model Number: 103 with model ConstantNaive in generation 0 of 10
Model Number: 104 with model DatepartRegression in generation 0 of 10
Epoch 1/50
11/11 [==============================] - 9s 13ms/step - loss: 101.4933
Epoch 2/50
11/11 [==============================] - 0s 15ms/step - loss: 101.4572
Epoch 3/50
11/11 [==============================] - 0s 17ms/step - loss: 100.5987
Epoch 4/50
11/11 [==============================] - 0s 17ms/step - loss: 100.9200
Epoch 5/50
11/11 [==============================] - 0s 17ms/step - loss: 102.1344
Epoch 6/50
11/11 [==============================] - 0s 16ms/step - loss: 100.7201
Epoch 7/50
11/11 [==============================] - 0s 16ms/step - loss: 101.8251
Epoch 8/50
11/11 [==============================] - 0s 18ms/step - loss: 101.3982
Epoch 9/50
11/11 [==============================] - 0s 16ms/step - loss: 100.6088
Epoch 10/50
11/11 [==============================] - 0s 17ms/step - loss: 100.6589
Epoch 11/50
11/11 [==============================] - 0s 17ms/step - loss: 100.9847
Epoch 12/50
11/11 [==============================] - 0s 22ms/step - loss: 100.8364
Epoch 13/50
11/11 [==============================] - 0s 18ms/step - loss: 101.1523
Epoch 14/50
11/11 [==============================] - 0s 18ms/step - loss: 101.1174
Epoch 15/50
11/11 [==============================] - 0s 18ms/step - loss: 100.8739
Epoch 16/50
11/11 [==============================] - 0s 18ms/step - loss: 100.5690
Epoch 17/50
11/11 [==============================] - 0s 17ms/step - loss: 100.2768
Epoch 18/50
11/11 [==============================] - 0s 19ms/step - loss: 100.2152
Epoch 19/50
11/11 [==============================] - 0s 19ms/step - loss: 99.9066
Epoch 20/50
11/11 [==============================] - 0s 17ms/step - loss: 101.0432
Epoch 21/50
11/11 [==============================] - 0s 18ms/step - loss: 100.7747
Epoch 22/50
11/11 [==============================] - 0s 17ms/step - loss: 100.0857
Epoch 23/50
11/11 [==============================] - 0s 17ms/step - loss: 100.1763
Epoch 24/50
11/11 [==============================] - 0s 17ms/step - loss: 99.9129
Epoch 25/50
11/11 [==============================] - 0s 17ms/step - loss: 100.6050
Epoch 26/50
11/11 [==============================] - 0s 17ms/step - loss: 99.7978
Epoch 27/50
11/11 [==============================] - 0s 17ms/step - loss: 100.1098
Epoch 28/50
11/11 [==============================] - 0s 17ms/step - loss: 99.8247
Epoch 29/50
11/11 [==============================] - 0s 16ms/step - loss: 100.2941
Epoch 30/50
11/11 [==============================] - 0s 16ms/step - loss: 100.6660
Epoch 31/50
11/11 [==============================] - 0s 16ms/step - loss: 100.0311
Epoch 32/50
11/11 [==============================] - 0s 16ms/step - loss: 100.3587
Epoch 33/50
11/11 [==============================] - 0s 16ms/step - loss: 99.8673
Epoch 34/50
11/11 [==============================] - 0s 17ms/step - loss: 100.0126
Epoch 35/50
11/11 [==============================] - 0s 19ms/step - loss: 100.2276
Epoch 36/50
11/11 [==============================] - 0s 18ms/step - loss: 99.8899
Epoch 37/50
11/11 [==============================] - 0s 17ms/step - loss: 100.3090
Epoch 38/50
11/11 [==============================] - 0s 21ms/step - loss: 99.8032
Epoch 39/50
11/11 [==============================] - 0s 18ms/step - loss: 100.1839
Epoch 40/50
11/11 [==============================] - 0s 19ms/step - loss: 99.9995
Epoch 41/50
11/11 [==============================] - 0s 19ms/step - loss: 100.4775
Epoch 42/50
11/11 [==============================] - 0s 23ms/step - loss: 99.9295
Epoch 43/50
11/11 [==============================] - 0s 18ms/step - loss: 100.1395
Epoch 44/50
11/11 [==============================] - 0s 17ms/step - loss: 100.1845
Epoch 45/50
11/11 [==============================] - 0s 22ms/step - loss: 99.9617
Epoch 46/50
11/11 [==============================] - 0s 25ms/step - loss: 100.4952
Epoch 47/50
11/11 [==============================] - 0s 20ms/step - loss: 100.1195
Epoch 48/50
11/11 [==============================] - 0s 16ms/step - loss: 100.3531
Epoch 49/50
11/11 [==============================] - 0s 19ms/step - loss: 99.7688
Epoch 50/50
11/11 [==============================] - 0s 21ms/step - loss: 100.1043
Template Eval Error: ValueError(&#39;Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True&#39;) in model 104: DatepartRegression
Model Number: 105 with model FBProphet in generation 0 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 105: FBProphet
Model Number: 106 with model FBProphet in generation 0 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 106: FBProphet
Model Number: 107 with model MultivariateRegression in generation 0 of 10
Model Number: 108 with model Theta in generation 0 of 10
Model Number: 109 with model MultivariateRegression in generation 0 of 10
Model Number: 110 with model LastValueNaive in generation 0 of 10
Model Number: 111 with model GLS in generation 0 of 10
Model Number: 112 with model ConstantNaive in generation 0 of 10
Model Number: 113 with model DatepartRegression in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 113: DatepartRegression
Model Number: 114 with model GLS in generation 0 of 10
Model Number: 115 with model UnobservedComponents in generation 0 of 10
Template Eval Error: LinAlgError(&#39;Singular matrix&#39;) in model 115: UnobservedComponents
Model Number: 116 with model DatepartRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\svm\_base.py:1208: ConvergenceWarning:

Liblinear failed to converge, increase the number of iterations.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 117 with model DatepartRegression in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 117: DatepartRegression
Model Number: 118 with model UnobservedComponents in generation 0 of 10
Model Number: 119 with model MultivariateRegression in generation 0 of 10
Epoch 1/50
47/47 [==============================] - 9s 14ms/step - loss: 0.0636
Epoch 2/50
47/47 [==============================] - 1s 13ms/step - loss: 0.0115
Epoch 3/50
47/47 [==============================] - 1s 14ms/step - loss: 0.0016
Epoch 4/50
47/47 [==============================] - 1s 13ms/step - loss: 0.0011
Epoch 5/50
47/47 [==============================] - 1s 14ms/step - loss: 9.5277e-04
Epoch 6/50
47/47 [==============================] - 1s 14ms/step - loss: 7.7466e-04
Epoch 7/50
47/47 [==============================] - 1s 14ms/step - loss: 7.2776e-04
Epoch 8/50
47/47 [==============================] - 1s 14ms/step - loss: 6.6100e-04
Epoch 9/50
47/47 [==============================] - 1s 16ms/step - loss: 5.7689e-04
Epoch 10/50
47/47 [==============================] - 1s 15ms/step - loss: 5.2501e-04
Epoch 11/50
47/47 [==============================] - 1s 16ms/step - loss: 5.3545e-04
Epoch 12/50
47/47 [==============================] - 1s 15ms/step - loss: 4.4294e-04
Epoch 13/50
47/47 [==============================] - 1s 14ms/step - loss: 4.7798e-04
Epoch 14/50
47/47 [==============================] - 1s 13ms/step - loss: 4.0527e-04
Epoch 15/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7283e-04
Epoch 16/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7459e-04
Epoch 17/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7376e-04
Epoch 18/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7424e-04
Epoch 19/50
47/47 [==============================] - 1s 14ms/step - loss: 3.9106e-04
Epoch 20/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7385e-04
Epoch 21/50
47/47 [==============================] - 1s 14ms/step - loss: 3.5949e-04
Epoch 22/50
47/47 [==============================] - 1s 14ms/step - loss: 3.4457e-04
Epoch 23/50
47/47 [==============================] - 1s 16ms/step - loss: 4.1480e-04
Epoch 24/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7439e-04
Epoch 25/50
47/47 [==============================] - 1s 14ms/step - loss: 3.2071e-04
Epoch 26/50
47/47 [==============================] - 1s 14ms/step - loss: 3.9268e-04
Epoch 27/50
47/47 [==============================] - 1s 14ms/step - loss: 3.2402e-04
Epoch 28/50
47/47 [==============================] - 1s 14ms/step - loss: 3.0804e-04
Epoch 29/50
47/47 [==============================] - 1s 14ms/step - loss: 3.7656e-04
Epoch 30/50
47/47 [==============================] - 1s 14ms/step - loss: 4.0517e-04
Epoch 31/50
47/47 [==============================] - 1s 13ms/step - loss: 3.3970e-04
Epoch 32/50
47/47 [==============================] - 1s 13ms/step - loss: 3.5555e-04
Epoch 33/50
47/47 [==============================] - 1s 15ms/step - loss: 3.2561e-04
Epoch 34/50
47/47 [==============================] - 1s 15ms/step - loss: 3.2613e-04
Epoch 35/50
47/47 [==============================] - 1s 15ms/step - loss: 3.7432e-04
Epoch 36/50
47/47 [==============================] - 1s 16ms/step - loss: 3.0226e-04
Epoch 37/50
47/47 [==============================] - 1s 17ms/step - loss: 3.2493e-04
Epoch 38/50
47/47 [==============================] - 1s 18ms/step - loss: 3.6247e-04
Epoch 39/50
47/47 [==============================] - 1s 17ms/step - loss: 3.0538e-04
Epoch 40/50
47/47 [==============================] - 1s 14ms/step - loss: 3.8124e-04
Epoch 41/50
47/47 [==============================] - 1s 14ms/step - loss: 3.3715e-04
Epoch 42/50
47/47 [==============================] - 1s 13ms/step - loss: 3.7144e-04
Epoch 43/50
47/47 [==============================] - 1s 14ms/step - loss: 3.0612e-04
Epoch 44/50
47/47 [==============================] - 1s 16ms/step - loss: 4.1523e-04
Epoch 45/50
47/47 [==============================] - 1s 14ms/step - loss: 2.9862e-04
Epoch 46/50
47/47 [==============================] - 1s 14ms/step - loss: 2.8963e-04
Epoch 47/50
47/47 [==============================] - 1s 14ms/step - loss: 3.0635e-04
Epoch 48/50
47/47 [==============================] - 1s 15ms/step - loss: 3.5204e-04
Epoch 49/50
47/47 [==============================] - 1s 14ms/step - loss: 3.3942e-04
Epoch 50/50
47/47 [==============================] - 1s 14ms/step - loss: 2.9167e-04
Template Eval Error: ValueError(&#39;Model MultivariateRegression returned NaN for one or more series. fail_on_forecast_nan=True&#39;) in model 119: MultivariateRegression
Model Number: 120 with model UnivariateMotif in generation 0 of 10
Model Number: 121 with model SeasonalNaive in generation 0 of 10
Model Number: 122 with model GLS in generation 0 of 10
Model Number: 123 with model SectionalMotif in generation 0 of 10
Model Number: 124 with model MultivariateMotif in generation 0 of 10
Template Eval Error: PicklingError(&#39;Could not pickle the task to send it to the workers.&#39;) in model 124: MultivariateMotif
Model Number: 125 with model UnivariateMotif in generation 0 of 10
Model Number: 126 with model VAR in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 126: VAR
Model Number: 127 with model LastValueNaive in generation 0 of 10
Model Number: 128 with model UnivariateMotif in generation 0 of 10
Model Number: 129 with model GLM in generation 0 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 129: GLM
Model Number: 130 with model MultivariateMotif in generation 0 of 10
Model Number: 131 with model GLM in generation 0 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 131: GLM
Model Number: 132 with model LastValueNaive in generation 0 of 10
Model Number: 133 with model UnobservedComponents in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 133: UnobservedComponents
Model Number: 134 with model Theta in generation 0 of 10
Model Number: 135 with model VAR in generation 0 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 135: VAR
Model Number: 136 with model NVAR in generation 0 of 10
Model Number: 137 with model UnivariateMotif in generation 0 of 10
Model Number: 138 with model ConstantNaive in generation 0 of 10
Model Number: 139 with model SectionalMotif in generation 0 of 10
Model Number: 140 with model ConstantNaive in generation 0 of 10
Model Number: 141 with model AverageValueNaive in generation 0 of 10
Model Number: 142 with model AverageValueNaive in generation 0 of 10
Model Number: 143 with model GLS in generation 0 of 10
Model Number: 144 with model ARDL in generation 0 of 10
Model Number: 145 with model UnivariateMotif in generation 0 of 10
Model Number: 146 with model WindowRegression in generation 0 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.5s
[Parallel(n_jobs=-2)]: Done 444 tasks      | elapsed:    1.4s
[Parallel(n_jobs=-2)]: Done 794 tasks      | elapsed:    2.5s
[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    3.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.1s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 147 with model ARDL in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but future_regressor not supplied&#34;) in model 147: ARDL
Model Number: 148 with model LastValueNaive in generation 0 of 10
Model Number: 149 with model ConstantNaive in generation 0 of 10
Model Number: 150 with model VECM in generation 0 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 150: VECM
Model Number: 151 with model NVAR in generation 0 of 10
Model Number: 152 with model NVAR in generation 0 of 10
New Generation: 1 of 10
Model Number: 153 with model LastValueNaive in generation 1 of 10
Model Number: 154 with model LastValueNaive in generation 1 of 10
Model Number: 155 with model LastValueNaive in generation 1 of 10
Model Number: 156 with model Theta in generation 1 of 10
Model Number: 157 with model Theta in generation 1 of 10
Model Number: 158 with model Theta in generation 1 of 10
Model Number: 159 with model Theta in generation 1 of 10
Model Number: 160 with model NVAR in generation 1 of 10
Model Number: 161 with model NVAR in generation 1 of 10
Model Number: 162 with model NVAR in generation 1 of 10
Model Number: 163 with model NVAR in generation 1 of 10
Model Number: 164 with model ConstantNaive in generation 1 of 10
Model Number: 165 with model ConstantNaive in generation 1 of 10
Model Number: 166 with model ConstantNaive in generation 1 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:1187: RuntimeWarning:

All-NaN slice encountered

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Template Eval Error: Exception(&#39;Transformer MaxAbsScaler failed on fit&#39;) in model 166: ConstantNaive
Model Number: 167 with model UnobservedComponents in generation 1 of 10
Model Number: 168 with model UnobservedComponents in generation 1 of 10
Model Number: 169 with model UnobservedComponents in generation 1 of 10
Model Number: 170 with model GLS in generation 1 of 10
Model Number: 171 with model GLS in generation 1 of 10
Model Number: 172 with model GLS in generation 1 of 10
Model Number: 173 with model SeasonalNaive in generation 1 of 10
Model Number: 174 with model SeasonalNaive in generation 1 of 10
Model Number: 175 with model SeasonalNaive in generation 1 of 10
Model Number: 176 with model SeasonalNaive in generation 1 of 10
Model Number: 177 with model WindowRegression in generation 1 of 10
Model Number: 178 with model WindowRegression in generation 1 of 10
Epoch 1/50
18/18 [==============================] - 20s 422ms/step - loss: 103.9447 - val_loss: 121.9874
Epoch 2/50
18/18 [==============================] - 8s 458ms/step - loss: 94.0657 - val_loss: 125.3344
Epoch 3/50
18/18 [==============================] - 8s 418ms/step - loss: 91.0484 - val_loss: 125.4194
Epoch 4/50
18/18 [==============================] - 7s 420ms/step - loss: 86.9609 - val_loss: 128.9946
Epoch 5/50
18/18 [==============================] - 7s 414ms/step - loss: 86.0640 - val_loss: 132.0940
Epoch 6/50
18/18 [==============================] - 8s 461ms/step - loss: 84.7157 - val_loss: 132.6775
Epoch 7/50
18/18 [==============================] - 8s 438ms/step - loss: 83.3668 - val_loss: 136.1450
Epoch 8/50
18/18 [==============================] - 8s 433ms/step - loss: 82.9913 - val_loss: 132.7413
Epoch 9/50
18/18 [==============================] - 8s 435ms/step - loss: 82.3165 - val_loss: 139.5983
Epoch 10/50
18/18 [==============================] - 7s 405ms/step - loss: 82.2243 - val_loss: 137.6282
Epoch 11/50
18/18 [==============================] - 8s 437ms/step - loss: 81.0812 - val_loss: 140.9158
Model Number: 179 with model WindowRegression in generation 1 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 179: WindowRegression
Model Number: 180 with model AverageValueNaive in generation 1 of 10
Model Number: 181 with model AverageValueNaive in generation 1 of 10
Model Number: 182 with model AverageValueNaive in generation 1 of 10
Model Number: 183 with model ARDL in generation 1 of 10
Model Number: 184 with model ARDL in generation 1 of 10
Model Number: 185 with model ARDL in generation 1 of 10
Model Number: 186 with model ARDL in generation 1 of 10
Model Number: 187 with model SectionalMotif in generation 1 of 10
Model Number: 188 with model SectionalMotif in generation 1 of 10
Model Number: 189 with model SectionalMotif in generation 1 of 10
Model Number: 190 with model SectionalMotif in generation 1 of 10
Model Number: 191 with model ETS in generation 1 of 10
Model Number: 192 with model ETS in generation 1 of 10
Model Number: 193 with model ETS in generation 1 of 10
ETS error ValueError(&#39;endog must be strictly positive when usingmultiplicative trend or seasonal components.&#39;)
ETS failed on Close with ValueError(&#39;endog must be strictly positive when usingmultiplicative trend or seasonal components.&#39;)
Model Number: 194 with model ETS in generation 1 of 10
Model Number: 195 with model UnivariateMotif in generation 1 of 10
Model Number: 196 with model UnivariateMotif in generation 1 of 10
Model Number: 197 with model UnivariateMotif in generation 1 of 10
Model Number: 198 with model UnivariateMotif in generation 1 of 10
Model Number: 199 with model MultivariateMotif in generation 1 of 10
Model Number: 200 with model MultivariateMotif in generation 1 of 10
Model Number: 201 with model MultivariateMotif in generation 1 of 10
Model Number: 202 with model MultivariateRegression in generation 1 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+01, tolerance: 5.856e-03

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 203 with model MultivariateRegression in generation 1 of 10
Template Eval Error: ValueError(&#39;Some value(s) of y are out of the valid range for family PoissonDistribution&#39;) in model 203: MultivariateRegression
Model Number: 204 with model MultivariateRegression in generation 1 of 10
Template Eval Error: ValueError(&#39;Some value(s) of y are out of the valid range for family PoissonDistribution&#39;) in model 204: MultivariateRegression
Model Number: 205 with model MultivariateRegression in generation 1 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 205: MultivariateRegression
Model Number: 206 with model DatepartRegression in generation 1 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 206: DatepartRegression
Model Number: 207 with model DatepartRegression in generation 1 of 10
Template Eval Error: ValueError(&#39;Failed to convert a NumPy array to a Tensor (Unsupported object type int).&#39;) in model 207: DatepartRegression
Model Number: 208 with model DatepartRegression in generation 1 of 10
Model Number: 209 with model GLM in generation 1 of 10
Model Number: 210 with model GLM in generation 1 of 10
Template Eval Error: ValueError(&#39;regression_type=user and no future_regressor passed&#39;) in model 210: GLM
Model Number: 211 with model GLM in generation 1 of 10
Template Eval Error: ValueError(&#39;regression_type=user and no future_regressor passed&#39;) in model 211: GLM
Model Number: 212 with model GLM in generation 1 of 10
Model Number: 213 with model VAR in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 213: VAR
Model Number: 214 with model VAR in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 214: VAR
Model Number: 215 with model VAR in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 215: VAR
Model Number: 216 with model VAR in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 216: VAR
Model Number: 217 with model VECM in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 217: VECM
Model Number: 218 with model VECM in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 218: VECM
Model Number: 219 with model VECM in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 219: VECM
Model Number: 220 with model VECM in generation 1 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 220: VECM
Model Number: 221 with model FBProphet in generation 1 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 221: FBProphet
Model Number: 222 with model FBProphet in generation 1 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 222: FBProphet
Model Number: 223 with model FBProphet in generation 1 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 223: FBProphet
Model Number: 224 with model FBProphet in generation 1 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 224: FBProphet
New Generation: 2 of 10
Model Number: 225 with model LastValueNaive in generation 2 of 10
Model Number: 226 with model LastValueNaive in generation 2 of 10
Model Number: 227 with model LastValueNaive in generation 2 of 10
Model Number: 228 with model NVAR in generation 2 of 10
Model Number: 229 with model NVAR in generation 2 of 10
Model Number: 230 with model NVAR in generation 2 of 10
Model Number: 231 with model UnivariateMotif in generation 2 of 10
Model Number: 232 with model UnivariateMotif in generation 2 of 10
Model Number: 233 with model UnivariateMotif in generation 2 of 10
Model Number: 234 with model UnivariateMotif in generation 2 of 10
Model Number: 235 with model Theta in generation 2 of 10
Model Number: 236 with model Theta in generation 2 of 10
Model Number: 237 with model Theta in generation 2 of 10
Model Number: 238 with model Theta in generation 2 of 10
Model Number: 239 with model ConstantNaive in generation 2 of 10
Model Number: 240 with model ConstantNaive in generation 2 of 10
Model Number: 241 with model ConstantNaive in generation 2 of 10
Model Number: 242 with model UnobservedComponents in generation 2 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 242: UnobservedComponents
Model Number: 243 with model UnobservedComponents in generation 2 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 243: UnobservedComponents
Model Number: 244 with model UnobservedComponents in generation 2 of 10
Template Eval Error: LinAlgError(&#39;Schur decomposition solver error.&#39;) in model 244: UnobservedComponents
Model Number: 245 with model GLS in generation 2 of 10
Model Number: 246 with model GLS in generation 2 of 10
Model Number: 247 with model GLS in generation 2 of 10
Model Number: 248 with model SeasonalNaive in generation 2 of 10
Model Number: 249 with model SeasonalNaive in generation 2 of 10
Model Number: 250 with model SeasonalNaive in generation 2 of 10
Model Number: 251 with model SeasonalNaive in generation 2 of 10
Model Number: 252 with model WindowRegression in generation 2 of 10
Model Number: 253 with model WindowRegression in generation 2 of 10
Model Number: 254 with model WindowRegression in generation 2 of 10
Model Number: 255 with model AverageValueNaive in generation 2 of 10
Model Number: 256 with model AverageValueNaive in generation 2 of 10
Model Number: 257 with model AverageValueNaive in generation 2 of 10
Model Number: 258 with model ARDL in generation 2 of 10
Model Number: 259 with model ARDL in generation 2 of 10
Model Number: 260 with model ARDL in generation 2 of 10
Model Number: 261 with model ARDL in generation 2 of 10
Model Number: 262 with model SectionalMotif in generation 2 of 10
Model Number: 263 with model SectionalMotif in generation 2 of 10
Model Number: 264 with model SectionalMotif in generation 2 of 10
Model Number: 265 with model SectionalMotif in generation 2 of 10
Template Eval Error: ValueError(&#34;regression_type==&#39;User&#39; but no future_regressor supplied&#34;) in model 265: SectionalMotif
Model Number: 266 with model ETS in generation 2 of 10
Model Number: 267 with model ETS in generation 2 of 10
Model Number: 268 with model ETS in generation 2 of 10
Model Number: 269 with model ETS in generation 2 of 10
Model Number: 270 with model MultivariateMotif in generation 2 of 10
Model Number: 271 with model MultivariateMotif in generation 2 of 10
Model Number: 272 with model MultivariateMotif in generation 2 of 10
Model Number: 273 with model MultivariateMotif in generation 2 of 10
Model Number: 274 with model MultivariateRegression in generation 2 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e-02, tolerance: 1.304e-05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 275 with model MultivariateRegression in generation 2 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 275: MultivariateRegression
Model Number: 276 with model MultivariateRegression in generation 2 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.7s
[Parallel(n_jobs=-2)]: Done 200 out of 200 | elapsed:    0.7s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 200 out of 200 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 277 with model MultivariateRegression in generation 2 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 277: MultivariateRegression
Model Number: 278 with model DatepartRegression in generation 2 of 10
Model Number: 279 with model DatepartRegression in generation 2 of 10
Model Number: 280 with model DatepartRegression in generation 2 of 10
Template Eval Error: ValueError(&#39;Failed to convert a NumPy array to a Tensor (Unsupported object type int).&#39;) in model 280: DatepartRegression
Model Number: 281 with model GLM in generation 2 of 10
Model Number: 282 with model GLM in generation 2 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 283 with model GLM in generation 2 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 284 with model GLM in generation 2 of 10
Model Number: 285 with model VAR in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 285: VAR
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 286 with model VAR in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 286: VAR
Model Number: 287 with model VAR in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 287: VAR
Model Number: 288 with model VAR in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 288: VAR
Model Number: 289 with model VECM in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 289: VECM
Model Number: 290 with model VECM in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 290: VECM
Model Number: 291 with model VECM in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 291: VECM
Model Number: 292 with model VECM in generation 2 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 292: VECM
Model Number: 293 with model FBProphet in generation 2 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 293: FBProphet
Model Number: 294 with model FBProphet in generation 2 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 294: FBProphet
Model Number: 295 with model FBProphet in generation 2 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 295: FBProphet
Model Number: 296 with model FBProphet in generation 2 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 296: FBProphet
New Generation: 3 of 10
Model Number: 297 with model LastValueNaive in generation 3 of 10
Model Number: 298 with model LastValueNaive in generation 3 of 10
Model Number: 299 with model LastValueNaive in generation 3 of 10
Model Number: 300 with model NVAR in generation 3 of 10
Model Number: 301 with model NVAR in generation 3 of 10
Model Number: 302 with model NVAR in generation 3 of 10
Model Number: 303 with model NVAR in generation 3 of 10
Model Number: 304 with model ARDL in generation 3 of 10
Model Number: 305 with model ARDL in generation 3 of 10
Model Number: 306 with model ARDL in generation 3 of 10
Model Number: 307 with model ARDL in generation 3 of 10
Model Number: 308 with model UnivariateMotif in generation 3 of 10
Model Number: 309 with model UnivariateMotif in generation 3 of 10
Model Number: 310 with model UnivariateMotif in generation 3 of 10
Model Number: 311 with model UnivariateMotif in generation 3 of 10
Model Number: 312 with model Theta in generation 3 of 10
Model Number: 313 with model Theta in generation 3 of 10
Model Number: 314 with model Theta in generation 3 of 10
Model Number: 315 with model Theta in generation 3 of 10
Model Number: 316 with model AverageValueNaive in generation 3 of 10
Model Number: 317 with model AverageValueNaive in generation 3 of 10
Model Number: 318 with model AverageValueNaive in generation 3 of 10
Model Number: 319 with model ConstantNaive in generation 3 of 10
Model Number: 320 with model ConstantNaive in generation 3 of 10
Model Number: 321 with model ConstantNaive in generation 3 of 10
Model Number: 322 with model UnobservedComponents in generation 3 of 10
Model Number: 323 with model UnobservedComponents in generation 3 of 10
Model Number: 324 with model UnobservedComponents in generation 3 of 10
Model Number: 325 with model GLM in generation 3 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 325: GLM
Model Number: 326 with model GLM in generation 3 of 10
Model Number: 327 with model GLM in generation 3 of 10
Model Number: 328 with model GLM in generation 3 of 10</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 328: GLM
Model Number: 329 with model GLS in generation 3 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:67: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

invalid value encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 330 with model GLS in generation 3 of 10
Model Number: 331 with model GLS in generation 3 of 10
Model Number: 332 with model SeasonalNaive in generation 3 of 10
Model Number: 333 with model SeasonalNaive in generation 3 of 10
Model Number: 334 with model SeasonalNaive in generation 3 of 10
Model Number: 335 with model SeasonalNaive in generation 3 of 10
Model Number: 336 with model WindowRegression in generation 3 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.833e+06, tolerance: 6.087e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 337 with model WindowRegression in generation 3 of 10
Model Number: 338 with model WindowRegression in generation 3 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.5s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    1.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 339 with model SectionalMotif in generation 3 of 10
Model Number: 340 with model SectionalMotif in generation 3 of 10
Model Number: 341 with model SectionalMotif in generation 3 of 10
Model Number: 342 with model SectionalMotif in generation 3 of 10
Model Number: 343 with model ETS in generation 3 of 10
Model Number: 344 with model ETS in generation 3 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\numpy\lib\nanfunctions.py:997: RuntimeWarning:

All-NaN slice encountered

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\numpy\lib\nanfunctions.py:1376: RuntimeWarning:

All-NaN slice encountered

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Template Eval Error: Exception(&#39;Transformer RobustScaler failed on fit&#39;) in model 344: ETS
Model Number: 345 with model ETS in generation 3 of 10
Model Number: 346 with model ETS in generation 3 of 10
Model Number: 347 with model MultivariateMotif in generation 3 of 10
Model Number: 348 with model MultivariateMotif in generation 3 of 10
Model Number: 349 with model MultivariateMotif in generation 3 of 10
Model Number: 350 with model MultivariateMotif in generation 3 of 10
Model Number: 351 with model MultivariateRegression in generation 3 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\experimental\enable_hist_gradient_boosting.py:17: UserWarning:

Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:67: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

invalid value encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 352 with model MultivariateRegression in generation 3 of 10
Model Number: 353 with model MultivariateRegression in generation 3 of 10
Model Number: 354 with model MultivariateRegression in generation 3 of 10
Model Number: 355 with model DatepartRegression in generation 3 of 10
Model Number: 356 with model DatepartRegression in generation 3 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 356: DatepartRegression
Model Number: 357 with model DatepartRegression in generation 3 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\base.py:451: UserWarning:

X does not have valid feature names, but MLPRegressor was fitted with feature names

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 358 with model VAR in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 358: VAR
Model Number: 359 with model VAR in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 359: VAR
Model Number: 360 with model VAR in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 360: VAR
Model Number: 361 with model VAR in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 361: VAR
Model Number: 362 with model VECM in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 362: VECM
Model Number: 363 with model VECM in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 363: VECM
Model Number: 364 with model VECM in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 364: VECM
Model Number: 365 with model VECM in generation 3 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 365: VECM
Model Number: 366 with model FBProphet in generation 3 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 366: FBProphet
Model Number: 367 with model FBProphet in generation 3 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 367: FBProphet
Model Number: 368 with model FBProphet in generation 3 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 368: FBProphet
Model Number: 369 with model FBProphet in generation 3 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 369: FBProphet
New Generation: 4 of 10
Model Number: 370 with model LastValueNaive in generation 4 of 10
Model Number: 371 with model LastValueNaive in generation 4 of 10
Model Number: 372 with model NVAR in generation 4 of 10
Model Number: 373 with model NVAR in generation 4 of 10
Model Number: 374 with model NVAR in generation 4 of 10
Model Number: 375 with model NVAR in generation 4 of 10
Model Number: 376 with model ARDL in generation 4 of 10
Model Number: 377 with model ARDL in generation 4 of 10
Model Number: 378 with model ARDL in generation 4 of 10
Model Number: 379 with model ARDL in generation 4 of 10
Model Number: 380 with model Theta in generation 4 of 10
Model Number: 381 with model Theta in generation 4 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+01, tolerance: 7.530e-02

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 382 with model Theta in generation 4 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e+00, tolerance: 1.905e-02

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 383 with model UnivariateMotif in generation 4 of 10
Model Number: 384 with model UnivariateMotif in generation 4 of 10
Model Number: 385 with model UnivariateMotif in generation 4 of 10
Model Number: 386 with model UnivariateMotif in generation 4 of 10
Model Number: 387 with model AverageValueNaive in generation 4 of 10
Model Number: 388 with model AverageValueNaive in generation 4 of 10
Model Number: 389 with model AverageValueNaive in generation 4 of 10
Model Number: 390 with model ConstantNaive in generation 4 of 10
Model Number: 391 with model ConstantNaive in generation 4 of 10
Model Number: 392 with model ConstantNaive in generation 4 of 10
Model Number: 393 with model GLM in generation 4 of 10
Model Number: 394 with model GLM in generation 4 of 10
Model Number: 395 with model GLM in generation 4 of 10
Model Number: 396 with model GLM in generation 4 of 10
Model Number: 397 with model UnobservedComponents in generation 4 of 10
Model Number: 398 with model UnobservedComponents in generation 4 of 10
Model Number: 399 with model UnobservedComponents in generation 4 of 10
Model Number: 400 with model MultivariateRegression in generation 4 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 400: MultivariateRegression
Model Number: 401 with model MultivariateRegression in generation 4 of 10
Model Number: 402 with model MultivariateRegression in generation 4 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.1s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:67: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

invalid value encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 403 with model MultivariateRegression in generation 4 of 10
Model Number: 404 with model GLS in generation 4 of 10
Model Number: 405 with model GLS in generation 4 of 10
Model Number: 406 with model GLS in generation 4 of 10
Template Eval Error: ValueError(&#39;zero-size array to reduction operation maximum which has no identity&#39;) in model 406: GLS
Model Number: 407 with model SeasonalNaive in generation 4 of 10
Model Number: 408 with model SeasonalNaive in generation 4 of 10
Model Number: 409 with model SeasonalNaive in generation 4 of 10
Model Number: 410 with model SeasonalNaive in generation 4 of 10
Model Number: 411 with model WindowRegression in generation 4 of 10
Model Number: 412 with model WindowRegression in generation 4 of 10
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Model Number: 413 with model WindowRegression in generation 4 of 10
Model Number: 414 with model SectionalMotif in generation 4 of 10
Model Number: 415 with model SectionalMotif in generation 4 of 10
Model Number: 416 with model SectionalMotif in generation 4 of 10
Model Number: 417 with model SectionalMotif in generation 4 of 10
Model Number: 418 with model MultivariateMotif in generation 4 of 10
Model Number: 419 with model MultivariateMotif in generation 4 of 10
Model Number: 420 with model MultivariateMotif in generation 4 of 10
Model Number: 421 with model MultivariateMotif in generation 4 of 10
Model Number: 422 with model ETS in generation 4 of 10
Model Number: 423 with model ETS in generation 4 of 10
Model Number: 424 with model ETS in generation 4 of 10
Model Number: 425 with model ETS in generation 4 of 10
Model Number: 426 with model DatepartRegression in generation 4 of 10
Template Eval Error: ValueError(&#39;Failed to convert a NumPy array to a Tensor (Unsupported object type int).&#39;) in model 426: DatepartRegression
Model Number: 427 with model DatepartRegression in generation 4 of 10
Model Number: 428 with model DatepartRegression in generation 4 of 10
Epoch 1/100
Template Eval Error: TypeError(&#39;in user code:\n\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 1021, in train_function  *\n        return step_function(self, iterator)\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 859, in train_step\n        y_pred = self(x, training=True)\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\utils\\traceback_utils.py&#34;, line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\backend.py&#34;, line 2223, in dot\n        out = tf.matmul(x, y)\n\n    TypeError: Exception encountered when calling layer &#34;forward_lstm&#34; (type LSTM).\n    \n    Input \&#39;b\&#39; of \&#39;MatMul\&#39; Op has type float32 that does not match type int64 of argument \&#39;a\&#39;.\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 1, 7), dtype=int64)\n      • mask=None\n      • training=True\n      • initial_state=None\n&#39;) in model 428: DatepartRegression
Model Number: 429 with model VAR in generation 4 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 429: VAR
Model Number: 430 with model VAR in generation 4 of 10
Template Eval Error: IndexError(&#39;tuple index out of range&#39;) in model 430: VAR
Model Number: 431 with model VAR in generation 4 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 431: VAR
Model Number: 432 with model VAR in generation 4 of 10
Template Eval Error: IndexError(&#39;tuple index out of range&#39;) in model 432: VAR
Model Number: 433 with model VECM in generation 4 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 433: VECM
Model Number: 434 with model VECM in generation 4 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 434: VECM
Model Number: 435 with model VECM in generation 4 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 435: VECM
Model Number: 436 with model VECM in generation 4 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 436: VECM
Model Number: 437 with model FBProphet in generation 4 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 437: FBProphet
Model Number: 438 with model FBProphet in generation 4 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 438: FBProphet
Model Number: 439 with model FBProphet in generation 4 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 439: FBProphet
Model Number: 440 with model FBProphet in generation 4 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 440: FBProphet
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.924e+08, tolerance: 6.133e+05

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.669e+13, tolerance: 7.233e+11

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>New Generation: 5 of 10
Model Number: 441 with model LastValueNaive in generation 5 of 10
Model Number: 442 with model LastValueNaive in generation 5 of 10
Model Number: 443 with model NVAR in generation 5 of 10
Model Number: 444 with model NVAR in generation 5 of 10
Model Number: 445 with model NVAR in generation 5 of 10
Model Number: 446 with model NVAR in generation 5 of 10
Model Number: 447 with model ARDL in generation 5 of 10
Model Number: 448 with model ARDL in generation 5 of 10
Model Number: 449 with model ARDL in generation 5 of 10
Model Number: 450 with model ARDL in generation 5 of 10
Model Number: 451 with model Theta in generation 5 of 10
Model Number: 452 with model Theta in generation 5 of 10
Model Number: 453 with model Theta in generation 5 of 10
Model Number: 454 with model Theta in generation 5 of 10
Model Number: 455 with model UnivariateMotif in generation 5 of 10
Model Number: 456 with model UnivariateMotif in generation 5 of 10
Template Eval Error: ValueError(&#39;kth(=20) out of bounds (11)&#39;) in model 456: UnivariateMotif
Model Number: 457 with model UnivariateMotif in generation 5 of 10
Model Number: 458 with model UnivariateMotif in generation 5 of 10
Model Number: 459 with model AverageValueNaive in generation 5 of 10
Model Number: 460 with model AverageValueNaive in generation 5 of 10
Model Number: 461 with model AverageValueNaive in generation 5 of 10
Model Number: 462 with model ConstantNaive in generation 5 of 10
Model Number: 463 with model ConstantNaive in generation 5 of 10
Model Number: 464 with model ConstantNaive in generation 5 of 10
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-06-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-07-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-08-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-09-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-10-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-11-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2019-12-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-01-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-02-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-03-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-04-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-05-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-06-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-07-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-08-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-09-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-10-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-11-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2020-12-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-01-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-02-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-03-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-04-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-05-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-06-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-07-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-08-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-09-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-10-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-11-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2021-12-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-01-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-02-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-09 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-10 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-16 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-17 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-23 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-24 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-30 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-03-31 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-01 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-05 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-06 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-07 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-08 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-11 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-12 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-13 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-14 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-15 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-18 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-19 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-20 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-21 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-22 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-25 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-26 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-27 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-28 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-04-29 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-05-02 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-05-03 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for 2022-05-04 00:00:00 with 0
SinTrend failed with ValueError(&#39;array must not contain infs or NaNs&#39;) for Close with 0
Template Eval Error: Exception(&#39;Transformer SinTrend failed on fit&#39;) in model 464: ConstantNaive
Model Number: 465 with model GLM in generation 5 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 465: GLM
Model Number: 466 with model GLM in generation 5 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 466: GLM
Model Number: 467 with model GLM in generation 5 of 10
Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 467: GLM
Model Number: 468 with model GLM in generation 5 of 10
Model Number: 469 with model UnobservedComponents in generation 5 of 10
Model Number: 470 with model UnobservedComponents in generation 5 of 10
Model Number: 471 with model UnobservedComponents in generation 5 of 10
Model Number: 472 with model MultivariateRegression in generation 5 of 10
Model Number: 473 with model MultivariateRegression in generation 5 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 473: MultivariateRegression
Model Number: 474 with model MultivariateRegression in generation 5 of 10
Model Number: 475 with model MultivariateRegression in generation 5 of 10
Model Number: 476 with model GLS in generation 5 of 10
Model Number: 477 with model GLS in generation 5 of 10
Model Number: 478 with model GLS in generation 5 of 10
Model Number: 479 with model SeasonalNaive in generation 5 of 10
Model Number: 480 with model SeasonalNaive in generation 5 of 10
Model Number: 481 with model SeasonalNaive in generation 5 of 10
Model Number: 482 with model SeasonalNaive in generation 5 of 10
Model Number: 483 with model WindowRegression in generation 5 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 483: WindowRegression
Model Number: 484 with model WindowRegression in generation 5 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 484: WindowRegression
Model Number: 485 with model WindowRegression in generation 5 of 10
Model Number: 486 with model SectionalMotif in generation 5 of 10
Model Number: 487 with model SectionalMotif in generation 5 of 10
Model Number: 488 with model SectionalMotif in generation 5 of 10
Model Number: 489 with model SectionalMotif in generation 5 of 10
Model Number: 490 with model MultivariateMotif in generation 5 of 10
Model Number: 491 with model MultivariateMotif in generation 5 of 10
Model Number: 492 with model MultivariateMotif in generation 5 of 10
Model Number: 493 with model MultivariateMotif in generation 5 of 10
Model Number: 494 with model ETS in generation 5 of 10
Model Number: 495 with model ETS in generation 5 of 10
ETS error ValueError(&#39;endog must be strictly positive when usingmultiplicative trend or seasonal components.&#39;)
ETS failed on Close with ValueError(&#39;endog must be strictly positive when usingmultiplicative trend or seasonal components.&#39;)
Model Number: 496 with model ETS in generation 5 of 10
Model Number: 497 with model ETS in generation 5 of 10
ETS error ValueError(&#39;endog must be strictly positive when usingmultiplicative trend or seasonal components.&#39;)
ETS failed on Close with ValueError(&#39;endog must be strictly positive when usingmultiplicative trend or seasonal components.&#39;)
Model Number: 498 with model DatepartRegression in generation 5 of 10
Template Eval Error: ValueError(&#39;Failed to convert a NumPy array to a Tensor (Unsupported object type int).&#39;) in model 498: DatepartRegression
Model Number: 499 with model DatepartRegression in generation 5 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.7s
[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    1.1s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 300 out of 300 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 500 with model DatepartRegression in generation 5 of 10
Model Number: 501 with model VAR in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 501: VAR
Model Number: 502 with model VAR in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 502: VAR
Model Number: 503 with model VAR in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 503: VAR
Model Number: 504 with model VAR in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 504: VAR
Model Number: 505 with model VECM in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 505: VECM
Model Number: 506 with model VECM in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 506: VECM
Model Number: 507 with model VECM in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 507: VECM
Model Number: 508 with model VECM in generation 5 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 508: VECM
Model Number: 509 with model FBProphet in generation 5 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 509: FBProphet
Model Number: 510 with model FBProphet in generation 5 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 510: FBProphet
Model Number: 511 with model FBProphet in generation 5 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 511: FBProphet
Model Number: 512 with model FBProphet in generation 5 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 512: FBProphet
New Generation: 6 of 10
Model Number: 513 with model LastValueNaive in generation 6 of 10
Model Number: 514 with model LastValueNaive in generation 6 of 10
Model Number: 515 with model LastValueNaive in generation 6 of 10
Model Number: 516 with model NVAR in generation 6 of 10
Model Number: 517 with model NVAR in generation 6 of 10
Model Number: 518 with model NVAR in generation 6 of 10
Template Eval Error: ValueError(&#34;Model returned NaN due to a preprocessing transformer {&#39;fillna&#39;: &#39;quadratic&#39;, &#39;transformations&#39;: {&#39;0&#39;: &#39;cffilter&#39;, &#39;1&#39;: &#39;IntermittentOccurrence&#39;, &#39;2&#39;: &#39;PositiveShift&#39;, &#39;3&#39;: &#39;Round&#39;}, &#39;transformation_params&#39;: {&#39;0&#39;: {}, &#39;1&#39;: {&#39;center&#39;: &#39;mean&#39;}, &#39;2&#39;: {}, &#39;3&#39;: {&#39;decimals&#39;: 2, &#39;on_transform&#39;: True, &#39;on_inverse&#39;: False}}}. fail_on_forecast_nan=True&#34;) in model 518: NVAR
Model Number: 519 with model NVAR in generation 6 of 10
Model Number: 520 with model ARDL in generation 6 of 10
Model Number: 521 with model ARDL in generation 6 of 10
Model Number: 522 with model ARDL in generation 6 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but future_regressor not supplied&#34;) in model 522: ARDL
Model Number: 523 with model ARDL in generation 6 of 10
Model Number: 524 with model Theta in generation 6 of 10
Model Number: 525 with model Theta in generation 6 of 10
Model Number: 526 with model Theta in generation 6 of 10
Model Number: 527 with model Theta in generation 6 of 10
Model Number: 528 with model UnivariateMotif in generation 6 of 10
Model Number: 529 with model UnivariateMotif in generation 6 of 10
Model Number: 530 with model UnivariateMotif in generation 6 of 10
Model Number: 531 with model UnivariateMotif in generation 6 of 10
Model Number: 532 with model AverageValueNaive in generation 6 of 10
Model Number: 533 with model AverageValueNaive in generation 6 of 10
Model Number: 534 with model AverageValueNaive in generation 6 of 10
Model Number: 535 with model ConstantNaive in generation 6 of 10
Model Number: 536 with model ConstantNaive in generation 6 of 10
Model Number: 537 with model ConstantNaive in generation 6 of 10
Model Number: 538 with model GLM in generation 6 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 539 with model GLM in generation 6 of 10
Model Number: 540 with model GLM in generation 6 of 10
Model Number: 541 with model GLM in generation 6 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 542 with model UnobservedComponents in generation 6 of 10
Model Number: 543 with model UnobservedComponents in generation 6 of 10
Model Number: 544 with model UnobservedComponents in generation 6 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 544: UnobservedComponents
Model Number: 545 with model MultivariateRegression in generation 6 of 10
Model Number: 546 with model MultivariateRegression in generation 6 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 546: MultivariateRegression
Model Number: 547 with model MultivariateRegression in generation 6 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 547: MultivariateRegression
Model Number: 548 with model MultivariateRegression in generation 6 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 548: MultivariateRegression
Model Number: 549 with model GLS in generation 6 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:461: RuntimeWarning:

All-NaN slice encountered

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:462: RuntimeWarning:

All-NaN slice encountered

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Template Eval Error: Exception(&#39;Transformer MinMaxScaler failed on fit&#39;) in model 549: GLS
Model Number: 550 with model GLS in generation 6 of 10
Model Number: 551 with model GLS in generation 6 of 10
Model Number: 552 with model SeasonalNaive in generation 6 of 10
Model Number: 553 with model SeasonalNaive in generation 6 of 10
Model Number: 554 with model SeasonalNaive in generation 6 of 10
Model Number: 555 with model SeasonalNaive in generation 6 of 10
Model Number: 556 with model WindowRegression in generation 6 of 10
Model Number: 557 with model WindowRegression in generation 6 of 10
Model Number: 558 with model WindowRegression in generation 6 of 10
Epoch 1/100
Template Eval Error: ValueError(&#39;in user code:\n\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 1021, in train_function  *\n        return step_function(self, iterator)\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py&#34;, line 859, in train_step\n        y_pred = self(x, training=True)\n    File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\utils\\traceback_utils.py&#34;, line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer &#34;residual_wrapper&#34; (type ResidualWrapper).\n    \n    in user code:\n    \n        File &#34;C:\\Users\\impep\\anaconda3\\envs\\OpenCV\\lib\\site-packages\\autots\\models\\dnn.py&#34;, line 31, in call  *\n            return inputs + delta\n    \n        ValueError: Dimensions must be equal, but are 24 and 30 for \&#39;{{node residual_wrapper/add}} = AddV2[T=DT_FLOAT](IteratorGetNext, residual_wrapper/sequential/dense_1/BiasAdd)\&#39; with input shapes: [?,1,24], [?,30].\n    \n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 1, 24), dtype=float32)\n      • args=&lt;class \&#39;inspect._empty\&#39;&gt;\n      • kwargs={\&#39;training\&#39;: \&#39;True\&#39;}\n&#39;) in model 558: WindowRegression
Model Number: 559 with model MultivariateMotif in generation 6 of 10
Model Number: 560 with model MultivariateMotif in generation 6 of 10
Model Number: 561 with model MultivariateMotif in generation 6 of 10
Model Number: 562 with model MultivariateMotif in generation 6 of 10
Model Number: 563 with model SectionalMotif in generation 6 of 10
Model Number: 564 with model SectionalMotif in generation 6 of 10
Model Number: 565 with model SectionalMotif in generation 6 of 10
Model Number: 566 with model SectionalMotif in generation 6 of 10
Model Number: 567 with model ETS in generation 6 of 10
Model Number: 568 with model ETS in generation 6 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.018e+00, tolerance: 1.951e-02

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 569 with model ETS in generation 6 of 10
Model Number: 570 with model ETS in generation 6 of 10
Model Number: 571 with model DatepartRegression in generation 6 of 10
Template Eval Error: ValueError(&#39;Failed to convert a NumPy array to a Tensor (Unsupported object type int).&#39;) in model 571: DatepartRegression
Model Number: 572 with model DatepartRegression in generation 6 of 10
Model Number: 573 with model DatepartRegression in generation 6 of 10
Model Number: 574 with model VAR in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 574: VAR
Model Number: 575 with model VAR in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 575: VAR
Model Number: 576 with model VAR in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 576: VAR
Model Number: 577 with model VAR in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 577: VAR
Model Number: 578 with model VECM in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 578: VECM
Model Number: 579 with model VECM in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 579: VECM
Model Number: 580 with model VECM in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 580: VECM
Model Number: 581 with model VECM in generation 6 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 581: VECM
Model Number: 582 with model FBProphet in generation 6 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 582: FBProphet
Model Number: 583 with model FBProphet in generation 6 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 583: FBProphet
Model Number: 584 with model FBProphet in generation 6 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 584: FBProphet
Model Number: 585 with model FBProphet in generation 6 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 585: FBProphet
New Generation: 7 of 10
Model Number: 586 with model LastValueNaive in generation 7 of 10
Model Number: 587 with model LastValueNaive in generation 7 of 10
Model Number: 588 with model LastValueNaive in generation 7 of 10
Model Number: 589 with model ARDL in generation 7 of 10
Model Number: 590 with model ARDL in generation 7 of 10
Model Number: 591 with model ARDL in generation 7 of 10
Model Number: 592 with model ARDL in generation 7 of 10
Model Number: 593 with model NVAR in generation 7 of 10
Model Number: 594 with model NVAR in generation 7 of 10
Model Number: 595 with model NVAR in generation 7 of 10
Model Number: 596 with model NVAR in generation 7 of 10
Model Number: 597 with model Theta in generation 7 of 10
Model Number: 598 with model Theta in generation 7 of 10
Model Number: 599 with model Theta in generation 7 of 10
Model Number: 600 with model Theta in generation 7 of 10
Model Number: 601 with model UnivariateMotif in generation 7 of 10
Model Number: 602 with model UnivariateMotif in generation 7 of 10
Model Number: 603 with model UnivariateMotif in generation 7 of 10
Model Number: 604 with model UnivariateMotif in generation 7 of 10
Model Number: 605 with model AverageValueNaive in generation 7 of 10
Model Number: 606 with model AverageValueNaive in generation 7 of 10
Model Number: 607 with model AverageValueNaive in generation 7 of 10
Model Number: 608 with model ConstantNaive in generation 7 of 10
Model Number: 609 with model ConstantNaive in generation 7 of 10
Model Number: 610 with model ConstantNaive in generation 7 of 10
Model Number: 611 with model GLM in generation 7 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.654e+08, tolerance: 6.081e+05

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 612 with model GLM in generation 7 of 10
Model Number: 613 with model GLM in generation 7 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.748e+08, tolerance: 5.158e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 614 with model GLM in generation 7 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 615 with model UnobservedComponents in generation 7 of 10
Model Number: 616 with model UnobservedComponents in generation 7 of 10
Model Number: 617 with model UnobservedComponents in generation 7 of 10
Model Number: 618 with model MultivariateRegression in generation 7 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 618: MultivariateRegression
Model Number: 619 with model MultivariateRegression in generation 7 of 10
Model Number: 620 with model MultivariateRegression in generation 7 of 10
Model Number: 621 with model MultivariateRegression in generation 7 of 10
Model Number: 622 with model GLS in generation 7 of 10
Model Number: 623 with model GLS in generation 7 of 10
Model Number: 624 with model GLS in generation 7 of 10
Model Number: 625 with model ETS in generation 7 of 10
Model Number: 626 with model ETS in generation 7 of 10
Model Number: 627 with model ETS in generation 7 of 10
Model Number: 628 with model ETS in generation 7 of 10
Model Number: 629 with model SeasonalNaive in generation 7 of 10
Model Number: 630 with model SeasonalNaive in generation 7 of 10
Model Number: 631 with model SeasonalNaive in generation 7 of 10
Model Number: 632 with model SeasonalNaive in generation 7 of 10
Model Number: 633 with model WindowRegression in generation 7 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.4s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    1.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 634 with model WindowRegression in generation 7 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 634: WindowRegression
Model Number: 635 with model WindowRegression in generation 7 of 10
Model Number: 636 with model MultivariateMotif in generation 7 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:696: ConvergenceWarning:

Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn&#39;t converged yet.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 637 with model MultivariateMotif in generation 7 of 10
Model Number: 638 with model MultivariateMotif in generation 7 of 10
Model Number: 639 with model MultivariateMotif in generation 7 of 10
Model Number: 640 with model SectionalMotif in generation 7 of 10
Model Number: 641 with model SectionalMotif in generation 7 of 10
Model Number: 642 with model SectionalMotif in generation 7 of 10
Model Number: 643 with model SectionalMotif in generation 7 of 10
Model Number: 644 with model DatepartRegression in generation 7 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 644: DatepartRegression
Model Number: 645 with model DatepartRegression in generation 7 of 10
Model Number: 646 with model DatepartRegression in generation 7 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 646: DatepartRegression
Model Number: 647 with model VAR in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 647: VAR
Model Number: 648 with model VAR in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 648: VAR
Model Number: 649 with model VAR in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 649: VAR
Model Number: 650 with model VAR in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 650: VAR
Model Number: 651 with model VECM in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 651: VECM
Model Number: 652 with model VECM in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 652: VECM
Model Number: 653 with model VECM in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 653: VECM
Model Number: 654 with model VECM in generation 7 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 654: VECM
Model Number: 655 with model FBProphet in generation 7 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 655: FBProphet
Model Number: 656 with model FBProphet in generation 7 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 656: FBProphet
Model Number: 657 with model FBProphet in generation 7 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 657: FBProphet
Model Number: 658 with model FBProphet in generation 7 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 658: FBProphet
New Generation: 8 of 10
Model Number: 659 with model LastValueNaive in generation 8 of 10
Model Number: 660 with model LastValueNaive in generation 8 of 10
Model Number: 661 with model LastValueNaive in generation 8 of 10
Model Number: 662 with model ARDL in generation 8 of 10
Model Number: 663 with model ARDL in generation 8 of 10
Model Number: 664 with model ARDL in generation 8 of 10
Model Number: 665 with model ARDL in generation 8 of 10
Model Number: 666 with model NVAR in generation 8 of 10
Model Number: 667 with model NVAR in generation 8 of 10
Model Number: 668 with model NVAR in generation 8 of 10
Model Number: 669 with model NVAR in generation 8 of 10
Model Number: 670 with model Theta in generation 8 of 10
Model Number: 671 with model Theta in generation 8 of 10
Model Number: 672 with model Theta in generation 8 of 10
Model Number: 673 with model Theta in generation 8 of 10
Model Number: 674 with model UnivariateMotif in generation 8 of 10
Model Number: 675 with model UnivariateMotif in generation 8 of 10
Model Number: 676 with model UnivariateMotif in generation 8 of 10
Model Number: 677 with model AverageValueNaive in generation 8 of 10
Model Number: 678 with model AverageValueNaive in generation 8 of 10
Model Number: 679 with model AverageValueNaive in generation 8 of 10
Model Number: 680 with model ConstantNaive in generation 8 of 10
Model Number: 681 with model ConstantNaive in generation 8 of 10
Model Number: 682 with model ConstantNaive in generation 8 of 10
Model Number: 683 with model GLM in generation 8 of 10
Model Number: 684 with model GLM in generation 8 of 10
Template Eval Error: ValueError(&#39;NaN, inf or invalid value detected in weights, estimation infeasible.&#39;) in model 684: GLM
Model Number: 685 with model GLM in generation 8 of 10
Template Eval Error: ValueError(&#39;regression_type=user and no future_regressor passed&#39;) in model 685: GLM
Model Number: 686 with model GLM in generation 8 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:1346: RuntimeWarning:

invalid value encountered in log

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:516: RuntimeWarning:

overflow encountered in exp

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:1346: RuntimeWarning:

divide by zero encountered in log

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\numpy\core\fromnumeric.py:86: RuntimeWarning:

invalid value encountered in reduce

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:132: RuntimeWarning:

invalid value encountered in multiply

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:1212: RuntimeWarning:

invalid value encountered in multiply

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 687 with model UnobservedComponents in generation 8 of 10
Model Number: 688 with model UnobservedComponents in generation 8 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 688: UnobservedComponents
Model Number: 689 with model UnobservedComponents in generation 8 of 10
Model Number: 690 with model MultivariateRegression in generation 8 of 10
Model Number: 691 with model MultivariateRegression in generation 8 of 10
Model Number: 692 with model MultivariateRegression in generation 8 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 692: MultivariateRegression
Model Number: 693 with model MultivariateRegression in generation 8 of 10
Model Number: 694 with model SeasonalNaive in generation 8 of 10
Model Number: 695 with model SeasonalNaive in generation 8 of 10
Model Number: 696 with model SeasonalNaive in generation 8 of 10
Model Number: 697 with model SeasonalNaive in generation 8 of 10
Model Number: 698 with model GLS in generation 8 of 10
Model Number: 699 with model GLS in generation 8 of 10
Model Number: 700 with model GLS in generation 8 of 10
Model Number: 701 with model ETS in generation 8 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.961e+08, tolerance: 6.167e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 702 with model ETS in generation 8 of 10
Model Number: 703 with model ETS in generation 8 of 10
Model Number: 704 with model ETS in generation 8 of 10
Model Number: 705 with model WindowRegression in generation 8 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 705: WindowRegression
Model Number: 706 with model WindowRegression in generation 8 of 10
Model Number: 707 with model WindowRegression in generation 8 of 10
Model Number: 708 with model MultivariateMotif in generation 8 of 10
Model Number: 709 with model MultivariateMotif in generation 8 of 10
Model Number: 710 with model MultivariateMotif in generation 8 of 10
Model Number: 711 with model MultivariateMotif in generation 8 of 10
Model Number: 712 with model SectionalMotif in generation 8 of 10
Template Eval Error: ValueError(&#34;regression_type==&#39;User&#39; but no future_regressor supplied&#34;) in model 712: SectionalMotif
Model Number: 713 with model SectionalMotif in generation 8 of 10
Model Number: 714 with model SectionalMotif in generation 8 of 10
Model Number: 715 with model SectionalMotif in generation 8 of 10
Template Eval Error: ValueError(&#34;regression_type==&#39;User&#39; but no future_regressor supplied&#34;) in model 715: SectionalMotif
Model Number: 716 with model DatepartRegression in generation 8 of 10
Template Eval Error: ValueError(&#39;Failed to convert a NumPy array to a Tensor (Unsupported object type int).&#39;) in model 716: DatepartRegression
Model Number: 717 with model DatepartRegression in generation 8 of 10
Model Number: 718 with model DatepartRegression in generation 8 of 10
Model Number: 719 with model VAR in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 719: VAR
Model Number: 720 with model VAR in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 720: VAR
Model Number: 721 with model VAR in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 721: VAR
Model Number: 722 with model VAR in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 722: VAR
Model Number: 723 with model VECM in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 723: VECM
Model Number: 724 with model VECM in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 724: VECM
Model Number: 725 with model VECM in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 725: VECM
Model Number: 726 with model VECM in generation 8 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 726: VECM
Model Number: 727 with model FBProphet in generation 8 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 727: FBProphet
Model Number: 728 with model FBProphet in generation 8 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 728: FBProphet
Model Number: 729 with model FBProphet in generation 8 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 729: FBProphet
Model Number: 730 with model FBProphet in generation 8 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 730: FBProphet
New Generation: 9 of 10
Model Number: 731 with model LastValueNaive in generation 9 of 10
Model Number: 732 with model LastValueNaive in generation 9 of 10
Model Number: 733 with model LastValueNaive in generation 9 of 10
Model Number: 734 with model MultivariateMotif in generation 9 of 10
Model Number: 735 with model MultivariateMotif in generation 9 of 10
Model Number: 736 with model MultivariateMotif in generation 9 of 10
Model Number: 737 with model MultivariateMotif in generation 9 of 10
Model Number: 738 with model ARDL in generation 9 of 10
Model Number: 739 with model ARDL in generation 9 of 10
Model Number: 740 with model ARDL in generation 9 of 10
Model Number: 741 with model ARDL in generation 9 of 10
Model Number: 742 with model NVAR in generation 9 of 10
Model Number: 743 with model NVAR in generation 9 of 10
Model Number: 744 with model NVAR in generation 9 of 10
Model Number: 745 with model NVAR in generation 9 of 10
Model Number: 746 with model Theta in generation 9 of 10
Model Number: 747 with model Theta in generation 9 of 10
Model Number: 748 with model Theta in generation 9 of 10
Model Number: 749 with model Theta in generation 9 of 10
Model Number: 750 with model UnivariateMotif in generation 9 of 10
Model Number: 751 with model UnivariateMotif in generation 9 of 10
Model Number: 752 with model UnivariateMotif in generation 9 of 10
Model Number: 753 with model UnivariateMotif in generation 9 of 10
Model Number: 754 with model ConstantNaive in generation 9 of 10
Model Number: 755 with model ConstantNaive in generation 9 of 10
Model Number: 756 with model AverageValueNaive in generation 9 of 10
Model Number: 757 with model AverageValueNaive in generation 9 of 10
Model Number: 758 with model AverageValueNaive in generation 9 of 10
Model Number: 759 with model GLM in generation 9 of 10
Model Number: 760 with model GLM in generation 9 of 10
Template Eval Error: ValueError(&#39;regression_type=user and no future_regressor passed&#39;) in model 760: GLM
Model Number: 761 with model GLM in generation 9 of 10
Model Number: 762 with model UnobservedComponents in generation 9 of 10
Model Number: 763 with model UnobservedComponents in generation 9 of 10
Model Number: 764 with model UnobservedComponents in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 764: UnobservedComponents
Model Number: 765 with model MultivariateRegression in generation 9 of 10
Model Number: 766 with model MultivariateRegression in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 766: MultivariateRegression
Model Number: 767 with model MultivariateRegression in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 767: MultivariateRegression
Model Number: 768 with model MultivariateRegression in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but not future_regressor supplied.&#34;) in model 768: MultivariateRegression
Model Number: 769 with model SeasonalNaive in generation 9 of 10
Model Number: 770 with model SeasonalNaive in generation 9 of 10
Model Number: 771 with model SeasonalNaive in generation 9 of 10
Model Number: 772 with model SeasonalNaive in generation 9 of 10
Model Number: 773 with model ETS in generation 9 of 10
Model Number: 774 with model ETS in generation 9 of 10
Template Eval Error: KeyError(Timestamp(&#39;2019-06-17 00:00:00&#39;, freq=&#39;B&#39;)) in model 774: ETS
Model Number: 775 with model ETS in generation 9 of 10
Model Number: 776 with model ETS in generation 9 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\extmath.py:985: RuntimeWarning:

invalid value encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\extmath.py:990: RuntimeWarning:

invalid value encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\extmath.py:1020: RuntimeWarning:

invalid value encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\utils\validation.py:1692: FutureWarning:

Feature names only support names that are all strings. Got feature names with dtypes: [&#39;Timestamp&#39;, &#39;str&#39;]. An error will be raised in 1.2.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Template Eval Error: Exception(&#39;Transformer StandardScaler failed on fit&#39;) in model 776: ETS
Model Number: 777 with model GLS in generation 9 of 10
Model Number: 778 with model GLS in generation 9 of 10
Model Number: 779 with model GLS in generation 9 of 10
Model Number: 780 with model WindowRegression in generation 9 of 10
Epoch 1/50
19/19 [==============================] - 17s 162ms/step - loss: 101.1094 - val_loss: 113.5622
Epoch 2/50
19/19 [==============================] - 0s 22ms/step - loss: 100.5323 - val_loss: 113.5624
Epoch 3/50
19/19 [==============================] - 0s 24ms/step - loss: 100.6309 - val_loss: 113.5632
Epoch 4/50
19/19 [==============================] - 0s 22ms/step - loss: 100.4794 - val_loss: 113.5643
Epoch 5/50
19/19 [==============================] - 0s 26ms/step - loss: 100.5529 - val_loss: 113.5644
Epoch 6/50
19/19 [==============================] - 1s 28ms/step - loss: 100.2369 - val_loss: 113.5649
Epoch 7/50
19/19 [==============================] - 1s 31ms/step - loss: 100.0577 - val_loss: 113.5652
Epoch 8/50
19/19 [==============================] - 1s 27ms/step - loss: 100.1277 - val_loss: 113.5663
Epoch 9/50
19/19 [==============================] - 1s 30ms/step - loss: 100.4871 - val_loss: 113.5661
Epoch 10/50
19/19 [==============================] - 0s 22ms/step - loss: 100.5493 - val_loss: 113.5679
Epoch 11/50
19/19 [==============================] - 0s 23ms/step - loss: 100.5940 - val_loss: 113.5677
Model Number: 781 with model WindowRegression in generation 9 of 10
Model Number: 782 with model WindowRegression in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 782: WindowRegression
Model Number: 783 with model SectionalMotif in generation 9 of 10
Model Number: 784 with model SectionalMotif in generation 9 of 10
Model Number: 785 with model SectionalMotif in generation 9 of 10
Model Number: 786 with model SectionalMotif in generation 9 of 10
Model Number: 787 with model DatepartRegression in generation 9 of 10
Model Number: 788 with model DatepartRegression in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor passed&#34;) in model 788: DatepartRegression
Model Number: 789 with model DatepartRegression in generation 9 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+08, tolerance: 5.206e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 790 with model VAR in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 790: VAR
Model Number: 791 with model VAR in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 791: VAR
Model Number: 792 with model VAR in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 792: VAR
Model Number: 793 with model VAR in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VAR&#39;) in model 793: VAR
Model Number: 794 with model VECM in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 794: VECM
Model Number: 795 with model VECM in generation 9 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but no future_regressor supplied&#34;) in model 795: VECM
Model Number: 796 with model VECM in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 796: VECM
Model Number: 797 with model VECM in generation 9 of 10
Template Eval Error: ValueError(&#39;Only gave one variable to VECM&#39;) in model 797: VECM
Model Number: 798 with model FBProphet in generation 9 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 798: FBProphet
Model Number: 799 with model FBProphet in generation 9 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 799: FBProphet
Model Number: 800 with model FBProphet in generation 9 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 800: FBProphet
Model Number: 801 with model FBProphet in generation 9 of 10
Template Eval Error: ModuleNotFoundError(&#34;No module named &#39;fbprophet&#39;&#34;) in model 801: FBProphet
New Generation: 10 of 10
Model Number: 802 with model LastValueNaive in generation 10 of 10
Model Number: 803 with model LastValueNaive in generation 10 of 10
Model Number: 804 with model LastValueNaive in generation 10 of 10
Model Number: 805 with model MultivariateMotif in generation 10 of 10
Model Number: 806 with model MultivariateMotif in generation 10 of 10
Model Number: 807 with model MultivariateMotif in generation 10 of 10
Model Number: 808 with model MultivariateMotif in generation 10 of 10
Model Number: 809 with model ARDL in generation 10 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but future_regressor not supplied&#34;) in model 809: ARDL
Model Number: 810 with model ARDL in generation 10 of 10
Model Number: 811 with model ARDL in generation 10 of 10
Template Eval Error: ValueError(&#34;regression_type=&#39;User&#39; but future_regressor not supplied&#34;) in model 811: ARDL
Model Number: 812 with model ARDL in generation 10 of 10
Model Number: 813 with model NVAR in generation 10 of 10
Model Number: 814 with model NVAR in generation 10 of 10
Model Number: 815 with model NVAR in generation 10 of 10
Model Number: 816 with model NVAR in generation 10 of 10
Model Number: 817 with model Theta in generation 10 of 10
Model Number: 818 with model Theta in generation 10 of 10
Model Number: 819 with model Theta in generation 10 of 10
Model Number: 820 with model Theta in generation 10 of 10
Model Number: 821 with model UnivariateMotif in generation 10 of 10
Model Number: 822 with model UnivariateMotif in generation 10 of 10
Model Number: 823 with model UnivariateMotif in generation 10 of 10
Model Number: 824 with model UnivariateMotif in generation 10 of 10
Model Number: 825 with model ConstantNaive in generation 10 of 10
Model Number: 826 with model ConstantNaive in generation 10 of 10
Model Number: 827 with model ConstantNaive in generation 10 of 10
Model Number: 828 with model AverageValueNaive in generation 10 of 10
Model Number: 829 with model AverageValueNaive in generation 10 of 10
Model Number: 830 with model AverageValueNaive in generation 10 of 10
Model Number: 831 with model UnobservedComponents in generation 10 of 10
Template Eval Error: Exception(&#39;Transformer DatepartRegression failed on fit&#39;) in model 831: UnobservedComponents
Model Number: 832 with model UnobservedComponents in generation 10 of 10
Template Eval Error: ValueError(&#34;&#39;shape&#39; elements cannot be negative&#34;) in model 832: UnobservedComponents
Model Number: 833 with model UnobservedComponents in generation 10 of 10
Model Number: 834 with model GLM in generation 10 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\scipy\interpolate\polyint.py:545: RuntimeWarning:

overflow encountered in multiply

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\scipy\interpolate\polyint.py:546: RuntimeWarning:

overflow encountered in reduce

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\scipy\interpolate\polyint.py:643: RuntimeWarning:

invalid value encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 835 with model GLM in generation 10 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model Number: 836 with model GLM in generation 10 of 10
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\scipy\interpolate\polyint.py:545: RuntimeWarning:

overflow encountered in multiply

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\scipy\interpolate\polyint.py:546: RuntimeWarning:

overflow encountered in reduce

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\scipy\interpolate\polyint.py:643: RuntimeWarning:

invalid value encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Template Eval Error: TypeError(&#34;ufunc &#39;isfinite&#39; not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule &#39;&#39;safe&#39;&#39;&#34;) in model 836: GLM
Model Number: 837 with model GLM in generation 10 of 10
Model Number: 838 with model MultivariateRegression in generation 10 of 10
Model Number: 839 with model MultivariateRegression in generation 10 of 10
Model Number: 840 with model MultivariateRegression in generation 10 of 10
Model Number: 841 with model MultivariateRegression in generation 10 of 10
Model Number: 842 with model SeasonalNaive in generation 10 of 10
Model Number: 843 with model SeasonalNaive in generation 10 of 10
Model Number: 844 with model SeasonalNaive in generation 10 of 10
Model Number: 845 with model SeasonalNaive in generation 10 of 10
Model Number: 846 with model ETS in generation 10 of 10
Model Number: 847 with model ETS in generation 10 of 10
Model Number: 848 with model ETS in generation 10 of 10
Model Number: 849 with model ETS in generation 10 of 10
Model Number: 850 with model GLS in generation 10 of 10
Model Number: 851 with model GLS in generation 10 of 10
Model Number: 852 with model GLS in generation 10 of 10
Model Number: 853 with model WindowRegression in generation 10 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 853: WindowRegression
Model Number: 854 with model WindowRegression in generation 10 of 10
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002516 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
Model Number: 855 with model WindowRegression in generation 10 of 10
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 855: WindowRegression
Model Number: 856 with model Ensemble in generation 11 of Ensembles
Model Number: 857 with model Ensemble in generation 11 of Ensembles
Model Number: 858 with model Ensemble in generation 11 of Ensembles
Model Number: 859 with model Ensemble in generation 11 of Ensembles
Model Number: 860 with model Ensemble in generation 11 of Ensembles
Model Number: 861 with model Ensemble in generation 11 of Ensembles
Model Number: 862 with model Ensemble in generation 11 of Ensembles
Model Number: 863 with model Ensemble in generation 11 of Ensembles
Validation Round: 1
Model Number: 1 of 130 with model Ensemble for Validation 1
📈 1 - Ensemble with avg smape 2.42: 
Model Number: 2 of 130 with model Ensemble for Validation 1
2 - Ensemble with avg smape 2.42: 
Model Number: 3 of 130 with model Ensemble for Validation 1
📈 3 - Ensemble with avg smape 2.31: 
Model Number: 4 of 130 with model Ensemble for Validation 1
📈 4 - Ensemble with avg smape 2.18: 
Model Number: 5 of 130 with model Ensemble for Validation 1
📈 5 - Ensemble with avg smape 2.14: 
Model Number: 6 of 130 with model LastValueNaive for Validation 1
6 - LastValueNaive with avg smape 2.27: 
Model Number: 7 of 130 with model MultivariateRegression for Validation 1
7 - MultivariateRegression with avg smape 2.2: 
Model Number: 8 of 130 with model LastValueNaive for Validation 1
8 - LastValueNaive with avg smape 2.57: 
Model Number: 9 of 130 with model LastValueNaive for Validation 1
📈 9 - LastValueNaive with avg smape 2.05: 
Model Number: 10 of 130 with model LastValueNaive for Validation 1
10 - LastValueNaive with avg smape 2.05: 
Model Number: 11 of 130 with model Ensemble for Validation 1
11 - Ensemble with avg smape 2.05: 
Model Number: 12 of 130 with model LastValueNaive for Validation 1
12 - LastValueNaive with avg smape 2.05: 
Model Number: 13 of 130 with model LastValueNaive for Validation 1
13 - LastValueNaive with avg smape 2.06: 
Model Number: 14 of 130 with model LastValueNaive for Validation 1
14 - LastValueNaive with avg smape 2.1: 
Model Number: 15 of 130 with model LastValueNaive for Validation 1
15 - LastValueNaive with avg smape 2.29: 
Model Number: 16 of 130 with model MultivariateMotif for Validation 1
16 - MultivariateMotif with avg smape 8.22: 
Model Number: 17 of 130 with model ARDL for Validation 1
17 - ARDL with avg smape 2.7: 
Model Number: 18 of 130 with model NVAR for Validation 1
📈 18 - NVAR with avg smape 1.93: 
Model Number: 19 of 130 with model NVAR for Validation 1
19 - NVAR with avg smape 1.93: 
Model Number: 20 of 130 with model NVAR for Validation 1
20 - NVAR with avg smape 1.93: 
Model Number: 21 of 130 with model NVAR for Validation 1
21 - NVAR with avg smape 1.93: 
Model Number: 22 of 130 with model Ensemble for Validation 1
22 - Ensemble with avg smape 2.09: 
Model Number: 23 of 130 with model NVAR for Validation 1
📈 23 - NVAR with avg smape 1.85: 
Model Number: 24 of 130 with model NVAR for Validation 1
24 - NVAR with avg smape 2.29: 
Model Number: 25 of 130 with model Theta for Validation 1
25 - Theta with avg smape 3.06: 
Model Number: 26 of 130 with model Theta for Validation 1
26 - Theta with avg smape 3.06: 
Model Number: 27 of 130 with model NVAR for Validation 1
27 - NVAR with avg smape 2.04: 
Model Number: 28 of 130 with model NVAR for Validation 1
28 - NVAR with avg smape 2.04: 
Model Number: 29 of 130 with model Theta for Validation 1
📈 29 - Theta with avg smape 1.65: 
Model Number: 30 of 130 with model ARDL for Validation 1
30 - ARDL with avg smape 3.73: 
Model Number: 31 of 130 with model Theta for Validation 1
31 - Theta with avg smape 2.69: 
Model Number: 32 of 130 with model Theta for Validation 1
32 - Theta with avg smape 2.66: 
Model Number: 33 of 130 with model UnivariateMotif for Validation 1
33 - UnivariateMotif with avg smape 2.8: 
Model Number: 34 of 130 with model UnivariateMotif for Validation 1
34 - UnivariateMotif with avg smape 2.54: 
Model Number: 35 of 130 with model Theta for Validation 1
35 - Theta with avg smape 2.63: 
Model Number: 36 of 130 with model Theta for Validation 1
36 - Theta with avg smape 2.07: 
Model Number: 37 of 130 with model Theta for Validation 1
37 - Theta with avg smape 2.7: 
Model Number: 38 of 130 with model ARDL for Validation 1
38 - ARDL with avg smape 4.06: 
Model Number: 39 of 130 with model ARDL for Validation 1
39 - ARDL with avg smape 3.61: 
Model Number: 40 of 130 with model ConstantNaive for Validation 1
40 - ConstantNaive with avg smape 2.11: 
Model Number: 41 of 130 with model ConstantNaive for Validation 1
41 - ConstantNaive with avg smape 2.11: 
Model Number: 42 of 130 with model ARDL for Validation 1
42 - ARDL with avg smape 4.06: 
Model Number: 43 of 130 with model ARDL for Validation 1
43 - ARDL with avg smape 3.69: 
Model Number: 44 of 130 with model ARDL for Validation 1
44 - ARDL with avg smape 3.7: 
Model Number: 45 of 130 with model AverageValueNaive for Validation 1
45 - AverageValueNaive with avg smape 1.73: 
Model Number: 46 of 130 with model ARDL for Validation 1
46 - ARDL with avg smape 2.76: 
Model Number: 47 of 130 with model Ensemble for Validation 1
47 - Ensemble with avg smape 2.29: 
Model Number: 48 of 130 with model ConstantNaive for Validation 1
48 - ConstantNaive with avg smape 2.7: 
Model Number: 49 of 130 with model ConstantNaive for Validation 1
49 - ConstantNaive with avg smape 2.7: 
Model Number: 50 of 130 with model ConstantNaive for Validation 1
50 - ConstantNaive with avg smape 2.7: 
Model Number: 51 of 130 with model ConstantNaive for Validation 1
51 - ConstantNaive with avg smape 2.7: 
Model Number: 52 of 130 with model ConstantNaive for Validation 1
52 - ConstantNaive with avg smape 2.7: 
Model Number: 53 of 130 with model ConstantNaive for Validation 1
53 - ConstantNaive with avg smape 2.7: 
Model Number: 54 of 130 with model AverageValueNaive for Validation 1
54 - AverageValueNaive with avg smape 3.89: 
Model Number: 55 of 130 with model UnobservedComponents for Validation 1
55 - UnobservedComponents with avg smape 2.76: 
Model Number: 56 of 130 with model MultivariateRegression for Validation 1
56 - MultivariateRegression with avg smape 1.7: 
Model Number: 57 of 130 with model UnobservedComponents for Validation 1
57 - UnobservedComponents with avg smape 3.54: 
Model Number: 58 of 130 with model GLM for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>58 - GLM with avg smape 1.79: 
Model Number: 59 of 130 with model GLM for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:426: RuntimeWarning:

divide by zero encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>59 - GLM with avg smape 1.79: 
Model Number: 60 of 130 with model GLM for Validation 1
Template Eval Error: ValueError(&#39;NaN, inf or invalid value detected in weights, estimation infeasible.&#39;) in model 60: GLM
Model Number: 61 of 130 with model GLM for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:132: RuntimeWarning:

divide by zero encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>61 - GLM with avg smape 1.79: 
Model Number: 62 of 130 with model GLM for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>62 - GLM with avg smape 1.79: 
Model Number: 63 of 130 with model GLM for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>63 - GLM with avg smape 1.79: 
Model Number: 64 of 130 with model GLM for Validation 1
64 - GLM with avg smape 1.79: 
Model Number: 65 of 130 with model GLM for Validation 1
65 - GLM with avg smape 1.78: 
Model Number: 66 of 130 with model MultivariateRegression for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:67: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

invalid value encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>66 - MultivariateRegression with avg smape 8.45: 
Model Number: 67 of 130 with model AverageValueNaive for Validation 1
67 - AverageValueNaive with avg smape 6.95: 
Model Number: 68 of 130 with model UnivariateMotif for Validation 1
68 - UnivariateMotif with avg smape 3.42: 
Model Number: 69 of 130 with model SeasonalNaive for Validation 1
69 - SeasonalNaive with avg smape 2.5: 
Model Number: 70 of 130 with model WindowRegression for Validation 1
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003725 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
70 - WindowRegression with avg smape 2.98: 
Model Number: 71 of 130 with model UnobservedComponents for Validation 1
📈 71 - UnobservedComponents with avg smape 1.57: 
Model Number: 72 of 130 with model GLS for Validation 1
72 - GLS with avg smape 3.55: 
Model Number: 73 of 130 with model UnobservedComponents for Validation 1
73 - UnobservedComponents with avg smape 3.71: 
Model Number: 74 of 130 with model UnivariateMotif for Validation 1
74 - UnivariateMotif with avg smape 4.18: 
Model Number: 75 of 130 with model ETS for Validation 1
75 - ETS with avg smape 3.49: 
Model Number: 76 of 130 with model ETS for Validation 1
76 - ETS with avg smape 3.5: 
Model Number: 77 of 130 with model UnobservedComponents for Validation 1
77 - UnobservedComponents with avg smape 4.27: 
Model Number: 78 of 130 with model MultivariateRegression for Validation 1
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 78: MultivariateRegression
Model Number: 79 of 130 with model ETS for Validation 1
79 - ETS with avg smape 3.49: 
Model Number: 80 of 130 with model GLS for Validation 1
80 - GLS with avg smape 3.54: 
Model Number: 81 of 130 with model SeasonalNaive for Validation 1
📈 81 - SeasonalNaive with avg smape 1.49: 
Model Number: 82 of 130 with model ETS for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.766e+08, tolerance: 5.935e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>82 - ETS with avg smape 5.09: 
Model Number: 83 of 130 with model MultivariateRegression for Validation 1
83 - MultivariateRegression with avg smape 3.25: 
Model Number: 84 of 130 with model ETS for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.058e-01, tolerance: 1.893e-02

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>84 - ETS with avg smape 4.7: 
Model Number: 85 of 130 with model SeasonalNaive for Validation 1
85 - SeasonalNaive with avg smape 2.32: 
Model Number: 86 of 130 with model UnobservedComponents for Validation 1
86 - UnobservedComponents with avg smape 3.94: 
Model Number: 87 of 130 with model SeasonalNaive for Validation 1
87 - SeasonalNaive with avg smape 2.34: 
Model Number: 88 of 130 with model SeasonalNaive for Validation 1
88 - SeasonalNaive with avg smape 2.1: 
Model Number: 89 of 130 with model UnivariateMotif for Validation 1
89 - UnivariateMotif with avg smape 5.06: 
Model Number: 90 of 130 with model UnobservedComponents for Validation 1
90 - UnobservedComponents with avg smape 3.79: 
Model Number: 91 of 130 with model AverageValueNaive for Validation 1
91 - AverageValueNaive with avg smape 2.01: 
Model Number: 92 of 130 with model AverageValueNaive for Validation 1
92 - AverageValueNaive with avg smape 7.63: 
Model Number: 93 of 130 with model WindowRegression for Validation 1
93 - WindowRegression with avg smape 5.92: 
Model Number: 94 of 130 with model WindowRegression for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.7s
[Parallel(n_jobs=-2)]: Done 444 tasks      | elapsed:    1.6s
[Parallel(n_jobs=-2)]: Done 794 tasks      | elapsed:    3.0s
[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    3.7s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.4s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.4s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.5s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>94 - WindowRegression with avg smape 4.03: 
Model Number: 95 of 130 with model WindowRegression for Validation 1
95 - WindowRegression with avg smape 2.2: 
Model Number: 96 of 130 with model MultivariateRegression for Validation 1
96 - MultivariateRegression with avg smape 1.99: 
Model Number: 97 of 130 with model GLS for Validation 1
97 - GLS with avg smape 4.49: 
Model Number: 98 of 130 with model WindowRegression for Validation 1
98 - WindowRegression with avg smape 1.71: 
Model Number: 99 of 130 with model ETS for Validation 1
99 - ETS with avg smape 4.31: 
Model Number: 100 of 130 with model SectionalMotif for Validation 1
100 - SectionalMotif with avg smape 3.32: 
Model Number: 101 of 130 with model UnobservedComponents for Validation 1
101 - UnobservedComponents with avg smape 4.48: 
Model Number: 102 of 130 with model WindowRegression for Validation 1
102 - WindowRegression with avg smape 2.61: 
Model Number: 103 of 130 with model SeasonalNaive for Validation 1
103 - SeasonalNaive with avg smape 2.28: 
Model Number: 104 of 130 with model ETS for Validation 1
104 - ETS with avg smape 4.86: 
Model Number: 105 of 130 with model ETS for Validation 1
105 - ETS with avg smape 3.48: 
Model Number: 106 of 130 with model MultivariateMotif for Validation 1
106 - MultivariateMotif with avg smape 16.13: 
Model Number: 107 of 130 with model SectionalMotif for Validation 1
107 - SectionalMotif with avg smape 3.41: 
Model Number: 108 of 130 with model MultivariateMotif for Validation 1
108 - MultivariateMotif with avg smape 3.07: 
Model Number: 109 of 130 with model SeasonalNaive for Validation 1
109 - SeasonalNaive with avg smape 4.81: 
Model Number: 110 of 130 with model WindowRegression for Validation 1
110 - WindowRegression with avg smape 3.24: 
Model Number: 111 of 130 with model MultivariateMotif for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.379e+06, tolerance: 5.816e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>111 - MultivariateMotif with avg smape 2.24: 
Model Number: 112 of 130 with model UnivariateMotif for Validation 1
112 - UnivariateMotif with avg smape 3.75: 
Model Number: 113 of 130 with model MultivariateRegression for Validation 1
113 - MultivariateRegression with avg smape 3.49: 
Model Number: 114 of 130 with model MultivariateMotif for Validation 1
114 - MultivariateMotif with avg smape 3.74: 
Model Number: 115 of 130 with model UnivariateMotif for Validation 1
115 - UnivariateMotif with avg smape 2.21: 
Model Number: 116 of 130 with model AverageValueNaive for Validation 1
116 - AverageValueNaive with avg smape 1.78: 
Model Number: 117 of 130 with model GLS for Validation 1
117 - GLS with avg smape 3.93: 
Model Number: 118 of 130 with model AverageValueNaive for Validation 1
118 - AverageValueNaive with avg smape 5.27: 
Model Number: 119 of 130 with model MultivariateRegression for Validation 1
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>119 - MultivariateRegression with avg smape 3.97: 
Model Number: 120 of 130 with model WindowRegression for Validation 1
Epoch 1/50
18/18 [==============================] - 10s 84ms/step - loss: 99.2440 - val_loss: 111.3699
Epoch 2/50
18/18 [==============================] - 0s 24ms/step - loss: 99.2834 - val_loss: 111.3751
Epoch 3/50
18/18 [==============================] - 0s 24ms/step - loss: 99.2982 - val_loss: 111.3863
Epoch 4/50
18/18 [==============================] - 0s 24ms/step - loss: 99.2836 - val_loss: 111.3936
Epoch 5/50
18/18 [==============================] - 0s 23ms/step - loss: 99.2469 - val_loss: 111.4016
Epoch 6/50
18/18 [==============================] - 0s 23ms/step - loss: 99.1917 - val_loss: 111.4130
Epoch 7/50
18/18 [==============================] - 0s 23ms/step - loss: 99.2039 - val_loss: 111.4200
Epoch 8/50
18/18 [==============================] - 0s 27ms/step - loss: 99.2091 - val_loss: 111.4346
Epoch 9/50
18/18 [==============================] - 1s 28ms/step - loss: 99.2968 - val_loss: 111.4445
Epoch 10/50
18/18 [==============================] - 0s 26ms/step - loss: 99.2864 - val_loss: 111.4534
Epoch 11/50
18/18 [==============================] - 1s 31ms/step - loss: 99.2964 - val_loss: 111.4684
120 - WindowRegression with avg smape 4.71: 
Model Number: 121 of 130 with model MultivariateMotif for Validation 1
121 - MultivariateMotif with avg smape 7.41: 
Model Number: 122 of 130 with model SectionalMotif for Validation 1
122 - SectionalMotif with avg smape 5.63: 
Model Number: 123 of 130 with model DatepartRegression for Validation 1
123 - DatepartRegression with avg smape 7.22: 
Model Number: 124 of 130 with model SeasonalNaive for Validation 1
124 - SeasonalNaive with avg smape 3.03: 
Model Number: 125 of 130 with model MultivariateMotif for Validation 1
125 - MultivariateMotif with avg smape 4.55: 
Model Number: 126 of 130 with model UnivariateMotif for Validation 1
126 - UnivariateMotif with avg smape 2.78: 
Model Number: 127 of 130 with model SectionalMotif for Validation 1
127 - SectionalMotif with avg smape 4.09: 
Model Number: 128 of 130 with model SectionalMotif for Validation 1
128 - SectionalMotif with avg smape 3.4: 
Model Number: 129 of 130 with model GLS for Validation 1
129 - GLS with avg smape 2.73: 
Model Number: 130 of 130 with model MultivariateMotif for Validation 1
130 - MultivariateMotif with avg smape 3.41: 
Validation Round: 2
Model Number: 1 of 130 with model Ensemble for Validation 2
📈 1 - Ensemble with avg smape 13.2: 
Model Number: 2 of 130 with model Ensemble for Validation 2
2 - Ensemble with avg smape 13.2: 
Model Number: 3 of 130 with model Ensemble for Validation 2
📈 3 - Ensemble with avg smape 12.29: 
Model Number: 4 of 130 with model Ensemble for Validation 2
📈 4 - Ensemble with avg smape 2.0: 
Model Number: 5 of 130 with model Ensemble for Validation 2
5 - Ensemble with avg smape 2.11: 
Model Number: 6 of 130 with model LastValueNaive for Validation 2
6 - LastValueNaive with avg smape 2.16: 
Model Number: 7 of 130 with model MultivariateRegression for Validation 2
7 - MultivariateRegression with avg smape 2.33: 
Model Number: 8 of 130 with model LastValueNaive for Validation 2
8 - LastValueNaive with avg smape 6.16: 
Model Number: 9 of 130 with model LastValueNaive for Validation 2
📈 9 - LastValueNaive with avg smape 1.86: 
Model Number: 10 of 130 with model LastValueNaive for Validation 2
10 - LastValueNaive with avg smape 1.86: 
Model Number: 11 of 130 with model Ensemble for Validation 2
11 - Ensemble with avg smape 1.86: 
Model Number: 12 of 130 with model LastValueNaive for Validation 2
12 - LastValueNaive with avg smape 1.86: 
Model Number: 13 of 130 with model LastValueNaive for Validation 2
13 - LastValueNaive with avg smape 1.87: 
Model Number: 14 of 130 with model LastValueNaive for Validation 2
14 - LastValueNaive with avg smape 1.9: 
Model Number: 15 of 130 with model LastValueNaive for Validation 2
15 - LastValueNaive with avg smape 2.17: 
Model Number: 16 of 130 with model MultivariateMotif for Validation 2
16 - MultivariateMotif with avg smape 47.41: 
Model Number: 17 of 130 with model ARDL for Validation 2
17 - ARDL with avg smape 2.91: 
Model Number: 18 of 130 with model NVAR for Validation 2
📈 18 - NVAR with avg smape 1.65: 
Model Number: 19 of 130 with model NVAR for Validation 2
19 - NVAR with avg smape 1.65: 
Model Number: 20 of 130 with model NVAR for Validation 2
20 - NVAR with avg smape 1.65: 
Model Number: 21 of 130 with model NVAR for Validation 2
21 - NVAR with avg smape 1.65: 
Model Number: 22 of 130 with model Ensemble for Validation 2
22 - Ensemble with avg smape 2.03: 
Model Number: 23 of 130 with model NVAR for Validation 2
23 - NVAR with avg smape 1.65: 
Model Number: 24 of 130 with model NVAR for Validation 2
24 - NVAR with avg smape 1.67: 
Model Number: 25 of 130 with model Theta for Validation 2
25 - Theta with avg smape 5.05: 
Model Number: 26 of 130 with model Theta for Validation 2
26 - Theta with avg smape 5.05: 
Model Number: 27 of 130 with model NVAR for Validation 2
27 - NVAR with avg smape 1.76: 
Model Number: 28 of 130 with model NVAR for Validation 2
28 - NVAR with avg smape 1.76: 
Model Number: 29 of 130 with model Theta for Validation 2
29 - Theta with avg smape 1.86: 
Model Number: 30 of 130 with model ARDL for Validation 2
30 - ARDL with avg smape 3.54: 
Model Number: 31 of 130 with model Theta for Validation 2
31 - Theta with avg smape 2.29: 
Model Number: 32 of 130 with model Theta for Validation 2
32 - Theta with avg smape 2.26: 
Model Number: 33 of 130 with model UnivariateMotif for Validation 2
33 - UnivariateMotif with avg smape 2.42: 
Model Number: 34 of 130 with model UnivariateMotif for Validation 2
34 - UnivariateMotif with avg smape 3.1: 
Model Number: 35 of 130 with model Theta for Validation 2
35 - Theta with avg smape 2.27: 
Model Number: 36 of 130 with model Theta for Validation 2
36 - Theta with avg smape 2.04: 
Model Number: 37 of 130 with model Theta for Validation 2
37 - Theta with avg smape 2.31: 
Model Number: 38 of 130 with model ARDL for Validation 2
38 - ARDL with avg smape 3.49: 
Model Number: 39 of 130 with model ARDL for Validation 2
39 - ARDL with avg smape 3.25: 
Model Number: 40 of 130 with model ConstantNaive for Validation 2
40 - ConstantNaive with avg smape 2.18: 
Model Number: 41 of 130 with model ConstantNaive for Validation 2
41 - ConstantNaive with avg smape 2.18: 
Model Number: 42 of 130 with model ARDL for Validation 2
42 - ARDL with avg smape 3.35: 
Model Number: 43 of 130 with model ARDL for Validation 2
43 - ARDL with avg smape 3.25: 
Model Number: 44 of 130 with model ARDL for Validation 2
44 - ARDL with avg smape 3.24: 
Model Number: 45 of 130 with model AverageValueNaive for Validation 2
45 - AverageValueNaive with avg smape 2.15: 
Model Number: 46 of 130 with model ARDL for Validation 2
46 - ARDL with avg smape 2.71: 
Model Number: 47 of 130 with model Ensemble for Validation 2
47 - Ensemble with avg smape 4.24: 
Model Number: 48 of 130 with model ConstantNaive for Validation 2
48 - ConstantNaive with avg smape 2.38: 
Model Number: 49 of 130 with model ConstantNaive for Validation 2
49 - ConstantNaive with avg smape 2.38: 
Model Number: 50 of 130 with model ConstantNaive for Validation 2
50 - ConstantNaive with avg smape 2.38: 
Model Number: 51 of 130 with model ConstantNaive for Validation 2
51 - ConstantNaive with avg smape 2.38: 
Model Number: 52 of 130 with model ConstantNaive for Validation 2
52 - ConstantNaive with avg smape 2.38: 
Model Number: 53 of 130 with model ConstantNaive for Validation 2
53 - ConstantNaive with avg smape 2.38: 
Model Number: 54 of 130 with model AverageValueNaive for Validation 2
54 - AverageValueNaive with avg smape 3.32: 
Model Number: 55 of 130 with model UnobservedComponents for Validation 2
55 - UnobservedComponents with avg smape 2.7: 
Model Number: 56 of 130 with model MultivariateRegression for Validation 2
56 - MultivariateRegression with avg smape 9.03: 
Model Number: 57 of 130 with model UnobservedComponents for Validation 2
57 - UnobservedComponents with avg smape 3.85: 
Model Number: 58 of 130 with model GLM for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>58 - GLM with avg smape 3.77: 
Model Number: 59 of 130 with model GLM for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>59 - GLM with avg smape 3.77: 
Model Number: 60 of 130 with model GLM for Validation 2
Template Eval Error: ValueError(&#39;NaN, inf or invalid value detected in weights, estimation infeasible.&#39;) in model 60: GLM
Model Number: 61 of 130 with model GLM for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:426: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\family.py:132: RuntimeWarning:

divide by zero encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>61 - GLM with avg smape 3.77: 
Model Number: 62 of 130 with model GLM for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>62 - GLM with avg smape 3.77: 
Model Number: 63 of 130 with model GLM for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>63 - GLM with avg smape 3.77: 
Model Number: 64 of 130 with model GLM for Validation 2
64 - GLM with avg smape 3.77: 
Model Number: 65 of 130 with model GLM for Validation 2
65 - GLM with avg smape 3.77: 
Model Number: 66 of 130 with model MultivariateRegression for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:67: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

invalid value encountered in true_divide

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>66 - MultivariateRegression with avg smape 12.15: 
Model Number: 67 of 130 with model AverageValueNaive for Validation 2
67 - AverageValueNaive with avg smape 4.34: 
Model Number: 68 of 130 with model UnivariateMotif for Validation 2
68 - UnivariateMotif with avg smape 3.28: 
Model Number: 69 of 130 with model SeasonalNaive for Validation 2
69 - SeasonalNaive with avg smape 7.93: 
Model Number: 70 of 130 with model WindowRegression for Validation 2
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
70 - WindowRegression with avg smape 2.85: 
Model Number: 71 of 130 with model UnobservedComponents for Validation 2
71 - UnobservedComponents with avg smape 2.32: 
Model Number: 72 of 130 with model GLS for Validation 2
72 - GLS with avg smape 3.22: 
Model Number: 73 of 130 with model UnobservedComponents for Validation 2
73 - UnobservedComponents with avg smape 3.37: 
Model Number: 74 of 130 with model UnivariateMotif for Validation 2
74 - UnivariateMotif with avg smape 5.14: 
Model Number: 75 of 130 with model ETS for Validation 2
75 - ETS with avg smape 3.04: 
Model Number: 76 of 130 with model ETS for Validation 2
76 - ETS with avg smape 3.04: 
Model Number: 77 of 130 with model UnobservedComponents for Validation 2
77 - UnobservedComponents with avg smape 3.93: 
Model Number: 78 of 130 with model MultivariateRegression for Validation 2
78 - MultivariateRegression with avg smape 2.16: 
Model Number: 79 of 130 with model ETS for Validation 2
79 - ETS with avg smape 3.17: 
Model Number: 80 of 130 with model GLS for Validation 2
80 - GLS with avg smape 3.06: 
Model Number: 81 of 130 with model SeasonalNaive for Validation 2
81 - SeasonalNaive with avg smape 1.84: 
Model Number: 82 of 130 with model ETS for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.312e+08, tolerance: 5.467e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>82 - ETS with avg smape 3.47: 
Model Number: 83 of 130 with model MultivariateRegression for Validation 2
83 - MultivariateRegression with avg smape 2.21: 
Model Number: 84 of 130 with model ETS for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+00, tolerance: 1.803e-02

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>84 - ETS with avg smape 3.84: 
Model Number: 85 of 130 with model SeasonalNaive for Validation 2
85 - SeasonalNaive with avg smape 5.52: 
Model Number: 86 of 130 with model UnobservedComponents for Validation 2
86 - UnobservedComponents with avg smape 3.19: 
Model Number: 87 of 130 with model SeasonalNaive for Validation 2
87 - SeasonalNaive with avg smape 5.5: 
Model Number: 88 of 130 with model SeasonalNaive for Validation 2
88 - SeasonalNaive with avg smape 3.67: 
Model Number: 89 of 130 with model UnivariateMotif for Validation 2
89 - UnivariateMotif with avg smape 3.52: 
Model Number: 90 of 130 with model UnobservedComponents for Validation 2
90 - UnobservedComponents with avg smape 3.21: 
Model Number: 91 of 130 with model AverageValueNaive for Validation 2
91 - AverageValueNaive with avg smape 1.96: 
Model Number: 92 of 130 with model AverageValueNaive for Validation 2
92 - AverageValueNaive with avg smape 12.27: 
Model Number: 93 of 130 with model WindowRegression for Validation 2
93 - WindowRegression with avg smape 3.37: 
Model Number: 94 of 130 with model WindowRegression for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-2)]: Done 444 tasks      | elapsed:    1.8s
[Parallel(n_jobs=-2)]: Done 794 tasks      | elapsed:    3.8s
[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    4.9s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.4s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.6s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.3s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.3s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>94 - WindowRegression with avg smape 3.2: 
Model Number: 95 of 130 with model WindowRegression for Validation 2
95 - WindowRegression with avg smape 1.77: 
Model Number: 96 of 130 with model MultivariateRegression for Validation 2
96 - MultivariateRegression with avg smape 6.62: 
Model Number: 97 of 130 with model GLS for Validation 2
97 - GLS with avg smape 3.74: 
Model Number: 98 of 130 with model WindowRegression for Validation 2
98 - WindowRegression with avg smape 1.89: 
Model Number: 99 of 130 with model ETS for Validation 2
99 - ETS with avg smape 2.87: 
Model Number: 100 of 130 with model SectionalMotif for Validation 2
100 - SectionalMotif with avg smape 5.26: 
Model Number: 101 of 130 with model UnobservedComponents for Validation 2
101 - UnobservedComponents with avg smape 3.73: 
Model Number: 102 of 130 with model WindowRegression for Validation 2
102 - WindowRegression with avg smape 10.88: 
Model Number: 103 of 130 with model SeasonalNaive for Validation 2
103 - SeasonalNaive with avg smape 1.93: 
Model Number: 104 of 130 with model ETS for Validation 2
104 - ETS with avg smape 4.14: 
Model Number: 105 of 130 with model ETS for Validation 2
105 - ETS with avg smape 3.36: 
Model Number: 106 of 130 with model MultivariateMotif for Validation 2
106 - MultivariateMotif with avg smape 17.36: 
Model Number: 107 of 130 with model SectionalMotif for Validation 2
107 - SectionalMotif with avg smape 8.29: 
Model Number: 108 of 130 with model MultivariateMotif for Validation 2
108 - MultivariateMotif with avg smape 2.49: 
Model Number: 109 of 130 with model SeasonalNaive for Validation 2
109 - SeasonalNaive with avg smape 5.45: 
Model Number: 110 of 130 with model WindowRegression for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.521e+06, tolerance: 5.406e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>110 - WindowRegression with avg smape 2.81: 
Model Number: 111 of 130 with model MultivariateMotif for Validation 2
111 - MultivariateMotif with avg smape 7.09: 
Model Number: 112 of 130 with model UnivariateMotif for Validation 2
112 - UnivariateMotif with avg smape 1.8: 
Model Number: 113 of 130 with model MultivariateRegression for Validation 2
113 - MultivariateRegression with avg smape 2.17: 
Model Number: 114 of 130 with model MultivariateMotif for Validation 2
114 - MultivariateMotif with avg smape 8.75: 
Model Number: 115 of 130 with model UnivariateMotif for Validation 2
115 - UnivariateMotif with avg smape 7.46: 
Model Number: 116 of 130 with model AverageValueNaive for Validation 2
116 - AverageValueNaive with avg smape 4.61: 
Model Number: 117 of 130 with model GLS for Validation 2
117 - GLS with avg smape 3.48: 
Model Number: 118 of 130 with model AverageValueNaive for Validation 2
118 - AverageValueNaive with avg smape 3.74: 
Model Number: 119 of 130 with model MultivariateRegression for Validation 2
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.4s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.1s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.3s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>119 - MultivariateRegression with avg smape 2.28: 
Model Number: 120 of 130 with model WindowRegression for Validation 2
Epoch 1/50
18/18 [==============================] - 24s 310ms/step - loss: 99.5590 - val_loss: 103.4906
Epoch 2/50
18/18 [==============================] - 1s 44ms/step - loss: 98.5988 - val_loss: 103.4897
Epoch 3/50
18/18 [==============================] - 1s 42ms/step - loss: 98.0109 - val_loss: 103.4895
Epoch 4/50
18/18 [==============================] - 1s 46ms/step - loss: 97.7775 - val_loss: 103.4966
Epoch 5/50
18/18 [==============================] - 1s 44ms/step - loss: 98.3618 - val_loss: 103.5075
Epoch 6/50
18/18 [==============================] - 1s 58ms/step - loss: 97.5772 - val_loss: 103.5201
Epoch 7/50
18/18 [==============================] - 1s 48ms/step - loss: 99.9695 - val_loss: 103.5243
Epoch 8/50
18/18 [==============================] - 1s 43ms/step - loss: 99.5447 - val_loss: 103.5418
Epoch 9/50
18/18 [==============================] - 1s 61ms/step - loss: 99.2083 - val_loss: 103.5426
Epoch 10/50
18/18 [==============================] - 1s 52ms/step - loss: 100.1419 - val_loss: 103.5384
Epoch 11/50
18/18 [==============================] - 1s 43ms/step - loss: 98.6760 - val_loss: 103.5516
Epoch 12/50
18/18 [==============================] - 1s 39ms/step - loss: 99.9153 - val_loss: 103.5497
Epoch 13/50
18/18 [==============================] - 1s 43ms/step - loss: 98.8464 - val_loss: 103.5610
120 - WindowRegression with avg smape 3.88: 
Model Number: 121 of 130 with model MultivariateMotif for Validation 2
121 - MultivariateMotif with avg smape 3.07: 
Model Number: 122 of 130 with model SectionalMotif for Validation 2
122 - SectionalMotif with avg smape 4.27: 
Model Number: 123 of 130 with model DatepartRegression for Validation 2
123 - DatepartRegression with avg smape 3.08: 
Model Number: 124 of 130 with model SeasonalNaive for Validation 2
124 - SeasonalNaive with avg smape 7.14: 
Model Number: 125 of 130 with model MultivariateMotif for Validation 2
125 - MultivariateMotif with avg smape 4.06: 
Model Number: 126 of 130 with model UnivariateMotif for Validation 2
126 - UnivariateMotif with avg smape 1.84: 
Model Number: 127 of 130 with model SectionalMotif for Validation 2
127 - SectionalMotif with avg smape 3.28: 
Model Number: 128 of 130 with model SectionalMotif for Validation 2
128 - SectionalMotif with avg smape 7.18: 
Model Number: 129 of 130 with model GLS for Validation 2
129 - GLS with avg smape 6.82: 
Model Number: 130 of 130 with model MultivariateMotif for Validation 2
130 - MultivariateMotif with avg smape 8.57: 
Validation Round: 3
Model Number: 1 of 130 with model Ensemble for Validation 3
📈 1 - Ensemble with avg smape 1.42: 
Model Number: 2 of 130 with model Ensemble for Validation 3
2 - Ensemble with avg smape 1.42: 
Model Number: 3 of 130 with model Ensemble for Validation 3
3 - Ensemble with avg smape 1.42: 
Model Number: 4 of 130 with model Ensemble for Validation 3
📈 4 - Ensemble with avg smape 1.29: 
Model Number: 5 of 130 with model Ensemble for Validation 3
5 - Ensemble with avg smape 1.31: 
Model Number: 6 of 130 with model LastValueNaive for Validation 3
6 - LastValueNaive with avg smape 1.42: 
Model Number: 7 of 130 with model MultivariateRegression for Validation 3
7 - MultivariateRegression with avg smape 1.89: 
Model Number: 8 of 130 with model LastValueNaive for Validation 3
8 - LastValueNaive with avg smape 10.44: 
Model Number: 9 of 130 with model LastValueNaive for Validation 3
📈 9 - LastValueNaive with avg smape 1.1: 
Model Number: 10 of 130 with model LastValueNaive for Validation 3
10 - LastValueNaive with avg smape 1.1: 
Model Number: 11 of 130 with model Ensemble for Validation 3
11 - Ensemble with avg smape 1.1: 
Model Number: 12 of 130 with model LastValueNaive for Validation 3
12 - LastValueNaive with avg smape 1.1: 
Model Number: 13 of 130 with model LastValueNaive for Validation 3
13 - LastValueNaive with avg smape 1.1: 
Model Number: 14 of 130 with model LastValueNaive for Validation 3
📈 14 - LastValueNaive with avg smape 1.09: 
Model Number: 15 of 130 with model LastValueNaive for Validation 3
15 - LastValueNaive with avg smape 1.49: 
Model Number: 16 of 130 with model MultivariateMotif for Validation 3
16 - MultivariateMotif with avg smape 1.65: 
Model Number: 17 of 130 with model ARDL for Validation 3
17 - ARDL with avg smape 1.61: 
Model Number: 18 of 130 with model NVAR for Validation 3
18 - NVAR with avg smape 1.74: 
Model Number: 19 of 130 with model NVAR for Validation 3
19 - NVAR with avg smape 1.74: 
Model Number: 20 of 130 with model NVAR for Validation 3
20 - NVAR with avg smape 1.74: 
Model Number: 21 of 130 with model NVAR for Validation 3
21 - NVAR with avg smape 1.74: 
Model Number: 22 of 130 with model Ensemble for Validation 3
22 - Ensemble with avg smape 1.09: 
Model Number: 23 of 130 with model NVAR for Validation 3
23 - NVAR with avg smape 1.72: 
Model Number: 24 of 130 with model NVAR for Validation 3
24 - NVAR with avg smape 1.48: 
Model Number: 25 of 130 with model Theta for Validation 3
25 - Theta with avg smape 1.43: 
Model Number: 26 of 130 with model Theta for Validation 3
26 - Theta with avg smape 1.43: 
Model Number: 27 of 130 with model NVAR for Validation 3
27 - NVAR with avg smape 1.57: 
Model Number: 28 of 130 with model NVAR for Validation 3
28 - NVAR with avg smape 1.57: 
Model Number: 29 of 130 with model Theta for Validation 3
29 - Theta with avg smape 1.59: 
Model Number: 30 of 130 with model ARDL for Validation 3
30 - ARDL with avg smape 1.84: 
Model Number: 31 of 130 with model Theta for Validation 3
📈 31 - Theta with avg smape 0.99: 
Model Number: 32 of 130 with model Theta for Validation 3
32 - Theta with avg smape 0.99: 
Model Number: 33 of 130 with model UnivariateMotif for Validation 3
33 - UnivariateMotif with avg smape 1.46: 
Model Number: 34 of 130 with model UnivariateMotif for Validation 3
34 - UnivariateMotif with avg smape 1.14: 
Model Number: 35 of 130 with model Theta for Validation 3
35 - Theta with avg smape 1.0: 
Model Number: 36 of 130 with model Theta for Validation 3
36 - Theta with avg smape 2.08: 
Model Number: 37 of 130 with model Theta for Validation 3
37 - Theta with avg smape 0.99: 
Model Number: 38 of 130 with model ARDL for Validation 3
38 - ARDL with avg smape 1.38: 
Model Number: 39 of 130 with model ARDL for Validation 3
39 - ARDL with avg smape 1.54: 
Model Number: 40 of 130 with model ConstantNaive for Validation 3
40 - ConstantNaive with avg smape 2.12: 
Model Number: 41 of 130 with model ConstantNaive for Validation 3
41 - ConstantNaive with avg smape 2.12: 
Model Number: 42 of 130 with model ARDL for Validation 3
42 - ARDL with avg smape 1.41: 
Model Number: 43 of 130 with model ARDL for Validation 3
43 - ARDL with avg smape 1.51: 
Model Number: 44 of 130 with model ARDL for Validation 3
44 - ARDL with avg smape 1.52: 
Model Number: 45 of 130 with model AverageValueNaive for Validation 3
45 - AverageValueNaive with avg smape 2.62: 
Model Number: 46 of 130 with model ARDL for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3253: RuntimeWarning:

divide by zero encountered in log

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>📈 46 - ARDL with avg smape 0.0: 
Model Number: 47 of 130 with model Ensemble for Validation 3
47 - Ensemble with avg smape 2.7: 
Model Number: 48 of 130 with model ConstantNaive for Validation 3
48 - ConstantNaive with avg smape 1.83: 
Model Number: 49 of 130 with model ConstantNaive for Validation 3
49 - ConstantNaive with avg smape 1.83: 
Model Number: 50 of 130 with model ConstantNaive for Validation 3
50 - ConstantNaive with avg smape 1.83: 
Model Number: 51 of 130 with model ConstantNaive for Validation 3
51 - ConstantNaive with avg smape 1.83: 
Model Number: 52 of 130 with model ConstantNaive for Validation 3
52 - ConstantNaive with avg smape 0.0: 
Model Number: 53 of 130 with model ConstantNaive for Validation 3
53 - ConstantNaive with avg smape 0.0: 
Model Number: 54 of 130 with model AverageValueNaive for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3253: RuntimeWarning:

divide by zero encountered in log

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3253: RuntimeWarning:

divide by zero encountered in log

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>54 - AverageValueNaive with avg smape 1.42: 
Model Number: 55 of 130 with model UnobservedComponents for Validation 3
55 - UnobservedComponents with avg smape 2.03: 
Model Number: 56 of 130 with model MultivariateRegression for Validation 3
56 - MultivariateRegression with avg smape 7.8: 
Model Number: 57 of 130 with model UnobservedComponents for Validation 3
57 - UnobservedComponents with avg smape 1.86: 
Model Number: 58 of 130 with model GLM for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>58 - GLM with avg smape 3.84: 
Model Number: 59 of 130 with model GLM for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\families\links.py:187: RuntimeWarning:

overflow encountered in exp

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>59 - GLM with avg smape 3.84: 
Model Number: 60 of 130 with model GLM for Validation 3
60 - GLM with avg smape 3.84: 
Model Number: 61 of 130 with model GLM for Validation 3
61 - GLM with avg smape 3.84: 
Model Number: 62 of 130 with model GLM for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>62 - GLM with avg smape 3.84: 
Model Number: 63 of 130 with model GLM for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\statsmodels\genmod\generalized_linear_model.py:301: DomainWarning:

The inverse_power link function does not respect the domain of the Gamma family.

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>63 - GLM with avg smape 3.84: 
Model Number: 64 of 130 with model GLM for Validation 3
64 - GLM with avg smape 3.84: 
Model Number: 65 of 130 with model GLM for Validation 3
65 - GLM with avg smape 3.84: 
Model Number: 66 of 130 with model MultivariateRegression for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:67: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

divide by zero encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\autots\tools\probabilistic.py:68: RuntimeWarning:

invalid value encountered in true_divide

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3253: RuntimeWarning:

divide by zero encountered in log

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>66 - MultivariateRegression with avg smape 18.34: 
Model Number: 67 of 130 with model AverageValueNaive for Validation 3
67 - AverageValueNaive with avg smape 0.0: 
Model Number: 68 of 130 with model UnivariateMotif for Validation 3
68 - UnivariateMotif with avg smape 1.33: </pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\preprocessing\_data.py:3196: RuntimeWarning:

divide by zero encountered in power

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Model Number: 69 of 130 with model SeasonalNaive for Validation 3
69 - SeasonalNaive with avg smape 2.09: 
Model Number: 70 of 130 with model WindowRegression for Validation 3
[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002369 seconds.
You can set `force_col_wise=true` to remove the overhead.
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
70 - WindowRegression with avg smape 3.88: 
Model Number: 71 of 130 with model UnobservedComponents for Validation 3
71 - UnobservedComponents with avg smape 2.11: 
Model Number: 72 of 130 with model GLS for Validation 3
72 - GLS with avg smape 1.31: 
Model Number: 73 of 130 with model UnobservedComponents for Validation 3
73 - UnobservedComponents with avg smape 1.64: 
Model Number: 74 of 130 with model UnivariateMotif for Validation 3
74 - UnivariateMotif with avg smape 1.27: 
Model Number: 75 of 130 with model ETS for Validation 3
75 - ETS with avg smape 1.72: 
Model Number: 76 of 130 with model ETS for Validation 3
76 - ETS with avg smape 1.72: 
Model Number: 77 of 130 with model UnobservedComponents for Validation 3
77 - UnobservedComponents with avg smape 1.78: 
Model Number: 78 of 130 with model MultivariateRegression for Validation 3
Template Eval Error: ValueError(&#34;Input contains NaN, infinity or a value too large for dtype(&#39;float64&#39;).&#34;) in model 78: MultivariateRegression
Model Number: 79 of 130 with model ETS for Validation 3
79 - ETS with avg smape 1.72: 
Model Number: 80 of 130 with model GLS for Validation 3
80 - GLS with avg smape 1.32: 
Model Number: 81 of 130 with model SeasonalNaive for Validation 3
81 - SeasonalNaive with avg smape 1.69: 
Model Number: 82 of 130 with model ETS for Validation 3
82 - ETS with avg smape 2.75: 
Model Number: 83 of 130 with model MultivariateRegression for Validation 3
83 - MultivariateRegression with avg smape 1.13: 
Model Number: 84 of 130 with model ETS for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.184e+00, tolerance: 1.720e-02

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>84 - ETS with avg smape 2.07: 
Model Number: 85 of 130 with model SeasonalNaive for Validation 3
85 - SeasonalNaive with avg smape 10.06: 
Model Number: 86 of 130 with model UnobservedComponents for Validation 3
86 - UnobservedComponents with avg smape 1.45: 
Model Number: 87 of 130 with model SeasonalNaive for Validation 3
87 - SeasonalNaive with avg smape 10.03: 
Model Number: 88 of 130 with model SeasonalNaive for Validation 3
88 - SeasonalNaive with avg smape 1.96: 
Model Number: 89 of 130 with model UnivariateMotif for Validation 3
89 - UnivariateMotif with avg smape 1.97: 
Model Number: 90 of 130 with model UnobservedComponents for Validation 3
90 - UnobservedComponents with avg smape 1.42: 
Model Number: 91 of 130 with model AverageValueNaive for Validation 3
91 - AverageValueNaive with avg smape 4.35: 
Model Number: 92 of 130 with model AverageValueNaive for Validation 3
92 - AverageValueNaive with avg smape 16.88: 
Model Number: 93 of 130 with model WindowRegression for Validation 3
93 - WindowRegression with avg smape 1.02: 
Model Number: 94 of 130 with model WindowRegression for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.1s
[Parallel(n_jobs=-2)]: Done 194 tasks      | elapsed:    0.6s
[Parallel(n_jobs=-2)]: Done 444 tasks      | elapsed:    1.5s
[Parallel(n_jobs=-2)]: Done 794 tasks      | elapsed:    2.8s
[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:    3.5s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.2s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:    0.1s
[Parallel(n_jobs=3)]: Done 1000 out of 1000 | elapsed:    0.2s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>94 - WindowRegression with avg smape 1.52: 
Model Number: 95 of 130 with model WindowRegression for Validation 3
95 - WindowRegression with avg smape 2.21: 
Model Number: 96 of 130 with model MultivariateRegression for Validation 3
96 - MultivariateRegression with avg smape 10.31: 
Model Number: 97 of 130 with model GLS for Validation 3
97 - GLS with avg smape 1.47: 
Model Number: 98 of 130 with model WindowRegression for Validation 3
98 - WindowRegression with avg smape 1.98: 
Model Number: 99 of 130 with model ETS for Validation 3
99 - ETS with avg smape 1.68: 
Model Number: 100 of 130 with model SectionalMotif for Validation 3
100 - SectionalMotif with avg smape 2.71: 
Model Number: 101 of 130 with model UnobservedComponents for Validation 3
101 - UnobservedComponents with avg smape 1.46: 
Model Number: 102 of 130 with model WindowRegression for Validation 3
102 - WindowRegression with avg smape 1.81: 
Model Number: 103 of 130 with model SeasonalNaive for Validation 3
103 - SeasonalNaive with avg smape 2.08: 
Model Number: 104 of 130 with model ETS for Validation 3
104 - ETS with avg smape 1.74: 
Model Number: 105 of 130 with model ETS for Validation 3
105 - ETS with avg smape 1.86: 
Model Number: 106 of 130 with model MultivariateMotif for Validation 3
106 - MultivariateMotif with avg smape 18.06: 
Model Number: 107 of 130 with model SectionalMotif for Validation 3
107 - SectionalMotif with avg smape 17.13: 
Model Number: 108 of 130 with model MultivariateMotif for Validation 3
108 - MultivariateMotif with avg smape 1.21: 
Model Number: 109 of 130 with model SeasonalNaive for Validation 3
109 - SeasonalNaive with avg smape 3.06: 
Model Number: 110 of 130 with model WindowRegression for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\impep\anaconda3\envs\OpenCV\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:648: ConvergenceWarning:

Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.126e+06, tolerance: 4.854e+05

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>110 - WindowRegression with avg smape 1.3: 
Model Number: 111 of 130 with model MultivariateMotif for Validation 3
111 - MultivariateMotif with avg smape 12.3: 
Model Number: 112 of 130 with model UnivariateMotif for Validation 3
112 - UnivariateMotif with avg smape 1.51: 
Model Number: 113 of 130 with model MultivariateRegression for Validation 3
113 - MultivariateRegression with avg smape 1.11: 
Model Number: 114 of 130 with model MultivariateMotif for Validation 3
114 - MultivariateMotif with avg smape 13.83: 
Model Number: 115 of 130 with model UnivariateMotif for Validation 3
115 - UnivariateMotif with avg smape 12.28: 
Model Number: 116 of 130 with model AverageValueNaive for Validation 3
116 - AverageValueNaive with avg smape 8.7: 
Model Number: 117 of 130 with model GLS for Validation 3
117 - GLS with avg smape 1.4: 
Model Number: 118 of 130 with model AverageValueNaive for Validation 3
118 - AverageValueNaive with avg smape 1.57: 
Model Number: 119 of 130 with model MultivariateRegression for Validation 3
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=-2)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=-2)]: Done 100 out of 100 | elapsed:    0.2s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.
[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    0.0s
[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>119 - MultivariateRegression with avg smape 1.76: 
Model Number: 120 of 130 with model WindowRegression for Validation 3
Epoch 1/50
17/17 [==============================] - 11s 116ms/step - loss: 105.7642 - val_loss: 108.1195
Epoch 2/50
17/17 [==============================] - 0s 25ms/step - loss: 101.8077 - val_loss: 108.1208
Epoch 3/50
17/17 [==============================] - 1s 32ms/step - loss: 111.3971 - val_loss: 108.1320
Epoch 4/50
17/17 [==============================] - 0s 26ms/step - loss: 102.1923 - val_loss: 108.1304
Epoch 5/50
17/17 [==============================] - 0s 27ms/step - loss: 105.6344 - val_loss: 108.1349
Epoch 6/50
17/17 [==============================] - 1s 41ms/step - loss: 103.9355 - val_loss: 108.1401
Epoch 7/50
17/17 [==============================] - 1s 51ms/step - loss: 98.0228 - val_loss: 108.1465
Epoch 8/50
17/17 [==============================] - 1s 63ms/step - loss: 115.9061 - val_loss: 108.1488
Epoch 9/50
17/17 [==============================] - 1s 44ms/step - loss: 101.9901 - val_loss: 108.1591
Epoch 10/50
17/17 [==============================] - 0s 27ms/step - loss: 114.2572 - val_loss: 108.1666
Epoch 11/50
17/17 [==============================] - 0s 27ms/step - loss: 99.9602 - val_loss: 108.1745
120 - WindowRegression with avg smape 1.53: 
Model Number: 121 of 130 with model MultivariateMotif for Validation 3
121 - MultivariateMotif with avg smape 2.17: 
Model Number: 122 of 130 with model SectionalMotif for Validation 3
122 - SectionalMotif with avg smape 2.09: 
Model Number: 123 of 130 with model DatepartRegression for Validation 3
123 - DatepartRegression with avg smape 4.41: 
Model Number: 124 of 130 with model SeasonalNaive for Validation 3
124 - SeasonalNaive with avg smape 12.08: 
Model Number: 125 of 130 with model MultivariateMotif for Validation 3
125 - MultivariateMotif with avg smape 1.79: 
Model Number: 126 of 130 with model UnivariateMotif for Validation 3
126 - UnivariateMotif with avg smape 1.23: 
Model Number: 127 of 130 with model SectionalMotif for Validation 3
127 - SectionalMotif with avg smape 1.24: 
Model Number: 128 of 130 with model SectionalMotif for Validation 3
128 - SectionalMotif with avg smape 5.13: 
Model Number: 129 of 130 with model GLS for Validation 3
129 - GLS with avg smape 11.68: 
Model Number: 130 of 130 with model MultivariateMotif for Validation 3
130 - MultivariateMotif with avg smape 13.47: 
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在經過漫長（但自動化）的複雜運算之後，AutoTS會選擇最佳的模型預測結果</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>                   Close
2022-06-16  16021.916427
2022-06-17  16009.360169
2022-06-20  15971.442562
2022-06-21  15958.721237
2022-06-22  15945.959265
2022-06-23  15933.156894
2022-06-24  15920.314374
2022-06-27  15881.548438
2022-06-28  15868.547841
2022-06-29  15855.508357
2022-06-30  15842.430242
2022-07-01  15829.313751
2022-07-04  15789.736584
2022-07-05  15776.469157
2022-07-06  15763.164642
2022-07-07  15749.823298
2022-07-08  15736.445387
2022-07-11  15696.094866
2022-07-12  15682.573305
2022-07-13  15669.016490
2022-07-14  15655.424686
2022-07-15  15641.798158
2022-07-18  15600.712897
2022-07-19  15586.950142
2022-07-20  15573.154002
2022-07-21  15559.324744
2022-07-22  15545.462640
2022-07-25  15503.681958
2022-07-26  15489.691181
2022-07-27  15475.668918
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>從預測數據來看，在未來30天，台灣加權股價指數為向下趨勢。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#32317;&#32080;">&#32317;&#32080;<a class="anchor-link" href="#&#32317;&#32080;"> </a></h2><p>投資買賣一定會帶來風險。 使用機器學習進行加價格預測，是根據歷史價格進行推算所得到的結果，希望您在投資之前先做好所有的風險評估。</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/myPortfolio/python/prediction/jupyter/autots/stock%20price/2022/06/16/TW-weight-Index-Prediction-with-AutoTS.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/myPortfolio/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/myPortfolio/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/myPortfolio/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A Digital Product Solution Enthusiast.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/impepper" target="_blank" title="impepper"><svg class="svg-icon grey"><use xlink:href="/myPortfolio/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/chihong-pepper-lin-87b75671" target="_blank" title="chihong-pepper-lin-87b75671"><svg class="svg-icon grey"><use xlink:href="/myPortfolio/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
