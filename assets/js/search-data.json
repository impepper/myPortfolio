{
  
    
        "post0": {
            "title": "Sales Prediction 透過預算分配預測業績",
            "content": "預測產品的未來銷售有助於企業更有效的管理產品的製造以及廣告成本。 因此，我希望透過這篇文章，來了解並學習使用機器學習模型預測產品的未來銷售量。 . 在這個Case Study中，所使用的數據資料包含了產品銷售的數據以及企業在各種廣告平台上所投放的媒體預算：以下是數據集中所有列的描述： . TV: 在電視上投放廣告所花費的廣告成本； | Radio: 在廣播上投放廣告的廣告費用（以美元計）； | Newspaper: 在報紙上投放廣告所花費的廣告成本； | Sales：售出的產品單位數量 | 因此，在上述數據資料中包含了產品的銷量以及產品的廣告成本。我希望了解這些數字之前是否有關連，並且利用 Python 進行機器學習的未來銷售預測。 . &#36039;&#26009;&#25972;&#29702; . 首先，我們導入此次專案所需要的 Python 函式庫以及數據資料： . import pandas as pd import numpy as np from sklearn import preprocessing from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression import plotly.express as px import plotly.graph_objects as go data = pd.read_csv(&quot;datasource/advertising.csv&quot;) print(data.head()) . TV Radio Newspaper Sales 0 230.1 37.8 69.2 22.1 1 44.5 39.3 45.1 10.4 2 17.2 45.9 69.3 12.0 3 151.5 41.3 58.5 16.5 4 180.8 10.8 58.4 17.9 . 確認一下資料中有沒有無效的數據（例如空白欄位） . print(data.isnull().sum()) . TV 0 Radio 0 Newspaper 0 Sales 0 dtype: int64 . 看來資料品質不錯！ . 那，我們先來了解一下數據中各欄位與產品銷售數字之間的相關性： . 電視廣告成本與銷售數字的關聯性 . figure = px.scatter(data_frame = data, x=&quot;Sales&quot;, y=&quot;TV&quot;, size=&quot;TV&quot;, trendline=&quot;ols&quot;) #figure.show() . 透過 figure.show() 指令可以取得以下圖表: . 報紙廣告成本與銷售數字的關聯性 . figure = px.scatter(data_frame = data, x=&quot;Sales&quot;, y=&quot;Newspaper&quot;, size=&quot;Newspaper&quot;, trendline=&quot;ols&quot;) #figure.show() . . 電台廣告與銷售數字的關聯性 . figure = px.scatter(data_frame = data, x=&quot;Sales&quot;, y=&quot;Radio&quot;, size=&quot;Radio&quot;, trendline=&quot;ols&quot;) #figure.show() . . 在各種平台上的所有廣告費用中，可以看到在電視上為產品做廣告的費用會帶來更多的產品銷售。現在讓我們透過相關係數來了解所有欄位與銷售數字的相關性 . correlation = data.corr() print(correlation[&quot;Sales&quot;].sort_values(ascending=False)) . Sales 1.000000 TV 0.901208 Radio 0.349631 Newspaper 0.157960 Name: Sales, dtype: float64 . &#24314;&#31435;&#37559;&#21806;&#38928;&#28204;&#27169;&#22411; . 接下來，我們將數據分成訓練以及驗證兩部分，來進行線性回歸的機器學習模型訓練： . x = np.array(data.drop([&quot;Sales&quot;], 1)) y = np.array(data[&quot;Sales&quot;]) xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42) . C: Users impep anaconda3 envs OpenCV lib site-packages ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument &#39;labels&#39; will be keyword-only . 開始訓練模型 . model = LinearRegression() model.fit(xtrain, ytrain) . LinearRegression() . 透過驗證資料比對來了解一下這個模型的準確程度 . print(model.score(xtest, ytest)) . 0.9059011844150826 . 現在讓我們根據我們訓練好的模型，透過輸入企業在各種平台上（電視|廣告|報紙）的廣告花費來預測可以銷售多少單位的產品： . features = np.array([[230.1, 37.8, 69.2]]) features_normalized = preprocessing.scale(features) print(model.predict(features)) . [21.37254028] . &#32317;&#32080; . 預測產品的未來銷售有助於企業管理產品的製造和廣告成本。我們在這次的案例中，透過線性回歸的機器學習訓練，來預測產品未來的銷售數字。 希望你喜歡這篇文章。 .",
            "url": "https://impepper.github.io/myPortfolio/python/prediction/jupyter/linear%20regression/sales/2022/04/20/Future-Sales-Prediction-with-Machine-Learning.html",
            "relUrl": "/python/prediction/jupyter/linear%20regression/sales/2022/04/20/Future-Sales-Prediction-with-Machine-Learning.html",
            "date": " • Apr 20, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Customer Lifetime Value (CLTV)  用戶全生命週期價值計算及消費預測",
            "content": "Customer Lifetime Value (CLTV or CLV) &#26159;&#20160;&#40636; . 顧名思義，Customer Lifetime Value就是用戶在其生命週期內所能帶來的商業價值。以商業市場來說，CLTV 即是消費者從第一次購買你的產品，直到不再購買你的產品為止，在這段時間內對於你的公司所貢獻的商業價值。 . &#28858;&#20160;&#40636;&#38656;&#35201; CLTV &#20316;&#28858;&#34913;&#37327;&#25351;&#27161; . &#36628;&#21161;&#21046;&#23450; CAC &#25351;&#27161; . CAC (Customer Acquisition Cost) 代表獲取一個顧客的成本，在商業經營中，唯有用戶在其生命週期內所帶來的商業價值（CLTV） 大於 獲取這位顧客的成本(CAC)，這個 Business 才能持續地滾動下去。因此，透過CLTV，商業經營者可以更加明確的規劃面相於故各地個性行銷活動，以確保商業模式能夠長久運轉。 . &#21487;&#25345;&#32396;&#24615;&#30340;&#22686;&#38263;&#25351;&#27161; . 隨著技術對用戶的生活產生改變，用戶的接觸點（Endpoints）越來越多多樣化，相對應的行銷策略與手段也因此而產生了重大變化，新零售（OMO）概念正充分說明，光是倚靠 Revenue 或是 CAC 來作為指標，無法有效的去衡量日常所做的每個項目投入；若是持續的僅使用這兩個指標來做衡量，甚至可能因此讓錯失了很多重要的項目無法被實施。 . CLTV 和傳統常見的指標最大的不同在於：是將多個部門的「心血」所匯集在一起呈現的指標。 CLTV的增長，反映了行銷、產品、業務跨三個部門協同運作的成果，將單一部門的活動轉化成了整體的經營成效增長。 . CLTV一直是 Amazon 內部採用作為日常增長指標來判斷一個項目/業務是否成功的衡量方式，像是知名的 Kindle 業務即是在這樣的文化下所誕生並且成功。以一個近乎成本價的方式銷售 Kindle device，而購買 Kindle 後的用戶其設備上產生的消費金額，才是衡量該業務成功與否的核心指標。 . 在這個實作中，我將以消費紀錄為基礎，利用機器學習，來計算消費者 Lifetime Value，並推估該用戶未來六個月的消費數據。 . 數據資料 . 在本次使用的消費紀錄資料中，包含了以下欄位： . 消費日期 | Invoice Number | 客戶編號 | 消費金額 | . 首先，我們導入此次專案所需要的 Python 函式庫 . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns sns.set() import warnings warnings.filterwarnings(&#39;ignore&#39;) . 接下來，進行數據資料的讀取及匯入 . #data = pd.read_csv(&quot;datasource/data.csv&quot;, parse_dates=[&#39;invoice_date&#39;]) data_clv = pd.read_csv(&quot;datasource/CLTV_data.csv&quot;, parse_dates=[&#39;invoice_date&#39;]) print(&quot;Total number of transactions happened in the given period: &quot;+ str(data_clv.shape[0])) data_clv.head(5) . Total number of transactions happened in the given period: 32030 . invoice_id invoice_date invoice_cus_id invoice_amount . 0 2021020600200001 | 2021-02-06 09:41:00 | 701000008.0 | 245 | . 1 2021020600200002 | 2021-02-06 09:43:00 | 701000001.0 | 240 | . 2 2021020600200003 | 2021-02-06 09:45:00 | 701000010.0 | 100 | . 3 2021020600200004 | 2021-02-06 09:46:00 | 701000010.0 | 515 | . 4 2021020600200005 | 2021-02-06 09:46:00 | 701000010.0 | 140 | . 因為退貨、折扣等因素，消費金額中可能會有負數出現。不過，在客戶生命週期價值計算中，我們只對客戶在其生命週期內可以為企業產生的總價值感興趣，我們可以簡單地將消費中的負值紀錄除掉，只使用正值。 . data_clv = data_clv[data_clv[&#39;invoice_amount&#39;] &gt; 0] data_clv.describe() #了解目前數列的各項統計數據 . invoice_cus_id invoice_amount . count 3.144700e+04 | 31447.000000 | . mean 7.211368e+08 | 354.360448 | . std 3.949744e+09 | 860.162176 | . min 2.010000e+08 | 1.000000 | . 25% 7.010000e+08 | 89.000000 | . 50% 7.010000e+08 | 150.000000 | . 75% 7.010002e+08 | 345.000000 | . max 7.010030e+11 | 67080.000000 | . 我們檢查一下現有資料中有沒有其他遺漏數據的資料列，像是欄位值為空值之類。 . 此外，因為接下來可能需要計算每位客戶的CLTV，我們也要過濾掉客戶資料欄為空值的資料 . data_clv = data_clv[pd.notnull(data_clv[&#39;invoice_cus_id&#39;])] pd.DataFrame(zip(data_clv.isnull().sum(), data_clv.isnull().sum()/len(data_clv)), columns=[&#39;Count&#39;, &#39;Proportion&#39;], index=data_clv.columns) . Count Proportion . invoice_id 0 | 0.0 | . invoice_date 0 | 0.0 | . invoice_cus_id 0 | 0.0 | . invoice_amount 0 | 0.0 | . 至此，資料已經整理完畢，讓我們初步看一下目前數據的基本資料： . maxdate = data_clv[&#39;invoice_date&#39;].dt.date.max() mindate = data_clv[&#39;invoice_date&#39;].dt.date.min() unique_cust = data_clv[&#39;invoice_cus_id&#39;].nunique() tot_sales = data_clv[&#39;invoice_amount&#39;].sum() print(f&quot;The Time range of transactions is: {mindate} to {maxdate}&quot;) print(f&quot;Total number of unique customers: {unique_cust}&quot;) print(f&quot;Total Sales for the period: {tot_sales}&quot;) . The Time range of transactions is: 2021-02-06 to 2022-04-20 Total number of unique customers: 2615 Total Sales for the period: 11143573 . &#35336;&#31639; Customer Lifetime Value . Aggregate Model . 計算 CLTV 的最簡單和最古老的方法是平均法。這假設所有客戶的平均支出和流失率保持不變。 . 此方法不區分單一客戶，只會整體地生成單一的CLTV數值。雖然對於一般消費者還算堪用，不過如果一些客戶進行高價值和高交易量的交易，對於這類消費者的生命週期價值將出現不切實際的估計。 . 平均法中用以計算CLTV的公式如下： . CLV = ((Average Sales X Purchase Frequency) / Churn) X Profit Margin . 其中， . Average Sales = TotalSales/Total no. of orders . Purchase Frequency = Total no. of orders/Total unique customers . Retention rate = Total no. of orders greater than 1/ Total unique customers . Churn = 1 - Retention rate . Profit Margin = Based on business context . customer = data_clv.groupby(&#39;invoice_cus_id&#39;).agg({&#39;invoice_date&#39;:lambda x: (x.max() - x.min()).days, &#39;invoice_id&#39;: lambda x: len(x), &#39;invoice_amount&#39;: lambda x: sum(x)}) customer.columns = [&#39;Age&#39;, &#39;Frequency&#39;, &#39;TotalSales&#39;] customer.head() . Age Frequency TotalSales . invoice_cus_id . 201000002.0 434 | 172 | 64997 | . 701000001.0 437 | 322 | 231844 | . 701000002.0 387 | 208 | 149509 | . 701000003.0 294 | 110 | 40052 | . 701000004.0 124 | 11 | 7749 | . Average_sales = round(np.mean(customer[&#39;TotalSales&#39;]),2) print(f&quot;Average sales: ${Average_sales}&quot;) Purchase_freq = round(np.mean(customer[&#39;Frequency&#39;]), 2) print(f&quot;Purchase Frequency: {Purchase_freq}&quot;) Retention_rate = customer[customer[&#39;Frequency&#39;]&gt;1].shape[0]/customer.shape[0] churn = round(1 - Retention_rate, 2) print(f&quot;Churn: {churn}%&quot;) . Average sales: $4261.4 Purchase Frequency: 12.03 Churn: 0.53% . 假設每筆交易所帶來的利潤空間(Profit margin)為5%進行計算 . Profit_margin = 0.05 CLTV = round(((Average_sales * Purchase_freq/churn)) * Profit_margin, 2) print(f&quot;The Customer Lifetime Value (CLTV) for each customer is: ${CLTV}&quot;) . The Customer Lifetime Value (CLTV) for each customer is: $4836.29 . 從這個方法中，我們得到了每個客戶的 CLTV 值。 你覺得這個數字有意義嗎？ 原因是因為來自極少數客戶具有非常高的銷售金額，而這個CLTV值實際上完全無法反應該類消費者的生命週期價值 . Cohort Model . 相比計算一個整體的CLTV值，我們可以嘗試將他們分成多個組來計算每個組的 CLTV，而不是簡單地假設所有客戶為一個組。這稱為隊列模型。 . 該模型的主要假設是，同組中的客戶花費相似。 . 這種模型克服了平均法模型的主要缺點 。 將客戶分組為同類群組的最常見方法是按客戶的開始日期，通常是按照月份。 . 在這種假設狀況下，我依照他們的消費開始月份將他們分組到不同的群組中。 . customer = data_clv.groupby(&#39;invoice_cus_id&#39;).agg({&#39;invoice_date&#39;:lambda x: x.min().month, &#39;invoice_id&#39;: lambda x: len(x), &#39;invoice_amount&#39;: lambda x: np.sum(x)}) customer.columns = [&#39;Start_Month&#39;, &#39;Frequency&#39;, &#39;TotalSales&#39;] customer.head() . Start_Month Frequency TotalSales . invoice_cus_id . 201000002.0 2 | 172 | 64997 | . 701000001.0 2 | 322 | 231844 | . 701000002.0 2 | 208 | 149509 | . 701000003.0 2 | 110 | 40052 | . 701000004.0 2 | 11 | 7749 | . months = [&#39;Jan&#39;, &#39;Feb&#39;, &#39;March&#39;, &#39;Apr&#39;, &#39;May&#39;, &#39;Jun&#39;, &#39;Jul&#39;, &#39;Aug&#39;, &#39;Sep&#39;, &#39;Oct&#39;, &#39;Nov&#39;, &#39;Dec&#39;] Monthly_CLV = [] for i in range(1, 13): customer_m = customer[customer[&#39;Start_Month&#39;]==i] Average_sales = round(np.mean(customer_m[&#39;TotalSales&#39;]),2) Purchase_freq = round(np.mean(customer_m[&#39;Frequency&#39;]), 2) Retention_rate = customer_m[customer_m[&#39;Frequency&#39;]&gt;1].shape[0]/customer_m.shape[0] churn = round(1 - Retention_rate, 2) CLV = round(((Average_sales * Purchase_freq/churn)) * Profit_margin, 2) Monthly_CLV.append(CLV) . monthly_clv = pd.DataFrame(zip(months, Monthly_CLV), columns=[&#39;Months&#39;, &#39;CLTV&#39;]) display(monthly_clv.style.background_gradient()) . &nbsp; Months CLTV . 0 Jan | 3673.600000 | . 1 Feb | 68379.320000 | . 2 March | 453.970000 | . 3 Apr | 386.970000 | . 4 May | 963.540000 | . 5 Jun | 1815.530000 | . 6 Jul | 1221.690000 | . 7 Aug | 927.490000 | . 8 Sep | 402.360000 | . 9 Oct | 305.040000 | . 10 Nov | 223.430000 | . 11 Dec | 92.510000 | . 現在，如果查看結果，從1月到12月，我們有 12 個不同的 CLTV 值。 . 很明顯，在不同月份獲得的客戶具有不同的 CLTV 值。 這是因為，他們可以通過不同的活動等方式獲得，因此他們的行為可能與其他人不同。 . BG/NBD Model (with Gamma-Gamma extension) . BG/NBD 指的是概率論中的 β 負二項分佈（離散隨機變量 X 的概率分佈） . 這是用於預測 CLTV 的最常用的概率模型之一，也是 CLV 計算中最常用的方法之一。 . 在本例中，我們將只關注 BG/NBD 模型。 BG/NBD 模型實際上試圖預測每個客戶的未來交易。然後將其與 Gamma-Gamma 模型相結合，得到客戶生命週期價值 (CLTV)。 . The BG/NBD 有一些假設條件： . When a user is active, number of transactions in a time t is described by Poisson distribution with rate lambda. | Heterogeneity in transaction across users (difference in purchasing behavior across users) has Gamma distribution with shape parameter r and scale parameter a. | Users may become inactive after any transaction with probability p and their dropout point is distributed between purchases with Geometric distribution. | Heterogeneity in dropout probability has Beta distribution with the two shape parameters alpha and beta. | Transaction rate and dropout probability vary independently across users. | 這些是該模型在預測客戶未來交易時考慮的一些假設。 . 我們不必擔心自己執行這個複雜的概率模型。有一個名為 Lifetimes 的 Python 函式庫，主要用於幫助計算客戶生命週期價值、預測客戶流失等。它具有 CLTV 計算所需的所有主要模型和實用功能。 . 在這種情況下，我們將利用這個函式庫，快速進行CLTV計算。 . import lifetimes . 首先，我們需要匯總我們的交易數據，使其成為一個客戶級別的 RFM 表格。 （RFM - Recency、Freguency &amp; Monetary） . 為此，我們可以在Lifetimes 函式庫中使用 summary_data_from_transactions_data 函數。 . 他所做的是將交易級別數據整合到客戶級別，並且計算每個客戶的Recency、Freguency、 T &amp; Monetary: . frequency - the number of repeat purchases (more than 1 purchases) | recency - the time between the first and the last transaction | T - the time between the first purchase and the end of the transaction period | monetary_value - it is the mean of a given customers sales value | . summary = lifetimes.utils.summary_data_from_transaction_data(data_clv, &#39;invoice_cus_id&#39;, &#39;invoice_date&#39;, &#39;invoice_amount&#39; ) summary = summary.reset_index() summary.head() . invoice_cus_id frequency recency T monetary_value . 0 201000002.0 | 122.0 | 434.0 | 438.0 | 527.270492 | . 1 701000001.0 | 181.0 | 437.0 | 438.0 | 1279.011050 | . 2 701000002.0 | 136.0 | 387.0 | 438.0 | 1092.125000 | . 3 701000003.0 | 81.0 | 294.0 | 427.0 | 480.765432 | . 4 701000004.0 | 9.0 | 125.0 | 435.0 | 853.222222 | . Here the value of 0 in frequency and recency means that, these are one time buyers. Let&#39;s check how many such one time buyers are there in our data. . summary[&#39;frequency&#39;].plot(kind=&#39;hist&#39;, bins=50) print(summary[&#39;frequency&#39;].describe()) print(&quot;&quot;) one_time_buyers = round(sum(summary[&#39;frequency&#39;] == 0)/float(len(summary))*(100),2) print(&quot;Percentage of customers purchase the item only once:&quot;, one_time_buyers ,&quot;%&quot;) . count 2615.000000 mean 2.221797 std 9.950323 min 0.000000 25% 0.000000 50% 0.000000 75% 2.000000 max 367.000000 Name: frequency, dtype: float64 Percentage of customers purchase the item only once: 55.72 % . Now, let&#39;s fit the BG/NBD model to our summary data. . BG/NBD model is available as BetaGeoFitter class in lifetimes package. . bgf = lifetimes.BetaGeoFitter(penalizer_coef=0.001) bgf.fit(summary[&#39;frequency&#39;], summary[&#39;recency&#39;], summary[&#39;T&#39;]) . &lt;lifetimes.BetaGeoFitter: fitted with 2615 subjects, a: 0.39, alpha: 16.78, b: 1.33, r: 0.22&gt; . bgf.summary . coef se(coef) lower 95% bound upper 95% bound . r 0.218279 | 0.008915 | 0.200805 | 0.235753 | . alpha 16.779933 | 1.179340 | 14.468426 | 19.091440 | . a 0.387987 | 0.042371 | 0.304941 | 0.471034 | . b 1.334940 | 0.184841 | 0.972652 | 1.697228 | . 上表顯示了從歷史數據中估計的分佈參數值。 該模型會使用它來預測未來的交易和客戶流失率。 . 因此，假設您想根據歷史數據了解客戶現在是否還活著（或預測客戶流失）。 在Lifetimes 函式庫中可以使用： . 1. model.conditional_probability_alive(): 此函數可以用來計算具有歷史記錄（frequency, recency, T）的客戶當前還活著的概率。 . 2. plot_probabilty_alive_matrix(model): 這個函數可以協助我們直觀地分析recency, frequency與客戶存活之間的關係。 . summary[&#39;probability_alive&#39;] = bgf.conditional_probability_alive(summary[&#39;frequency&#39;], summary[&#39;recency&#39;], summary[&#39;T&#39;]) summary.head(10) . invoice_cus_id frequency recency T monetary_value probability_alive . 0 201000002.0 | 122.0 | 434.0 | 438.0 | 527.270492 | 9.907499e-01 | . 1 701000001.0 | 181.0 | 437.0 | 438.0 | 1279.011050 | 9.968217e-01 | . 2 701000002.0 | 136.0 | 387.0 | 438.0 | 1092.125000 | 3.230038e-05 | . 3 701000003.0 | 81.0 | 294.0 | 427.0 | 480.765432 | 5.699000e-11 | . 4 701000004.0 | 9.0 | 125.0 | 435.0 | 853.222222 | 5.512930e-04 | . 5 701000006.0 | 4.0 | 302.0 | 401.0 | 165.000000 | 7.811945e-01 | . 6 701000008.0 | 0.0 | 0.0 | 438.0 | 0.000000 | 1.000000e+00 | . 7 701000009.0 | 4.0 | 305.0 | 425.0 | 972.500000 | 7.458372e-01 | . 8 701000010.0 | 367.0 | 438.0 | 438.0 | 13758.144414 | 9.989449e-01 | . 9 701000011.0 | 1.0 | 88.0 | 438.0 | 6350.000000 | 3.652369e-01 | . from lifetimes.plotting import plot_probability_alive_matrix fig = plt.figure(figsize=(12,8)) plot_probability_alive_matrix(bgf) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Probability Customer is Alive, nby Frequency and Recency of a Customer&#39;}, xlabel=&#34;Customer&#39;s Historical Frequency&#34;, ylabel=&#34;Customer&#39;s Recency&#34;&gt; . 稍微解釋一下： . 客戶存活機率，是依照客戶的Recency以及Frequency來計算出來的，所以： . 如果客戶購買了多次（Frequency）並且第一次和最後一次交易之間的時間很長（Recency），那麼他/她存續的可能性就很高。 | 同樣，如果客戶的頻率較低（只有購買一次或兩次）並且第一次和最後一次交易之間的時間很短（Recency），那麼他/她的存活概率就很高。 | . 接下來我們還可以使用這個經過訓練的模型來預測每個客戶未來可能發生的交易。 您可以使用： . model.conditional_expected_number_of_purchases_up_to_time() . 計算從人群（或整個人群）中隨機選擇的個體到時間 t 的預期重複購買次數 - 假設他們有購買記錄（frequency, recency, T）。 . t = 30 # 預測接下來的30天內，各個消費者的預期重複回購次數 summary[&#39;pred_num_txn&#39;] = round(bgf.conditional_expected_number_of_purchases_up_to_time(t, summary[&#39;frequency&#39;], summary[&#39;recency&#39;], summary[&#39;T&#39;]),2) summary.sort_values(by=&#39;pred_num_txn&#39;, ascending=False).head(10).reset_index() . index invoice_cus_id frequency recency T monetary_value probability_alive pred_num_txn . 0 8 | 701000010.0 | 367.0 | 438.0 | 438.0 | 13758.144414 | 0.998945 | 23.90 | . 1 2392 | 701003443.0 | 79.0 | 98.0 | 98.0 | 3692.278481 | 0.995133 | 19.67 | . 2 1 | 701000001.0 | 181.0 | 437.0 | 438.0 | 1279.011050 | 0.996822 | 11.77 | . 3 0 | 201000002.0 | 122.0 | 434.0 | 438.0 | 527.270492 | 0.990750 | 7.89 | . 4 1328 | 701001605.0 | 48.0 | 342.0 | 342.0 | 289.708333 | 0.992037 | 3.94 | . 5 1816 | 701002433.0 | 34.0 | 241.0 | 245.0 | 437.352941 | 0.981221 | 3.77 | . 6 1751 | 701002326.0 | 30.0 | 257.0 | 258.0 | 140.466667 | 0.985921 | 3.19 | . 7 2531 | 701003765.0 | 6.0 | 33.0 | 34.0 | 271.666667 | 0.935184 | 3.14 | . 8 335 | 701000367.0 | 47.0 | 413.0 | 421.0 | 1095.872340 | 0.980795 | 3.13 | . 9 1616 | 701002107.0 | 29.0 | 284.0 | 289.0 | 2824.275862 | 0.979038 | 2.76 | . 既然我們預測了預期的未來交易，我們現在需要預測每筆交易的未來貨幣價值。 . 就像我之前提到的，BG/NBD 模型只能預測客戶的未來交易和流失率。 為了增加問題的貨幣方面，我們必須使用 Gamma-Gamma 模型 對貨幣價值進行建模。 . Gamma-Gamma 模型的一些關鍵假設是： . 客戶給定交易的貨幣價值在其平均交易價值附近隨機變化。 | 平均交易價值因客戶而異，但對於任何給定客戶不會隨時間而變化。 | 客戶之間平均交易價值的分佈與交易過程無關。 | 作為將模型擬合到數據之前的第一步，我們必須檢查模型所做的假設是否適用於這些數據：只有滿足了，我們才繼續進行。 . 注意：我們只考慮重複購買的客戶，即頻率 &gt; 0。因為如果頻率為 0，則意味著他們是一次性客戶並且被認為已經流失。 . return_customers_summary = summary[summary[&#39;frequency&#39;]&gt;0] return_customers_summary[[&#39;frequency&#39;, &#39;monetary_value&#39;]].corr() . frequency monetary_value . frequency 1.000000 | 0.308369 | . monetary_value 0.308369 | 1.000000 | . 在這個CASE中，交易的頻率和貨幣價值之間沒有關係，我們可以透過相關性驗證其相關姓性並不顯著。 . 再來，我們利用 Gamma-Gamma 模型進行建模： . ggf = lifetimes.GammaGammaFitter(penalizer_coef=0.001) ggf.fit(return_customers_summary[&#39;frequency&#39;], return_customers_summary[&#39;monetary_value&#39;]) # Summary of the fitted parameters ggf.summary . coef se(coef) lower 95% bound upper 95% bound . p 10.770713 | 0.421400 | 9.944770 | 11.596656 | . q 0.665780 | 0.023646 | 0.619433 | 0.712127 | . v 10.636420 | 0.429762 | 9.794086 | 11.478754 | . 接下來，我們可以使用該模型預測每筆交易的預期平均利潤和客戶生命週期價值。 . 1. model.conditional_expected_average_profit(): 該函數計算一個或多個客戶的每筆交易的期望平均利潤。 . 2. model.customer_lifetime_value(): 該函數計算一組一個或多個客戶的平均生命週期價值。 該方法以 BG/NBD 模型和預測範圍作為參數來計算 CLTV。 . summary = summary[summary[&#39;monetary_value&#39;] &gt;0] summary[&#39;exp_avg_sales&#39;] = ggf.conditional_expected_average_profit(summary[&#39;frequency&#39;], summary[&#39;monetary_value&#39;]) summary.head() . invoice_cus_id frequency recency T monetary_value probability_alive pred_num_txn exp_avg_sales . 0 201000002.0 | 122.0 | 434.0 | 438.0 | 527.270492 | 9.907499e-01 | 7.89 | 527.491842 | . 1 701000001.0 | 181.0 | 437.0 | 438.0 | 1279.011050 | 9.968217e-01 | 11.77 | 1279.289134 | . 2 701000002.0 | 136.0 | 387.0 | 438.0 | 1092.125000 | 3.230038e-05 | 0.00 | 1092.452468 | . 3 701000003.0 | 81.0 | 294.0 | 427.0 | 480.765432 | 5.699000e-11 | 0.00 | 481.081044 | . 4 701000004.0 | 9.0 | 125.0 | 435.0 | 853.222222 | 5.512930e-04 | 0.00 | 857.360073 | . 注意： 我們使用上述方法所得到的銷售額而不是利潤。我們可以另外將結果乘以我們的利潤率，得出實際利潤值。 . print(f&quot;Expected Average Sales: {summary[&#39;exp_avg_sales&#39;].mean()}&quot;) print(f&quot;Actual Average Sales: {summary[&#39;monetary_value&#39;].mean()}&quot;) . Expected Average Sales: 731.1509233516309 Actual Average Sales: 713.8926372998563 . 現在，讓我們直接使用Lifetime 函式庫中的函數來計算客戶生命週期價值。 . 有幾件事情要注意： . 1. time: customer_lifetime_value()函數中的這個參數以月為單位，t=1表示一個月，以此類推。 . 2. freq: 此參數是您將指定數據所在的時間單位的位置。如果您的數據是每日級別，那麼“D”，每月“M”等等。 . 3. discount_rate: 這個參數是基於DCF（discounted cash flow）的概念，你將未來的貨幣價值通過一個貼現率貼現得到該現金流的現值。 在文件中，給出的預設值是每月 0.01（每年 ~12.7%）。 . summary[&#39;predicted_clv&#39;] = ggf.customer_lifetime_value(bgf, summary[&#39;frequency&#39;], summary[&#39;recency&#39;], summary[&#39;T&#39;], summary[&#39;monetary_value&#39;], time=1, # lifetime in months freq=&#39;D&#39;, # frequency in which the data is present(T) discount_rate=0.01) # discount rate summary.head() . invoice_cus_id frequency recency T monetary_value probability_alive pred_num_txn exp_avg_sales predicted_clv . 0 201000002.0 | 122.0 | 434.0 | 438.0 | 527.270492 | 9.907499e-01 | 7.89 | 527.491842 | 4.120102e+03 | . 1 701000001.0 | 181.0 | 437.0 | 438.0 | 1279.011050 | 9.968217e-01 | 11.77 | 1279.289134 | 1.490641e+04 | . 2 701000002.0 | 136.0 | 387.0 | 438.0 | 1092.125000 | 3.230038e-05 | 0.00 | 1092.452468 | 3.100526e-01 | . 3 701000003.0 | 81.0 | 294.0 | 427.0 | 480.765432 | 5.699000e-11 | 0.00 | 481.081044 | 1.471555e-07 | . 4 701000004.0 | 9.0 | 125.0 | 435.0 | 853.222222 | 5.512930e-04 | 0.00 | 857.360073 | 2.830461e-01 | . 您還可以根據未來交易的預測數量 (pred_num_txn) 和每筆交易的預期平均銷售額 (exp_avg_sales) 手動計算 CLTV。 . summary[&#39;manual_predicted_clv&#39;] = summary[&#39;pred_num_txn&#39;] * summary[&#39;exp_avg_sales&#39;] summary.head() . invoice_cus_id frequency recency T monetary_value probability_alive pred_num_txn exp_avg_sales predicted_clv manual_predicted_clv . 0 201000002.0 | 122.0 | 434.0 | 438.0 | 527.270492 | 9.907499e-01 | 7.89 | 527.491842 | 4.120102e+03 | 4161.910633 | . 1 701000001.0 | 181.0 | 437.0 | 438.0 | 1279.011050 | 9.968217e-01 | 11.77 | 1279.289134 | 1.490641e+04 | 15057.233110 | . 2 701000002.0 | 136.0 | 387.0 | 438.0 | 1092.125000 | 3.230038e-05 | 0.00 | 1092.452468 | 3.100526e-01 | 0.000000 | . 3 701000003.0 | 81.0 | 294.0 | 427.0 | 480.765432 | 5.699000e-11 | 0.00 | 481.081044 | 1.471555e-07 | 0.000000 | . 4 701000004.0 | 9.0 | 125.0 | 435.0 | 853.222222 | 5.512930e-04 | 0.00 | 857.360073 | 2.830461e-01 | 0.000000 | . 兩個 CLV 值非常接近，並且在接下來的 30 天內似乎是合理的。 . 這裡需要注意的一點是，我們為 CLTV 計算的兩個值都是銷售價值，而不是實際利潤。 . Summary . 我們預測了每個客戶未來 30 天的 CLTV。 . 行銷及業務團隊現在可以透過這些信息來定位客戶並尋求合適的方式來增加他們的銷售額。 . 希望你喜歡這篇文章。 .",
            "url": "https://impepper.github.io/myPortfolio/python/prediction/jupyter/customer%20life%20time%20value/sales/2022/04/11/Customer-Lifetime-Value-(CLV).html",
            "relUrl": "/python/prediction/jupyter/customer%20life%20time%20value/sales/2022/04/11/Customer-Lifetime-Value-(CLV).html",
            "date": " • Apr 11, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "股價預測",
            "content": "&#32929;&#20729;&#38928;&#28204;&#26159;&#27231;&#22120;&#23416;&#32722;&#22312;&#37329;&#34701;&#38936;&#22495;&#26368;&#37325;&#35201;&#30340;&#25033;&#29992;&#20043;&#19968;&#12290;&#22312;&#36889;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#23559;&#22039;&#35430;&#36879;&#36942;&#20351;&#29992; Python &#30340;&#32218;&#24615;&#22238;&#27512;&#27169;&#22411;&#20358;&#36914;&#34892;&#32929;&#31080;&#20729;&#26684;&#30340;&#38928;&#28204;&#12290; . Stock Price Prediction . 預測股市的價格，一直是投資者的終極目標。 在每天數以億計的交易之中，每筆交易，都代表者投資者對於該股票的價格預期，並且期望透過交易獲利。 . 也因此，股票漲跌，便取決於投資者在交易市場中的投資行為。 如果投資者能夠準確預測市場動向，便有機會創造誘人的財富。 . 如果您具有股票市場的投資經驗以及機器學習的量化數據分析技能，對於您進行股票價格預測將會有明顯的助益。 . 我們來看看如何使用 python 來預測股票價格。 . 首先，我們先導入此項專案所需的所有必要 python 函式庫： . import numpy as np import pandas as pd from sklearn import preprocessing from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression . &#36039;&#26009;&#28310;&#20633; Data Preparation . 在這裡，我們先建立一個子程式，協助我們將等會讀取進來的資料進行切割： . def prepare_data(df,forecast_col,forecast_out,test_size): label = df[forecast_col].shift(-forecast_out) #建立一個新的序列，裡面的是5 {%forecast_out%}天後的股價（收盤價） X = np.array(df[[forecast_col]]) #建立序列 X = preprocessing.scale(X) #將訓練資料進行特徵標準化(normalization)工作 X_lately = X[-forecast_out:] #建立等會用來進行預測的資料(資料集中最後5 {%forecast_out%}天的股價（收盤價）) X = X[:-forecast_out] # 將資料集中最後的5{%forecast_out%}筆資料移除掉，亦即移除掉等下要作為預測用的資料 label.dropna(inplace=True) #通過**dropna()**過濾掉缺失的數據（亦即移除掉最後5筆數列） y = np.array(label) X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_size, random_state=0) #切割數據集 response = [X_train,X_test , Y_train, Y_test , X_lately] return response . 為什麼要將資料進行切割呢？這是因為在機器學習的領域之中，資料將會分成以下4類資料來進行資料分析以及驗證： . 訓練資料 &lt;- 在訓練模型時所依據的基礎資料 | 訓練資料所對應的歷史結果 &lt;- 在訓練模型時，透過基礎資料與歷史結果的關係，來建立數據模型 | 測試資料 &lt;- 在數據模型建立之後，作為模型驗證實的基礎資料 | 測試資料所對應的歷史結果 &lt;- 在訓練資料透過數據模模演算後的結過（預測），與相對應的歷史結果進行比較，以了解數據麼型的準確程度 | (上述的4類資料，都是來自於歷史資料) . 接下來，我們開始讀取要進行分析的股價資料（以TESLA股價為例） . df = pd.read_csv(&quot;datasource/TSLA.csv&quot;) . 現在，我準備建立三個輸入變量供上面創建的子程式使用。包含了我們想要預測的資料欄位、訓練及驗證資料的分割比例、以及我們預計預測的天數。 . forecast_col = &#39;Close&#39; # 在這個練習中，我選擇收盤價欄位作為訓練模型以及預測的欄位 forecast_out = 5 # 在這個練習中，我規劃預測 5 天後的TESLA的收盤價 test_size = 0.2 # 在這個練習中，我預計用來進行模型驗證的資料比例（在大多數的案例中，會採用20%。也就是0.2作為模型驗證之用） . &#24314;&#31435;&#20006;&#25033;&#29992;&#32929;&#20729;&#38928;&#28204;&#27169;&#22411; . 現在，我們開始將匯入的資料進行切割，並據此開始訓練線性回歸模型： . X_train, X_test, Y_train, Y_test , X_lately =prepare_data(df,forecast_col,forecast_out,test_size); learner = LinearRegression() #定義以及初始化線性回歸模型 learner.fit(X_train,Y_train) #訓練線性回歸模型 . LinearRegression() . 到這裡，模型已經訓練並且建立完畢，我們可以快速地了解模型準確度並開始進行預測！ . score=learner.score(X_test,Y_test) # 了解一下這個模型的準確程度（透過驗證資料比對） forecast= learner.predict(X_lately) # 提供基礎資料進行模型演算餅取得預測結果 （5 天後的TESLA的收盤價） response={} # creting json object response[&#39;模型分數&#39;]=score response[&#39;預測價格&#39;]=forecast print(response) . {&#39;模型分數&#39;: 0.7901258449593493, &#39;預測價格&#39;: array([738.10424235, 739.67504036, 747.39116981, 741.79828889, 722.43892968])} . &#32317;&#32080; . 這就是我們如何學習透過 Python 和機器學習中的線性回歸模型來預測股票價格。 希望你喜歡這篇文章。 .",
            "url": "https://impepper.github.io/myPortfolio/python/prediction/jupyter/linear%20regression/stock%20price/2022/02/12/Stock-Price-Prediction.html",
            "relUrl": "/python/prediction/jupyter/linear%20regression/stock%20price/2022/02/12/Stock-Price-Prediction.html",
            "date": " • Feb 12, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "CV",
          "content": "EDUCATION . Gemological Institute of America | 東海大學 (Sep.1990 ~ Jun.1994) | . WORK EXPERIENCE . Chanel Inc. (Taiwan) . IT Manager - Client Solution &amp; Digital . One to support frontline the suitable ecosystems and find potential digital activaions accordingly. . To design and build the digital ecosystem architect on LINE/SFMC for CRM purpose and potential business activation ideas | To cooperate with regional colleagues launching newly activations | To utilize functional roles on each sub-systems | . Loreal Taiwan . Ditital Product Solution Manager . One to build OMNI ecosystems as turnkey and find potential buiness activaions accordingly. . To manage and build the digital ecosystem architect for potential business activation ideas | To define, build, and utilize functional roles on each sub-system | To find business opportunities though existed systems or implementing new technologies/ideas | Country key contact with Global/Region on GA/GTM Tagging | . Project Manager . To build/upgrading the online eCommerce website solution as the brand/local integrations needs | To monitor and enhance the online sales activity and performance | To ensure user experience and all eCommerce activities are consistent with the brand sense of purpose | Collect and connect working knowledge on the e-retailers | Optimizing SEO/Data Tracking Schema collecting owned data for further analyzing | Create synergies between inside and outside websites in data synchronizations | . Freelace . One to build and integrate digital systems for business innovations. . To build eCommerce website and desktop tools managing product data (external data sources) | To build mobile app and managing web consols | To build and maintain customer/product/sales systems for small business | . TechArt Center, Taipei National University of the Arts . Engineer . To support exhibition planning | Code rewriting | Exhibition space planning | To support annual projects and general affairs | .",
          "url": "https://impepper.github.io/myPortfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  
      ,"page6": {
          "title": "Skills",
          "content": "Certifications . Critical Thinking for More Effective Communication (2021) . fierce CONVERSATIONS (2021) . Python for Machine Learning and Data Science Bootcamp (2021) . Social Media Marketing &amp; Digital Marketing Course (2020) . Skills . Software Deveopment . Desktop/WEB applications, Integrations (e.g. LINE Messaging Bot), API . Programing Language . Javascript, Python, VBA | . Web/Data analytics . Web Analytics . Google Analytics | Google Tag Manager Website Optimizing . | SEO | AB Test (ABTasty / Google Optimize) | . Data Management . Data Managing/Engineering . SQL | Data processing Data Visualization . | Google Data Studio | Microsoft Power BI | . Project Management . Robotic Process Automation (RPA) . Selenium | Microsoft Power Automate | Katalon Studio | AutoIt | UIPath Software Project Management . | JIRA | Confluence | Airtable | .",
          "url": "https://impepper.github.io/myPortfolio/skill/",
          "relUrl": "/skill/",
          "date": ""
      }
      
  

  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://impepper.github.io/myPortfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}